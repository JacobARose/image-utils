<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>imutils.ml.utils.experiment_utils API documentation</title>
<meta name="description" content="image-utils/imutils/utils/experiment_utils.py …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>imutils.ml.utils.experiment_utils</code></h1>
</header>
<section id="section-intro">
<p>image-utils/imutils/utils/experiment_utils.py</p>
<p>Based on previous script located at:
<a href="https://github.com/JacobARose/lightning-hydra-classifiers/blob/datasets_refactor/lightning_hydra_classifiers/utils/experiment_utils.py">lightning_hydra_classifiers/utils/experiment_utils.py</a></p>
<p>Contains common experiment utils for use in multiple scripts, including:</p>
<p>Created on: Wednesday, November 3rd, 2021
Author: Jacob A Rose</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
image-utils/imutils/utils/experiment_utils.py

Based on previous script located at:
[lightning_hydra_classifiers/utils/experiment_utils.py](https://github.com/JacobARose/lightning-hydra-classifiers/blob/datasets_refactor/lightning_hydra_classifiers/utils/experiment_utils.py)

Contains common experiment utils for use in multiple scripts, including:




Created on: Wednesday, November 3rd, 2021
Author: Jacob A Rose


&#34;&#34;&#34;

import argparse
from dataclasses import asdict
import os
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import numbers
from typing import *
import collections
import seaborn as sns
from sklearn.model_selection import train_test_split
import json
import hydra
from omegaconf import OmegaConf, DictConfig, ListConfig
import pytorch_lightning as pl

from imutils.ml.utils import template_utils

# from lightning_hydra_classifiers.utils import template_utils
# from lightning_hydra_classifiers.utils.plot_utils import colorbar
# from lightning_hydra_classifiers.utils.dataset_management_utils import LabelEncoder
# from lightning_hydra_classifiers.models.transfer import LightningClassifier

log = template_utils.get_logger(__name__)
log.setLevel(&#34;DEBUG&#34;)

__all__ = [&#34;load_data&#34;, 
                   &#34;resolve_config&#34;, 
                   &#34;configure_callbacks&#34;, 
                   &#34;configure_loggers&#34;,
                   &#34;configure_trainer&#34;, 
                   &#34;configure_model&#34;,
                   &#34;configure_loss_func&#34;]




def resolve_config(cfg: DictConfig) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Tool for ensuring all relative references in a dict-like config instance are resolved, typically prior to import/export.
        &#34;&#34;&#34;
        try:
                cfg = asdict(cfg)
        except TypeError:
                try:
                        cfg = OmegaConf.to_container(cfg, resolve=True)
                except ValueError:
                        cfg = dict(cfg)
        finally:
                cfg = OmegaConf.create(dict(cfg))
        return cfg



def configure_callbacks(cfg) -&gt; List[pl.Callback]:
        callbacks: List[pl.Callback] = []
        
        callback_configs = enumerate(cfg.callbacks) if isinstance(cfg.callbacks, ListConfig) else cfg.callbacks.items()
        
        for k, cb_conf in callback_configs:
                if cb_conf is None:
                        continue
                elif &#34;_target_&#34; in cb_conf:
                        log.info(f&#34;Instantiating callback &lt;{cb_conf._target_}&gt;&#34;)
                        
                        if k == &#34;module_data_monitor&#34;:
                                cb_conf = OmegaConf.to_container(cb_conf, resolve=True)
                        
                        callbacks.append(hydra.utils.instantiate(cb_conf))
        return callbacks


# def configure_loggers(config) -&gt; List[pl.loggers.LightningLoggerBase]:
#        logger: List[pl.loggers.LightningLoggerBase] = []
#        for _, lg_conf in config[&#34;logger&#34;].items():
#                if &#34;_target_&#34; in lg_conf:
#                        log.info(f&#34;Instantiating logger &lt;{lg_conf._target_}&gt;&#34;)
#                        logger.append(hydra.utils.instantiate(lg_conf))

#        return logger

import wandb

def configure_loggers(cfg, model=None):

        wandb_logger = None
        if &#34;wandb&#34; in cfg.logging:
                hydra.utils.log.info(f&#34;Instantiating &lt;WandbLogger&gt;&#34;)
                wandb_config = cfg.logging.wandb
                wandb_logger = pl.loggers.WandbLogger(**wandb_config)
                        # name=wandb_config.get(
                        #       &#34;name&#34;, 
                        #       (cfg.data.datamodule.get(&#34;name&#34;) + &#34;__&#34; + cfg.model_cfg.name)
                        # ),
                #       project=wandb_config.project,
                #       entity=wandb_config.entity,
                #       tags=cfg.core.tags,
                #       log_model=&#34;all&#34;, #True,
                # )
                                
                # print(f&#34;type(wandb_logger): {type(wandb_logger)}&#34;)
                # if model is not None:
                #        hydra.utils.log.info(f&#34;W&amp;B is now watching &lt;{wandb_config.watch.log}&gt;!&#34;)
                #        wandb_logger.watch(
                #                model, log=wandb_config.watch.log, log_freq=wandb_config.watch.log_freq
                #        )

        return wandb_logger


def configure_loss_func(cfg,
                                            **kwargs) -&gt; Callable:
        &#34;&#34;&#34;
        Singular function for organizing custom instantiation workflows for different categories of loss function, as some require different kinds of dynamically created kwargs that are difficult or impossible to specify completely within config files.
        
        
        Currently tested for:
                * torch.nn.CrossEntropyLoss
                * imutils.ml.utils.toolbox.nn.loss.CBCrossEntropyLoss
        &#34;&#34;&#34;
        import hydra
        
        if cfg.model_cfg.loss._target_ == &#34;imutils.ml.utils.toolbox.nn.loss.CBCrossEntropyLoss&#34;:
                assert &#34;targets&#34; in kwargs, &#34;Class-Balanced-Cross-Entropy Loss requires user to pass a `targets` as a kwarg&#34;
                loss = hydra.utils.instantiate(cfg.model_cfg.loss, targets=kwargs[&#34;targets&#34;])
        else:
                loss = hydra.utils.instantiate(cfg.model_cfg.loss)
                
        return loss






def configure_ckpt_dir(cfg):
        &#34;&#34;&#34;
        Creates directory cfg.checkpoint_dir if it doesn&#39;t exist. 
        If there are previous ckpts, assigns cfg.resume_from_checkpoint to the value of the path of the last one.
        
        Currently meant to only be called inside configure_trainer(cfg,...)
        
        (2022-03-22)
        [Note]: This is not tested or guaranteed to select the most relevant ckpt
        [Note]: cfg.resume_from_checkpoint is not yet guaranteed to be used. Might need to change to cfg.pl_trainer.resume_from_checkpoint.
        &#34;&#34;&#34;
        
        if os.path.exists(os.path.abspath(cfg.checkpoint_dir)):
                os.makedirs(os.path.abspath(cfg.checkpoint_dir), exist_ok=True)
                ckpt_paths = [os.path.join(cfg.checkpoint_dir, ckpt) for ckpt in os.listdir(cfg.checkpoint_dir)]
                if len(ckpt_paths) and os.path.exists(ckpt_paths[-1]):
                        print(f&#34;Found checkpoint: {os.path.basename(ckpt_paths[-1])} in cfg.checkpoint_dir: {os.path.abspath(cfg.checkpoint_dir)}&#34;)
                        cfg.resume_from_checkpoint = ckpt_paths[-1]

        
# def configure_progress_bar(*args, **kwargs):
#       &#34;&#34;&#34;
#       Currently set to just the default kwargs for pl.callbacks.RichProgressBar
#       &#34;&#34;&#34;

#       prog_bar = RichProgressBar(
#               refresh_rate_per_second=10,
#               leave=False,
#               theme=RichProgressBarTheme(
#                       description=&#39;white&#39;,
#                       progress_bar=&#39;#6206E0&#39;,
#                       progress_bar_finished=&#39;#6206E0&#39;, 
#                       progress_bar_pulse=&#39;#6206E0&#39;,
#                       batch_progress=&#39;white&#39;,
#                       time=&#39;grey54&#39;,
#                       processing_speed=&#39;grey70&#39;, 
#                       metrics=&#39;white&#39;
#               )
#       )
#       return prog_bar



def configure_trainer(cfg,
                                          callbacks=None,
                                          logger=None,
                                          **kwargs) -&gt; pl.Trainer:
        &#34;&#34;&#34;
        Checks for existing checkpoints, adds callbacks and logger to cfg, then instantiates pl.Trainer
        &#34;&#34;&#34;
        configure_ckpt_dir(cfg)
        
        trainer_cfg = resolve_config(cfg.train.pl_trainer)
        kwargs[&#39;callbacks&#39;] = callbacks
        kwargs[&#39;logger&#39;] = logger
        
        # import pdb;pdb.set_trace()
        
        trainer: pl.Trainer = hydra.utils.instantiate(trainer_cfg, **kwargs)
        return trainer








def configure_model(config: argparse.Namespace,
                                        label_encoder: Optional[&#34;LabelEncoder&#34;]=None
                                   ) -&gt; Tuple[&#34;LightningClassifier&#34;, argparse.Namespace]:

        model, config.model = build_model_or_load_from_checkpoint(ckpt_path=config.model.ckpt_path,
                                                                                                                          ckpt_dir=config.model.ckpt_dir,
                                                                                                                          ckpt_mode=config.model.ckpt_mode,
                                                                                                                          config=config.model)
        if hasattr(model, &#34;label_encoder&#34;):
                label_encoder = model.label_encoder
        if label_encoder is not None:
                model.label_encoder = label_encoder

        return model, config


def load_data(config: argparse.Namespace,
                          task_id: int=0
                         ) -&gt; &#34;DataModule&#34;:
        
        if not getattr(config.data, &#34;experiment&#34;, [None]):
                config.data.experiment = None

        if config.debug == True:
                log.warning(f&#34;Debug mode activated, loading CIFAR10 datamodule&#34;)
                datamodule = CIFAR10DataModule(task_id=task_id,
                                                                           batch_size=config.data.batch_size,
                                                                           image_size=config.data.image_size,
                                                                           image_buffer_size=config.data.image_buffer_size,
                                                                           num_workers=config.data.num_workers,
                                                                           pin_memory=config.data.pin_memory,
                                                                           experiment_config=config.data.experiment)
        else:
#                print(f&#34;Creating datamodule: config=&#34;)
#                pp(OmegaConf.to_container(config, resolve=True))
                datamodule = MultiTaskDataModule(task_id=task_id,
                                                                                 batch_size=config.data.batch_size,
                                                                                 image_size=config.data.image_size,
                                                                                 image_buffer_size=config.data.image_buffer_size,
                                                                                 num_workers=config.data.num_workers,
                                                                                 pin_memory=config.data.pin_memory,
                                                                                 experiment_config=config.data.experiment)
        datamodule.setup()
        return datamodule







# def load_data_and_model(config: argparse.Namespace, 
#                                                task_id: int=0,
#                                                ckpt_path: Optional[str]=&#34;&#34;) -&gt; Tuple[&#34;DataModule&#34;, LitMultiTaskModule]:

#        datamodule = load_data(config=config,
#                                                       task_id=task_id)
        

#        config.model.num_classes = datamodule.num_classes
#        for task_id_idx in range(len(config.model.multitask)):
#                task_name = config.system.task_ids[task_id_idx]
#                datamodule.set_task(task_id_idx)
#                datamodule.setup(&#34;fit&#34;)
#                config.model.multitask[task_name].num_classes = datamodule.num_classes
                
#        datamodule.set_task(task_id)
#        datamodule.setup()
                
#        task_name = config.system.task_ids[task_id]
#        if ckpt_path in [None, &#34;&#34;]:
#                config.model.ckpt_path = os.path.join(config.system.tasks[task_name].model_ckpt_dir, &#34;model.ckpt&#34;)
#        else:
#                config.model.ckpt_path = ckpt_path
#        model = load_model(config=config,
#                                               task_id=task_id,
#                                               ckpt_path=ckpt_path)
#        model.label_encoder = datamodule.label_encoder

#        return datamodule, model, config






#############################################################
#############################################################
#############################################################
#############################################################
#############################################################
#############################################################


def plot_class_distributions(targets: List[Any], 
                                                         sort_by: Optional[Union[str, bool, Sequence]]=&#34;count&#34;,
                                                         ax=None,
                                                         xticklabels: bool=True,
                                                         hist_kwargs: Optional[Dict]=None):
        &#34;&#34;&#34;
        Example:
                counts = plot_class_distributions(targets=data.targets, sort=True)
        &#34;&#34;&#34;
        
        counts = compute_class_counts(targets,
                                                                  sort_by=sort_by)
                                                
        keys = list(counts.keys())
        values = list(counts.values())

        if ax is None:
                plt.figure(figsize=(20,12))
        ax = sns.histplot(x=keys, weights=values, discrete=True, ax=ax, **hist_kwargs)
        plt.sca(ax)
        if xticklabels:
                xtick_fontsize = &#34;medium&#34;
                if len(keys) &gt; 100:
                        xtick_fontsize = &#34;x-small&#34;
                elif len(keys) &gt; 75:
                        xtick_fontsize = &#34;small&#34;
                plt.xticks(
                        rotation=90, #45, 
                        horizontalalignment=&#39;right&#39;,
                        fontweight=&#39;light&#39;,
                        fontsize=xtick_fontsize
                )
                if len(keys) &gt; 100:
                        for label in ax.xaxis.get_ticklabels()[::2]:
                                label.set_visible(False)
                
        else:
                ax.set_xticklabels([])
        
        return counts


#############################################################
#############################################################


def plot_split_distributions(data_splits: Dict[str, &#34;CommonDataset&#34;],
                                                         use_one_axis: bool=False,
                                                         hist_kwargs: Optional[Dict]=None):
        &#34;&#34;&#34;
        Create 3 vertically-stacked count plots of train, val, and test dataset class label distributions
        
        Arguments:
                data_splits: Dict[str, &#34;CommonDataset&#34;],
                        Dictionary mapping str split names to Dataset objects that at least have a Dataset.targets attribute for labels.
                use_one_axis: bool=False
                        If true, Plot all subsets to the same axis overlayed on top of each other. If False, plot them in individual subplots in the same figure.
                hist_kwargs: Optional[Dict]=None
                        Optional additional kwargs to be passed to sns.histplot(**hist_kwargs)
        
        &#34;&#34;&#34;
        assert isinstance(data_splits, dict)
        num_splits = len(data_splits)
        
        if use_one_axis:
                rows, cols = 1, 1
                fig, ax = plt.subplots(rows, cols, figsize=(20*cols,10*rows))
                ax = [ax]*num_splits
        else:
                if num_splits &lt;= 3:
                        rows = num_splits
                        cols = 1
                else:
                        rows = int(num_splits // 2)
                        cols = int(num_splits % 2)
                        
                fig, ax = plt.subplots(rows, cols, figsize=(20*cols,10*rows))   
                if hasattr(ax, &#34;flatten&#34;):
                        ax = ax.flatten()
        
        train_key = [k for k,v in data_splits.items() if &#34;train&#34; in k]
        sort_by = True
        if len(train_key)==1:
                sort_by = compute_class_counts(data_splits[train_key[0]].targets,
                                                                           sort_by=&#34;count&#34;)
                log.info(f&#39;Sorting by count for {train_key} subset, and applying order to all other subsets&#39;)
#                log.info(f&#34;len(sort_by)={len(sort_by)}&#34;)

        num_classes = len(set(list(data_splits.values())[0].targets))   
        xticklabels=False
        num_samples = 0
        counts = {}
        for i, (k, v) in enumerate(data_splits.items()):
                if i == num_splits-1:
                        xticklabels=True
                counts[k] = plot_class_distributions(targets=v.targets, 
                                                                                         sort_by=sort_by,
                                                                                         ax = ax[i],
                                                                                         xticklabels=xticklabels,
                                                                                         hist_kwargs=hist_kwargs)
                num_nonzero_classes = len([name for name, count_i in counts[k].items() if count_i &gt; 0])
                
                title = f&#34;{k} [n={len(v)}&#34;
                if num_nonzero_classes &lt; num_classes:
                        title += f&#34;, num_classes@(count &gt; 0) = {num_nonzero_classes}-out-of-{num_classes} classes in dataset&#34;
                title += &#34;]&#34;
                plt.gca().set_title(title, fontsize=&#39;large&#39;)
                
                num_samples += len(v)
        
        suptitle = &#39;-&#39;.join(list(data_splits.keys())) + f&#34;_splits (total samples={num_samples}, total classes = {num_classes})&#34;
        
        plt.suptitle(suptitle, fontsize=&#39;x-large&#39;)
        plt.subplots_adjust(bottom=0.1, top=0.94, wspace=None, hspace=0.08)
        
        return fig, ax


#############################################################
#############################################################



#############################################################
#############################################################



def compute_class_counts(targets: Sequence,
                                                 sort_by: Optional[Union[str, bool, Sequence]]=&#34;count&#34;
                                                ) -&gt; Dict[str, int]:
        
        counts = collections.Counter(targets)
#        if hasattr(sort_by, &#34;__len__&#34;):
        if isinstance(sort_by, dict):
                counts = {k: counts[k] for k in sort_by.keys()}
        if isinstance(sort_by, list):
                counts = {k: counts[k] for k in sort_by}
        elif (sort_by == &#34;count&#34;):
                counts = dict(sorted(counts.items(), key = lambda x:x[1], reverse=True))
        elif (sort_by is True):
                counts = dict(sorted(counts.items(), key = lambda x:x[0], reverse=True))
                
        return counts

#############################################################
#############################################################</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="imutils.ml.utils.experiment_utils.configure_callbacks"><code class="name flex">
<span>def <span class="ident">configure_callbacks</span></span>(<span>cfg) ‑> List[pytorch_lightning.callbacks.base.Callback]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_callbacks(cfg) -&gt; List[pl.Callback]:
        callbacks: List[pl.Callback] = []
        
        callback_configs = enumerate(cfg.callbacks) if isinstance(cfg.callbacks, ListConfig) else cfg.callbacks.items()
        
        for k, cb_conf in callback_configs:
                if cb_conf is None:
                        continue
                elif &#34;_target_&#34; in cb_conf:
                        log.info(f&#34;Instantiating callback &lt;{cb_conf._target_}&gt;&#34;)
                        
                        if k == &#34;module_data_monitor&#34;:
                                cb_conf = OmegaConf.to_container(cb_conf, resolve=True)
                        
                        callbacks.append(hydra.utils.instantiate(cb_conf))
        return callbacks</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.configure_loggers"><code class="name flex">
<span>def <span class="ident">configure_loggers</span></span>(<span>cfg, model=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_loggers(cfg, model=None):

        wandb_logger = None
        if &#34;wandb&#34; in cfg.logging:
                hydra.utils.log.info(f&#34;Instantiating &lt;WandbLogger&gt;&#34;)
                wandb_config = cfg.logging.wandb
                wandb_logger = pl.loggers.WandbLogger(**wandb_config)
                        # name=wandb_config.get(
                        #       &#34;name&#34;, 
                        #       (cfg.data.datamodule.get(&#34;name&#34;) + &#34;__&#34; + cfg.model_cfg.name)
                        # ),
                #       project=wandb_config.project,
                #       entity=wandb_config.entity,
                #       tags=cfg.core.tags,
                #       log_model=&#34;all&#34;, #True,
                # )
                                
                # print(f&#34;type(wandb_logger): {type(wandb_logger)}&#34;)
                # if model is not None:
                #        hydra.utils.log.info(f&#34;W&amp;B is now watching &lt;{wandb_config.watch.log}&gt;!&#34;)
                #        wandb_logger.watch(
                #                model, log=wandb_config.watch.log, log_freq=wandb_config.watch.log_freq
                #        )

        return wandb_logger</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.configure_loss_func"><code class="name flex">
<span>def <span class="ident">configure_loss_func</span></span>(<span>cfg, **kwargs) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>Singular function for organizing custom instantiation workflows for different categories of loss function, as some require different kinds of dynamically created kwargs that are difficult or impossible to specify completely within config files.</p>
<p>Currently tested for:
* torch.nn.CrossEntropyLoss
* imutils.ml.utils.toolbox.nn.loss.CBCrossEntropyLoss</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_loss_func(cfg,
                                            **kwargs) -&gt; Callable:
        &#34;&#34;&#34;
        Singular function for organizing custom instantiation workflows for different categories of loss function, as some require different kinds of dynamically created kwargs that are difficult or impossible to specify completely within config files.
        
        
        Currently tested for:
                * torch.nn.CrossEntropyLoss
                * imutils.ml.utils.toolbox.nn.loss.CBCrossEntropyLoss
        &#34;&#34;&#34;
        import hydra
        
        if cfg.model_cfg.loss._target_ == &#34;imutils.ml.utils.toolbox.nn.loss.CBCrossEntropyLoss&#34;:
                assert &#34;targets&#34; in kwargs, &#34;Class-Balanced-Cross-Entropy Loss requires user to pass a `targets` as a kwarg&#34;
                loss = hydra.utils.instantiate(cfg.model_cfg.loss, targets=kwargs[&#34;targets&#34;])
        else:
                loss = hydra.utils.instantiate(cfg.model_cfg.loss)
                
        return loss</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.configure_model"><code class="name flex">
<span>def <span class="ident">configure_model</span></span>(<span>config: argparse.Namespace, label_encoder: Optional[ForwardRef('LabelEncoder')] = None) ‑> Tuple[LightningClassifier, argparse.Namespace]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_model(config: argparse.Namespace,
                                        label_encoder: Optional[&#34;LabelEncoder&#34;]=None
                                   ) -&gt; Tuple[&#34;LightningClassifier&#34;, argparse.Namespace]:

        model, config.model = build_model_or_load_from_checkpoint(ckpt_path=config.model.ckpt_path,
                                                                                                                          ckpt_dir=config.model.ckpt_dir,
                                                                                                                          ckpt_mode=config.model.ckpt_mode,
                                                                                                                          config=config.model)
        if hasattr(model, &#34;label_encoder&#34;):
                label_encoder = model.label_encoder
        if label_encoder is not None:
                model.label_encoder = label_encoder

        return model, config</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.configure_trainer"><code class="name flex">
<span>def <span class="ident">configure_trainer</span></span>(<span>cfg, callbacks=None, logger=None, **kwargs) ‑> pytorch_lightning.trainer.trainer.Trainer</span>
</code></dt>
<dd>
<div class="desc"><p>Checks for existing checkpoints, adds callbacks and logger to cfg, then instantiates pl.Trainer</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def configure_trainer(cfg,
                                          callbacks=None,
                                          logger=None,
                                          **kwargs) -&gt; pl.Trainer:
        &#34;&#34;&#34;
        Checks for existing checkpoints, adds callbacks and logger to cfg, then instantiates pl.Trainer
        &#34;&#34;&#34;
        configure_ckpt_dir(cfg)
        
        trainer_cfg = resolve_config(cfg.train.pl_trainer)
        kwargs[&#39;callbacks&#39;] = callbacks
        kwargs[&#39;logger&#39;] = logger
        
        # import pdb;pdb.set_trace()
        
        trainer: pl.Trainer = hydra.utils.instantiate(trainer_cfg, **kwargs)
        return trainer</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>config: argparse.Namespace, task_id: int = 0) ‑> DataModule</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(config: argparse.Namespace,
                          task_id: int=0
                         ) -&gt; &#34;DataModule&#34;:
        
        if not getattr(config.data, &#34;experiment&#34;, [None]):
                config.data.experiment = None

        if config.debug == True:
                log.warning(f&#34;Debug mode activated, loading CIFAR10 datamodule&#34;)
                datamodule = CIFAR10DataModule(task_id=task_id,
                                                                           batch_size=config.data.batch_size,
                                                                           image_size=config.data.image_size,
                                                                           image_buffer_size=config.data.image_buffer_size,
                                                                           num_workers=config.data.num_workers,
                                                                           pin_memory=config.data.pin_memory,
                                                                           experiment_config=config.data.experiment)
        else:
#                print(f&#34;Creating datamodule: config=&#34;)
#                pp(OmegaConf.to_container(config, resolve=True))
                datamodule = MultiTaskDataModule(task_id=task_id,
                                                                                 batch_size=config.data.batch_size,
                                                                                 image_size=config.data.image_size,
                                                                                 image_buffer_size=config.data.image_buffer_size,
                                                                                 num_workers=config.data.num_workers,
                                                                                 pin_memory=config.data.pin_memory,
                                                                                 experiment_config=config.data.experiment)
        datamodule.setup()
        return datamodule</code></pre>
</details>
</dd>
<dt id="imutils.ml.utils.experiment_utils.resolve_config"><code class="name flex">
<span>def <span class="ident">resolve_config</span></span>(<span>cfg: omegaconf.dictconfig.DictConfig) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Tool for ensuring all relative references in a dict-like config instance are resolved, typically prior to import/export.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resolve_config(cfg: DictConfig) -&gt; Dict[str, Any]:
        &#34;&#34;&#34;
        Tool for ensuring all relative references in a dict-like config instance are resolved, typically prior to import/export.
        &#34;&#34;&#34;
        try:
                cfg = asdict(cfg)
        except TypeError:
                try:
                        cfg = OmegaConf.to_container(cfg, resolve=True)
                except ValueError:
                        cfg = dict(cfg)
        finally:
                cfg = OmegaConf.create(dict(cfg))
        return cfg</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="imutils.ml.utils" href="index.html">imutils.ml.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="imutils.ml.utils.experiment_utils.configure_callbacks" href="#imutils.ml.utils.experiment_utils.configure_callbacks">configure_callbacks</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.configure_loggers" href="#imutils.ml.utils.experiment_utils.configure_loggers">configure_loggers</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.configure_loss_func" href="#imutils.ml.utils.experiment_utils.configure_loss_func">configure_loss_func</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.configure_model" href="#imutils.ml.utils.experiment_utils.configure_model">configure_model</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.configure_trainer" href="#imutils.ml.utils.experiment_utils.configure_trainer">configure_trainer</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.load_data" href="#imutils.ml.utils.experiment_utils.load_data">load_data</a></code></li>
<li><code><a title="imutils.ml.utils.experiment_utils.resolve_config" href="#imutils.ml.utils.experiment_utils.resolve_config">resolve_config</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>