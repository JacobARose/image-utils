<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>imutils.utils.ResizeRight.resize_right.resize_right API documentation</title>
<meta name="description" content="resize_right.py" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>imutils.utils.ResizeRight.resize_right.resize_right</code></h1>
</header>
<section id="section-intro">
<p>resize_right.py</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;

resize_right.py

&#34;&#34;&#34;

import warnings
from math import ceil
from . import interp_methods

class NoneClass:
        pass

# try:
#       import torch
#       from torch import nn
#       nnModuleWrapped = nn.Module
# except ImportError:
#       warnings.warn(&#34;No PyTorch found, will work only with Numpy&#34;)
#       torch = None
#       nnModuleWrapped = NoneClass
import torch
from torch import nn
nnModuleWrapped = nn.Module
import numpy

        
        
def resize(
        input_tensor,
        scale_factors=None,
        out_shape=None,
        interp_method=interp_methods.cubic,
        support_sz=None,
        antialiasing=True):
        &#34;&#34;&#34;
        resize()

        &#34;&#34;&#34;
        # get properties of the input_tensor tensor
        in_shape, n_dims = input_tensor.shape, input_tensor.ndim

        # fw stands for framework that can be either numpy or torch,
        # determined by the input_tensor type
        fw = numpy if type(input_tensor) is numpy.ndarray else torch
        eps = fw.finfo(fw.float32).eps

        # set missing scale factors or output shapem one according to another,
        # scream if both missing
        scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw)

        # sort indices of dimensions according to scale of each dimension.
        # since we are going dim by dim this is efficient
        sorted_filtered_dims_and_scales = [
                (dim, scale_factors[dim])
                for dim in sorted(range(n_dims), key=lambda ind: scale_factors[ind])
                if scale_factors[dim] != 1.0
        ]

        # unless support size is specified by the user, it is an attribute
        # of the interpolation method
        if support_sz is None:
                support_sz = interp_method.support_sz

        # when using pytorch, we need to know what is the input_tensor tensor device
        device = input_tensor.device if fw is torch else None

        # output begins identical to input_tensor and changes with each iteration
        output = input_tensor

        # iterate over dims
        for dim, scale_factor in sorted_filtered_dims_and_scales:

                # get 1d set of weights and fields of view for each output location
                # along this dim
                field_of_view, weights = prepare_weights_and_field_of_view_1d(
                        dim,
                        scale_factor,
                        in_shape[dim],
                        out_shape[dim],
                        interp_method,
                        support_sz,
                        antialiasing,
                        fw,
                        eps,
                        device,
                )

                # multiply the weights by the values in the field of view and
                # aggreagate
                output = apply_weights(output, field_of_view, weights, dim, n_dims, fw)
        return output


class ResizeLayer(nnModuleWrapped):
        &#34;&#34;&#34;
        ResizeLayer()
        
        &#34;&#34;&#34;
        def __init__(
                self,
                in_shape,
                scale_factors=None,
                out_shape=None,
                interp_method=interp_methods.cubic,
                support_sz=None,
                antialiasing=True,
                device=None
                ):
                &#34;&#34;&#34;
                
                &#34;&#34;&#34;
                super(ResizeLayer, self).__init__()

                # fw stands for framework, that can be either numpy or torch. since
                # this is a torch layer, only one option in this case.
                torch = torch
                eps = torch.finfo(torch.float32).eps

                # set missing scale factors or output shapem one according to another,
                # scream if both missing
                scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape, scale_factors, torch)

                # unless support size is specified by the user, it is an attribute
                # of the interpolation method
                if support_sz is None:
                        support_sz = interp_method.support_sz

                self.n_dims = len(in_shape)

                # sort indices of dimensions according to scale of each dimension.
                # since we are going dim by dim this is efficient
                self.sorted_filtered_dims_and_scales = [
                        (dim, scale_factors[dim])
                        for dim in sorted(range(self.n_dims), key=lambda ind: scale_factors[ind])
                        if scale_factors[dim] != 1.0
                ]

                # iterate over dims
                field_of_view_list = []
                weights_list = []
                for dim, scale_factor in self.sorted_filtered_dims_and_scales:

                        # get 1d set of weights and fields of view for each output
                        # location along this dim
                        field_of_view, weights = prepare_weights_and_field_of_view_1d(
                                dim,
                                scale_factor,
                                in_shape[dim],
                                out_shape[dim],
                                interp_method,
                                support_sz,
                                antialiasing,
                                torch,
                                eps,
                                device,
                        )

                        # keep weights and fields of views for all dims
                        weights_list.append(nn.Parameter(weights, requires_grad=False))
                        field_of_view_list.append(nn.Parameter(field_of_view, requires_grad=False))

                self.field_of_view = nn.ParameterList(field_of_view_list)
                self.weights = nn.ParameterList(weights_list)
                self.in_shape = in_shape

        def forward(self, input_tensor):
                &#34;&#34;&#34;
                
                &#34;&#34;&#34;
                # output begins identical to input_tensor and changes with each iteration
                output = input_tensor

                for (dim, scale_factor), field_of_view, weights in zip(
                        self.sorted_filtered_dims_and_scales, self.field_of_view, self.weights
                ):
                        # multiply the weights by the values in the field of view and
                        # aggreagate
                        output = apply_weights(output, field_of_view, weights, dim, self.n_dims, torch)
                return output


def prepare_weights_and_field_of_view_1d(
        dim,
        scale_factor,
        in_sz,
        out_sz,
        interp_method,
        support_sz,
        antialiasing,
        fw,
        eps,
        device=None
        ):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # If antialiasing is taking place, we modify the window size and the
        # interpolation method (see inside function)
        interp_method, cur_support_sz = apply_antialiasing_if_needed(
                interp_method, support_sz, scale_factor, antialiasing
        )

        # STEP 1- PROJECTED GRID: The non-integer locations of the projection of
        # output pixel locations to the input tensor
        projected_grid = get_projected_grid(in_sz, out_sz, scale_factor, fw, device)

        # STEP 2- FIELDS OF VIEW: for each output pixels, map the input pixels
        # that influence it
        field_of_view = get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps, device)

        # STEP 3- CALCULATE WEIGHTS: Match a set of weights to the pixels in the
        # field of view for each output pixel
        weights = get_weights(interp_method, projected_grid, field_of_view)

        return field_of_view, weights


def apply_weights(input_tensor, field_of_view, weights, dim, n_dims, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # STEP 4- APPLY WEIGHTS: Each output pixel is calculated by multiplying
        # its set of weights with the pixel values in its field of view.
        # We now multiply the fields of view with their matching weights.
        # We do this by tensor multiplication and broadcasting.
        # this step is separated to a different function, so that it can be
        # repeated with the same calculated weights and fields.

        # for this operations we assume the resized dim is the first one.
        # so we transpose and will transpose back after multiplying
        tmp_input = fw_swapaxes(input_tensor, dim, 0, fw)

        # field_of_view is a tensor of order 2: for each output (1d location
        # along cur dim)- a list of 1d neighbors locations.
        # note that this whole operations is applied to each dim separately,
        # this is why it is all in 1d.
        # neighbors = tmp_input[field_of_view] is a tensor of order image_dims+1:
        # for each output pixel (this time indicated in all dims), these are the
        # values of the neighbors in the 1d field of view. note that we only
        # consider neighbors along the current dim, but such set exists for every
        # multi-dim location, hence the final tensor order is image_dims+1.
        neighbors = tmp_input[field_of_view]

        # weights is an order 2 tensor: for each output location along 1d- a list
        # of weighs matching the field of view. we augment it with ones, for
        # broadcasting, so that when multiplies some tensor the weights affect
        # only its first dim.
        tmp_weights = fw.reshape(weights, (*weights.shape, *[1] * (n_dims - 1)))

        # now we simply multiply the weights with the neighbors, and then sum
        # along the field of view, to get a single value per out pixel
        tmp_output = (neighbors * tmp_weights).sum(1)

        # we transpose back the resized dim to its original position
        return fw_swapaxes(tmp_output, 0, dim, fw)


def set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # eventually we must have both scale-factors and out-sizes for all in/out
        # dims. however, we support many possible partial arguments
        if scale_factors is None and out_shape is None:
                raise ValueError(&#34;either scale_factors or out_shape should be provided&#34;)
        if out_shape is not None:
                # if out_shape has less dims than in_shape, we defaultly resize the
                # first dims for numpy and last dims for torch
                out_shape = (
                        list(out_shape) + list(in_shape[: -len(out_shape)])
                        if fw is numpy
                        else list(in_shape[: -len(out_shape)]) + list(out_shape)
                )
                if scale_factors is None:
                        # if no scale given, we calculate it as the out to in ratio
                        # (not recomended)
                        scale_factors = [out_sz / in_sz for out_sz, in_sz in zip(out_shape, in_shape)]
        if scale_factors is not None:
                # by default, if a single number is given as scale, we assume resizing
                # two dims (most common are images with 2 spatial dims)
                scale_factors = (
                        scale_factors
                        if isinstance(scale_factors, (list, tuple))
                        else [scale_factors, scale_factors]
                )
                # if less scale_factors than in_shape dims, we defaultly resize the
                # first dims for numpy and last dims for torch
                scale_factors = (
                        list(scale_factors) + [1] * (len(in_shape) - len(scale_factors))
                        if fw is numpy
                        else [1] * (len(in_shape) - len(scale_factors)) + list(scale_factors)
                )
                if out_shape is None:
                        # when no out_shape given, it is calculated by multiplying the
                        # scale by the in_shape (not recomended)
                        out_shape = [
                                ceil(scale_factor * in_sz) for scale_factor, in_sz in zip(scale_factors, in_shape)
                        ]
                # next line intentionally after out_shape determined for stability
                scale_factors = [float(sf) for sf in scale_factors]
        return scale_factors, out_shape


def get_projected_grid(in_sz, out_sz, scale_factor, fw, device=None):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # we start by having the ouput coordinates which are just integer locations
        out_coordinates = fw.arange(out_sz)

        # if using torch we need to match the grid tensor device to the input device
        out_coordinates = fw_set_device(out_coordinates, device, fw)

        # This is projecting the ouput pixel locations in 1d to the input tensor,
        # as non-integer locations.
        # the following fomrula is derived in the paper
        # &#34;From Discrete to Continuous Convolutions&#34; by Shocher et al.
        return out_coordinates / scale_factor + (in_sz - 1) / 2 - (out_sz - 1) / (2 * scale_factor)


def get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps, device):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # for each output pixel, map which input pixels influence it, in 1d.
        # we start by calculating the leftmost neighbor, using half of the window
        # size (eps is for when boundary is exact int)
        left_boundaries = fw_ceil(projected_grid - cur_support_sz / 2 - eps, fw)

        # then we simply take all the pixel centers in the field by counting
        # window size pixels from the left boundary
        ordinal_numbers = fw.arange(ceil(cur_support_sz - eps))
        # in case using torch we need to match the device
        ordinal_numbers = fw_set_device(ordinal_numbers, device, fw)
        field_of_view = left_boundaries[:, None] + ordinal_numbers

        # next we do a trick instead of padding, we map the field of view so that
        # it would be like mirror padding, without actually padding
        # (which would require enlarging the input tensor)
        mirror = fw_cat((fw.arange(in_sz), fw.arange(in_sz - 1, -1, step=-1)), fw)
        field_of_view = mirror[fw.remainder(field_of_view, mirror.shape[0])]
        field_of_view = fw_set_device(field_of_view, device, fw)
        return field_of_view


def get_weights(interp_method, projected_grid, field_of_view):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # the set of weights per each output pixels is the result of the chosen
        # interpolation method applied to the distances between projected grid
        # locations and the pixel-centers in the field of view (distances are
        # directed, can be positive or negative)
        weights = interp_method(projected_grid[:, None] - field_of_view)

        # we now carefully normalize the weights to sum to 1 per each output pixel
        sum_weights = weights.sum(1, keepdims=True)
        sum_weights[sum_weights == 0] = 1
        return weights / sum_weights


def apply_antialiasing_if_needed(interp_method, support_sz, scale_factor, antialiasing):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # antialiasing is &#34;stretching&#34; the field of view according to the scale
        # factor (only for downscaling). this is low-pass filtering. this
        # requires modifying both the interpolation (stretching the 1d
        # function and multiplying by the scale-factor) and the window size.
        if scale_factor &gt;= 1.0 or not antialiasing:
                return interp_method, support_sz
        cur_interp_method = lambda arg: scale_factor * interp_method(scale_factor * arg)
        cur_support_sz = support_sz / scale_factor
        return cur_interp_method, cur_support_sz


def fw_ceil(x, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.int_(fw.ceil(x))
        else:
                return x.ceil().long()


def fw_cat(x, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.concatenate(x)
        else:
                return fw.cat(x)


def fw_swapaxes(x, ax_1, ax_2, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.swapaxes(x, ax_1, ax_2)
        else:
                return x.transpose(ax_1, ax_2)


def fw_set_device(x, device, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return x
        else:
                return x.to(device)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.apply_antialiasing_if_needed"><code class="name flex">
<span>def <span class="ident">apply_antialiasing_if_needed</span></span>(<span>interp_method, support_sz, scale_factor, antialiasing)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_antialiasing_if_needed(interp_method, support_sz, scale_factor, antialiasing):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # antialiasing is &#34;stretching&#34; the field of view according to the scale
        # factor (only for downscaling). this is low-pass filtering. this
        # requires modifying both the interpolation (stretching the 1d
        # function and multiplying by the scale-factor) and the window size.
        if scale_factor &gt;= 1.0 or not antialiasing:
                return interp_method, support_sz
        cur_interp_method = lambda arg: scale_factor * interp_method(scale_factor * arg)
        cur_support_sz = support_sz / scale_factor
        return cur_interp_method, cur_support_sz</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.apply_weights"><code class="name flex">
<span>def <span class="ident">apply_weights</span></span>(<span>input_tensor, field_of_view, weights, dim, n_dims, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_weights(input_tensor, field_of_view, weights, dim, n_dims, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # STEP 4- APPLY WEIGHTS: Each output pixel is calculated by multiplying
        # its set of weights with the pixel values in its field of view.
        # We now multiply the fields of view with their matching weights.
        # We do this by tensor multiplication and broadcasting.
        # this step is separated to a different function, so that it can be
        # repeated with the same calculated weights and fields.

        # for this operations we assume the resized dim is the first one.
        # so we transpose and will transpose back after multiplying
        tmp_input = fw_swapaxes(input_tensor, dim, 0, fw)

        # field_of_view is a tensor of order 2: for each output (1d location
        # along cur dim)- a list of 1d neighbors locations.
        # note that this whole operations is applied to each dim separately,
        # this is why it is all in 1d.
        # neighbors = tmp_input[field_of_view] is a tensor of order image_dims+1:
        # for each output pixel (this time indicated in all dims), these are the
        # values of the neighbors in the 1d field of view. note that we only
        # consider neighbors along the current dim, but such set exists for every
        # multi-dim location, hence the final tensor order is image_dims+1.
        neighbors = tmp_input[field_of_view]

        # weights is an order 2 tensor: for each output location along 1d- a list
        # of weighs matching the field of view. we augment it with ones, for
        # broadcasting, so that when multiplies some tensor the weights affect
        # only its first dim.
        tmp_weights = fw.reshape(weights, (*weights.shape, *[1] * (n_dims - 1)))

        # now we simply multiply the weights with the neighbors, and then sum
        # along the field of view, to get a single value per out pixel
        tmp_output = (neighbors * tmp_weights).sum(1)

        # we transpose back the resized dim to its original position
        return fw_swapaxes(tmp_output, 0, dim, fw)</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.fw_cat"><code class="name flex">
<span>def <span class="ident">fw_cat</span></span>(<span>x, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fw_cat(x, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.concatenate(x)
        else:
                return fw.cat(x)</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.fw_ceil"><code class="name flex">
<span>def <span class="ident">fw_ceil</span></span>(<span>x, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fw_ceil(x, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.int_(fw.ceil(x))
        else:
                return x.ceil().long()</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.fw_set_device"><code class="name flex">
<span>def <span class="ident">fw_set_device</span></span>(<span>x, device, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fw_set_device(x, device, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return x
        else:
                return x.to(device)</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.fw_swapaxes"><code class="name flex">
<span>def <span class="ident">fw_swapaxes</span></span>(<span>x, ax_1, ax_2, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fw_swapaxes(x, ax_1, ax_2, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        if fw is numpy:
                return fw.swapaxes(x, ax_1, ax_2)
        else:
                return x.transpose(ax_1, ax_2)</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.get_field_of_view"><code class="name flex">
<span>def <span class="ident">get_field_of_view</span></span>(<span>projected_grid, cur_support_sz, in_sz, fw, eps, device)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps, device):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # for each output pixel, map which input pixels influence it, in 1d.
        # we start by calculating the leftmost neighbor, using half of the window
        # size (eps is for when boundary is exact int)
        left_boundaries = fw_ceil(projected_grid - cur_support_sz / 2 - eps, fw)

        # then we simply take all the pixel centers in the field by counting
        # window size pixels from the left boundary
        ordinal_numbers = fw.arange(ceil(cur_support_sz - eps))
        # in case using torch we need to match the device
        ordinal_numbers = fw_set_device(ordinal_numbers, device, fw)
        field_of_view = left_boundaries[:, None] + ordinal_numbers

        # next we do a trick instead of padding, we map the field of view so that
        # it would be like mirror padding, without actually padding
        # (which would require enlarging the input tensor)
        mirror = fw_cat((fw.arange(in_sz), fw.arange(in_sz - 1, -1, step=-1)), fw)
        field_of_view = mirror[fw.remainder(field_of_view, mirror.shape[0])]
        field_of_view = fw_set_device(field_of_view, device, fw)
        return field_of_view</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.get_projected_grid"><code class="name flex">
<span>def <span class="ident">get_projected_grid</span></span>(<span>in_sz, out_sz, scale_factor, fw, device=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_projected_grid(in_sz, out_sz, scale_factor, fw, device=None):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # we start by having the ouput coordinates which are just integer locations
        out_coordinates = fw.arange(out_sz)

        # if using torch we need to match the grid tensor device to the input device
        out_coordinates = fw_set_device(out_coordinates, device, fw)

        # This is projecting the ouput pixel locations in 1d to the input tensor,
        # as non-integer locations.
        # the following fomrula is derived in the paper
        # &#34;From Discrete to Continuous Convolutions&#34; by Shocher et al.
        return out_coordinates / scale_factor + (in_sz - 1) / 2 - (out_sz - 1) / (2 * scale_factor)</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.get_weights"><code class="name flex">
<span>def <span class="ident">get_weights</span></span>(<span>interp_method, projected_grid, field_of_view)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_weights(interp_method, projected_grid, field_of_view):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # the set of weights per each output pixels is the result of the chosen
        # interpolation method applied to the distances between projected grid
        # locations and the pixel-centers in the field of view (distances are
        # directed, can be positive or negative)
        weights = interp_method(projected_grid[:, None] - field_of_view)

        # we now carefully normalize the weights to sum to 1 per each output pixel
        sum_weights = weights.sum(1, keepdims=True)
        sum_weights[sum_weights == 0] = 1
        return weights / sum_weights</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.prepare_weights_and_field_of_view_1d"><code class="name flex">
<span>def <span class="ident">prepare_weights_and_field_of_view_1d</span></span>(<span>dim, scale_factor, in_sz, out_sz, interp_method, support_sz, antialiasing, fw, eps, device=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_weights_and_field_of_view_1d(
        dim,
        scale_factor,
        in_sz,
        out_sz,
        interp_method,
        support_sz,
        antialiasing,
        fw,
        eps,
        device=None
        ):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # If antialiasing is taking place, we modify the window size and the
        # interpolation method (see inside function)
        interp_method, cur_support_sz = apply_antialiasing_if_needed(
                interp_method, support_sz, scale_factor, antialiasing
        )

        # STEP 1- PROJECTED GRID: The non-integer locations of the projection of
        # output pixel locations to the input tensor
        projected_grid = get_projected_grid(in_sz, out_sz, scale_factor, fw, device)

        # STEP 2- FIELDS OF VIEW: for each output pixels, map the input pixels
        # that influence it
        field_of_view = get_field_of_view(projected_grid, cur_support_sz, in_sz, fw, eps, device)

        # STEP 3- CALCULATE WEIGHTS: Match a set of weights to the pixels in the
        # field of view for each output pixel
        weights = get_weights(interp_method, projected_grid, field_of_view)

        return field_of_view, weights</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.resize"><code class="name flex">
<span>def <span class="ident">resize</span></span>(<span>input_tensor, scale_factors=None, out_shape=None, interp_method=&lt;function cubic&gt;, support_sz=None, antialiasing=True)</span>
</code></dt>
<dd>
<div class="desc"><p>resize()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resize(
        input_tensor,
        scale_factors=None,
        out_shape=None,
        interp_method=interp_methods.cubic,
        support_sz=None,
        antialiasing=True):
        &#34;&#34;&#34;
        resize()

        &#34;&#34;&#34;
        # get properties of the input_tensor tensor
        in_shape, n_dims = input_tensor.shape, input_tensor.ndim

        # fw stands for framework that can be either numpy or torch,
        # determined by the input_tensor type
        fw = numpy if type(input_tensor) is numpy.ndarray else torch
        eps = fw.finfo(fw.float32).eps

        # set missing scale factors or output shapem one according to another,
        # scream if both missing
        scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw)

        # sort indices of dimensions according to scale of each dimension.
        # since we are going dim by dim this is efficient
        sorted_filtered_dims_and_scales = [
                (dim, scale_factors[dim])
                for dim in sorted(range(n_dims), key=lambda ind: scale_factors[ind])
                if scale_factors[dim] != 1.0
        ]

        # unless support size is specified by the user, it is an attribute
        # of the interpolation method
        if support_sz is None:
                support_sz = interp_method.support_sz

        # when using pytorch, we need to know what is the input_tensor tensor device
        device = input_tensor.device if fw is torch else None

        # output begins identical to input_tensor and changes with each iteration
        output = input_tensor

        # iterate over dims
        for dim, scale_factor in sorted_filtered_dims_and_scales:

                # get 1d set of weights and fields of view for each output location
                # along this dim
                field_of_view, weights = prepare_weights_and_field_of_view_1d(
                        dim,
                        scale_factor,
                        in_shape[dim],
                        out_shape[dim],
                        interp_method,
                        support_sz,
                        antialiasing,
                        fw,
                        eps,
                        device,
                )

                # multiply the weights by the values in the field of view and
                # aggreagate
                output = apply_weights(output, field_of_view, weights, dim, n_dims, fw)
        return output</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.set_scale_and_out_sz"><code class="name flex">
<span>def <span class="ident">set_scale_and_out_sz</span></span>(<span>in_shape, out_shape, scale_factors, fw)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_scale_and_out_sz(in_shape, out_shape, scale_factors, fw):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # eventually we must have both scale-factors and out-sizes for all in/out
        # dims. however, we support many possible partial arguments
        if scale_factors is None and out_shape is None:
                raise ValueError(&#34;either scale_factors or out_shape should be provided&#34;)
        if out_shape is not None:
                # if out_shape has less dims than in_shape, we defaultly resize the
                # first dims for numpy and last dims for torch
                out_shape = (
                        list(out_shape) + list(in_shape[: -len(out_shape)])
                        if fw is numpy
                        else list(in_shape[: -len(out_shape)]) + list(out_shape)
                )
                if scale_factors is None:
                        # if no scale given, we calculate it as the out to in ratio
                        # (not recomended)
                        scale_factors = [out_sz / in_sz for out_sz, in_sz in zip(out_shape, in_shape)]
        if scale_factors is not None:
                # by default, if a single number is given as scale, we assume resizing
                # two dims (most common are images with 2 spatial dims)
                scale_factors = (
                        scale_factors
                        if isinstance(scale_factors, (list, tuple))
                        else [scale_factors, scale_factors]
                )
                # if less scale_factors than in_shape dims, we defaultly resize the
                # first dims for numpy and last dims for torch
                scale_factors = (
                        list(scale_factors) + [1] * (len(in_shape) - len(scale_factors))
                        if fw is numpy
                        else [1] * (len(in_shape) - len(scale_factors)) + list(scale_factors)
                )
                if out_shape is None:
                        # when no out_shape given, it is calculated by multiplying the
                        # scale by the in_shape (not recomended)
                        out_shape = [
                                ceil(scale_factor * in_sz) for scale_factor, in_sz in zip(scale_factors, in_shape)
                        ]
                # next line intentionally after out_shape determined for stability
                scale_factors = [float(sf) for sf in scale_factors]
        return scale_factors, out_shape</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.NoneClass"><code class="flex name class">
<span>class <span class="ident">NoneClass</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoneClass:
        pass</code></pre>
</details>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer"><code class="flex name class">
<span>class <span class="ident">ResizeLayer</span></span>
<span>(</span><span>in_shape, scale_factors=None, out_shape=None, interp_method=&lt;function cubic&gt;, support_sz=None, antialiasing=True, device=None)</span>
</code></dt>
<dd>
<div class="desc"><p>ResizeLayer()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ResizeLayer(nnModuleWrapped):
        &#34;&#34;&#34;
        ResizeLayer()
        
        &#34;&#34;&#34;
        def __init__(
                self,
                in_shape,
                scale_factors=None,
                out_shape=None,
                interp_method=interp_methods.cubic,
                support_sz=None,
                antialiasing=True,
                device=None
                ):
                &#34;&#34;&#34;
                
                &#34;&#34;&#34;
                super(ResizeLayer, self).__init__()

                # fw stands for framework, that can be either numpy or torch. since
                # this is a torch layer, only one option in this case.
                torch = torch
                eps = torch.finfo(torch.float32).eps

                # set missing scale factors or output shapem one according to another,
                # scream if both missing
                scale_factors, out_shape = set_scale_and_out_sz(in_shape, out_shape, scale_factors, torch)

                # unless support size is specified by the user, it is an attribute
                # of the interpolation method
                if support_sz is None:
                        support_sz = interp_method.support_sz

                self.n_dims = len(in_shape)

                # sort indices of dimensions according to scale of each dimension.
                # since we are going dim by dim this is efficient
                self.sorted_filtered_dims_and_scales = [
                        (dim, scale_factors[dim])
                        for dim in sorted(range(self.n_dims), key=lambda ind: scale_factors[ind])
                        if scale_factors[dim] != 1.0
                ]

                # iterate over dims
                field_of_view_list = []
                weights_list = []
                for dim, scale_factor in self.sorted_filtered_dims_and_scales:

                        # get 1d set of weights and fields of view for each output
                        # location along this dim
                        field_of_view, weights = prepare_weights_and_field_of_view_1d(
                                dim,
                                scale_factor,
                                in_shape[dim],
                                out_shape[dim],
                                interp_method,
                                support_sz,
                                antialiasing,
                                torch,
                                eps,
                                device,
                        )

                        # keep weights and fields of views for all dims
                        weights_list.append(nn.Parameter(weights, requires_grad=False))
                        field_of_view_list.append(nn.Parameter(field_of_view, requires_grad=False))

                self.field_of_view = nn.ParameterList(field_of_view_list)
                self.weights = nn.ParameterList(weights_list)
                self.in_shape = in_shape

        def forward(self, input_tensor):
                &#34;&#34;&#34;
                
                &#34;&#34;&#34;
                # output begins identical to input_tensor and changes with each iteration
                output = input_tensor

                for (dim, scale_factor), field_of_view, weights in zip(
                        self.sorted_filtered_dims_and_scales, self.field_of_view, self.weights
                ):
                        # multiply the weights by the values in the field of view and
                        # aggreagate
                        output = apply_weights(output, field_of_view, weights, dim, self.n_dims, torch)
                return output</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, input_tensor) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, input_tensor):
        &#34;&#34;&#34;
        
        &#34;&#34;&#34;
        # output begins identical to input_tensor and changes with each iteration
        output = input_tensor

        for (dim, scale_factor), field_of_view, weights in zip(
                self.sorted_filtered_dims_and_scales, self.field_of_view, self.weights
        ):
                # multiply the weights by the values in the field of view and
                # aggreagate
                output = apply_weights(output, field_of_view, weights, dim, self.n_dims, torch)
        return output</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="imutils.utils.ResizeRight.resize_right" href="index.html">imutils.utils.ResizeRight.resize_right</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.apply_antialiasing_if_needed" href="#imutils.utils.ResizeRight.resize_right.resize_right.apply_antialiasing_if_needed">apply_antialiasing_if_needed</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.apply_weights" href="#imutils.utils.ResizeRight.resize_right.resize_right.apply_weights">apply_weights</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.fw_cat" href="#imutils.utils.ResizeRight.resize_right.resize_right.fw_cat">fw_cat</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.fw_ceil" href="#imutils.utils.ResizeRight.resize_right.resize_right.fw_ceil">fw_ceil</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.fw_set_device" href="#imutils.utils.ResizeRight.resize_right.resize_right.fw_set_device">fw_set_device</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.fw_swapaxes" href="#imutils.utils.ResizeRight.resize_right.resize_right.fw_swapaxes">fw_swapaxes</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.get_field_of_view" href="#imutils.utils.ResizeRight.resize_right.resize_right.get_field_of_view">get_field_of_view</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.get_projected_grid" href="#imutils.utils.ResizeRight.resize_right.resize_right.get_projected_grid">get_projected_grid</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.get_weights" href="#imutils.utils.ResizeRight.resize_right.resize_right.get_weights">get_weights</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.prepare_weights_and_field_of_view_1d" href="#imutils.utils.ResizeRight.resize_right.resize_right.prepare_weights_and_field_of_view_1d">prepare_weights_and_field_of_view_1d</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.resize" href="#imutils.utils.ResizeRight.resize_right.resize_right.resize">resize</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.set_scale_and_out_sz" href="#imutils.utils.ResizeRight.resize_right.resize_right.set_scale_and_out_sz">set_scale_and_out_sz</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.NoneClass" href="#imutils.utils.ResizeRight.resize_right.resize_right.NoneClass">NoneClass</a></code></h4>
</li>
<li>
<h4><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer" href="#imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer">ResizeLayer</a></code></h4>
<ul class="">
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.dump_patches" href="#imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.dump_patches">dump_patches</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.forward" href="#imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.forward">forward</a></code></li>
<li><code><a title="imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.training" href="#imutils.utils.ResizeRight.resize_right.resize_right.ResizeLayer.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>