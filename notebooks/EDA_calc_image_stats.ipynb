{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d4a8cd-4e6d-4cc0-bc55-dedc99912842",
   "metadata": {},
   "source": [
    "## EDA_calc_image_stats notebook\n",
    "\n",
    "Created on: Saturday April 9th, 2022  \n",
    "Created by: Jacob Alexander Rose  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b89ee-a099-4a23-944e-a0939924676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "from rich import print as pp\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from imutils.big.datamodule import Herbarium2022DataModule, Herbarium2022Dataset\n",
    "from imutils.ml.data.datamodule import Herbarium2022DataModule, Herbarium2022Dataset\n",
    "from imutils.ml.utils.etl_utils import ETL\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms as T\n",
    "import argparse\n",
    "import imutils\n",
    "from hydra.experimental import compose, initialize, initialize_config_dir\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import *\n",
    "default_reader = None\n",
    "import torchmetrics\n",
    "\n",
    "from imutils.ml.models.pl import classifier\n",
    "\n",
    "from imutils.ml.utils.experiment_utils import configure_callbacks, configure_loggers, configure_trainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import imutils\n",
    "from imutils.ml.data.datamodule import *\n",
    "from imutils.ml.utils.etl_utils import ETL\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from rich import print as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992de5cd-852d-4923-9db3-c6d8f05a1f8c",
   "metadata": {},
   "source": [
    "## Load test config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37162ce1-0c8d-4b7e-baee-a2dc653b757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overrides = [\"aug@data.datamodule.transform_cfg=auto_image_aug\",\n",
    "#              \"data/datamodule@data=extant_leaves_family_10_512_datamodule\",\n",
    "#              \"model_cfg.backbone.name=resnext50_32x4d\"]\n",
    "\n",
    "overrides = [\"data/datamodule@data=extant_leaves_family_10_512_datamodule\",\n",
    "             \"model_cfg.backbone.name=resnext50_32x4d\"]\n",
    "\n",
    "# overrides = [\"data/datamodule@data=herbarium2022-res_512_datamodule\",\n",
    "#           \"model_cfg.backbone.name=resnext50_32x4d\"]\n",
    "          # \"+train.pl_trainer.limit_train_batches=2\",\n",
    "          # \"hp.batch_size=16\",\n",
    "          # \"hp.resolution=224\",\n",
    "          # \"+train.pl_trainer.limit_val_batches=2\",\n",
    "          # \"train.pl_trainer.log_every_n_steps=10\",\n",
    "          # \"train.pl_trainer.devices=1\",\n",
    "          # \"train.pl_trainer.strategy=null\",\n",
    "          # 'model_cfg/loss=class-balanced-ce-loss',\n",
    "          # \"model_cfg.loss.beta=0.99\",\n",
    "          # \"data.datamodule.transform_cfg.skip_augmentations=true\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf061f4-97d0-4776-8438-4cd4263a9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.dirname(imutils.ml.BASE_ML_CONF_PATH)\n",
    "config_name = os.path.basename(imutils.ml.BASE_ML_CONF_PATH)\n",
    "\n",
    "print(config_path, config_name)\n",
    "\n",
    "cfg = ETL.init_structured_config(config_name = config_name,\n",
    "                                 config_path = config_path,\n",
    "                                 job_name = \"demo\",\n",
    "                                 dataclass_type= None,\n",
    "                                 overrides=overrides,\n",
    "                                 cfg = None)\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "# Hydra run directory\n",
    "try:\n",
    "    hydra_dir = Path(HydraConfig.get().run.dir)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    hydra_dir = os.getcwd()\n",
    "\n",
    "\n",
    "hydra_dir = cfg.core.experiments_root_dir #\"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17\"\n",
    "\n",
    "\n",
    "if not cfg.get(\"hydra\"):\n",
    "    cfg.update({\"hydra\":{\"run\":{\"dir\":hydra_dir}},\n",
    "                \"run_output_dir\":hydra_dir})\n",
    "    print(cfg.hydra.run.dir)\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg.hydra))#, resolve=True, sort_keys=True))\n",
    "pp(OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "# transform_cfg = OmegaConf.to_container(cfg.data.datamodule.transform_cfg.train, resolve=True)\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "# transforms = []\n",
    "# for transform_step in transform_cfg:\n",
    "#     transforms.append(\n",
    "#         hydra.utils.instantiate(transform_step)\n",
    "#     )\n",
    "    \n",
    "# pp(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4278b24-2816-443a-87d3-eacb8a6cbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.utils.log.info(f\"Instantiating <{cfg.data.datamodule._target_}>\")\n",
    "datamodule = hydra.utils.instantiate(\n",
    "    cfg.data.datamodule, _recursive_=False\n",
    ")\n",
    "\n",
    "pp(datamodule.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65783ddb-8990-4e6a-8805-42eb1833edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "def threshold_image(img: np.ndarray, threshold: float) -> np.ndarray:\n",
    "    return ma.masked_greater(img, threshold)\n",
    "    # return ma.masked_where(img > threshold, img)\n",
    "\n",
    "def unnormalize(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "def image_stats(img: np.ndarray) -> str:\n",
    "    \n",
    "    return f\"{img.mean()=:.3f}, {img.std()=:.3f}, {img.min()=:.3f}, {img.max()=:.3f}, {img.dtype=}, {img.shape=}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a73177-24c0-4cd7-86fa-3a7903d63378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_hist_channel(image):#, channel):\n",
    "    \n",
    "    channels = [\"red\", \"green\", \"blue\"]\n",
    "    \n",
    "    # if isinstance(channel, str):\n",
    "    #     channel_idx = channels.index(channel)\n",
    "    # else:\n",
    "    #     channel_idx = channel\n",
    "    if image.ndim == 2:\n",
    "        channels = [\"Black&White\"]\n",
    "        color = \"orange\"\n",
    "        label = \"grayscale\"\n",
    "    \n",
    "    \n",
    "    alpha=1/len(channels)\n",
    "    # fig, (ax1, ax2) = plt.subplots(\n",
    "    #     ncols=2, figsize=(18, 6)\n",
    "    # )  # , sharex=True, sharey=True)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "        ncols=3, figsize=(27, 6)\n",
    "    )  # , sharex=True, sharey=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    stats_label = image_stats(image)\n",
    "    ax1.legend(stats_label)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"Normalized image\")\n",
    "    \n",
    "    ax2.imshow(unnormalize(image))\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Saturation-rescaled image\")\n",
    "\n",
    "    extracted_channel = image\n",
    "    for channel_idx in range(len(channels)):\n",
    "    \n",
    "        if image.ndim == 3:\n",
    "            color = channels[channel_idx]\n",
    "            label=color\n",
    "            extracted_channel = image[:, :, channel_idx]\n",
    "        print(extracted_channel.shape, extracted_channel.ravel().shape)\n",
    "        print(f\"color: {color}\")\n",
    "\n",
    "        ax3.hist(extracted_channel.ravel(), bins=256, color=[color], alpha=alpha, label=label)\n",
    "        # ax2.set_title(f\"{channels[channel_idx]} histogram\")\n",
    "        \n",
    "    ax3.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc5137-d615-45d1-bf65-a8b584827171",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stats(datamodule.train_dataset.fetch_item(25)[0])\n",
    "\n",
    "image_stats(datamodule.train_dataset[25][0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(18,8), sharex=True, sharey=True)\n",
    "\n",
    "idx =33\n",
    "\n",
    "img = datamodule.train_dataset.fetch_item(idx)[0]\n",
    "aug_img = datamodule.train_dataset[idx][0].permute(1,2,0).numpy()\n",
    "\n",
    "# img_tensor = torch.from_numpy(image).permute(2,0,1)\n",
    "print(img.shape)\n",
    "# aug_image = augs(img_tensor).permute(1,2,0).numpy()\n",
    "print(aug_img.shape)\n",
    "\n",
    "ax[1].imshow(aug_img)\n",
    "ax[1].set_title(\"augmented\")\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"original\")\n",
    "\n",
    "\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "plot_with_hist_channel(image=img)\n",
    "\n",
    "img2 = rgb2gray(img)\n",
    "plot_with_hist_channel(image=img2)\n",
    "\n",
    "threshold = img2.mean()\n",
    "img3 = threshold_image(img2, threshold)\n",
    "\n",
    "plot_with_hist_channel(image=img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c4a41-d199-4522-b8d6-b0997b5eb6a3",
   "metadata": {},
   "source": [
    "## Calculate dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c4bf5-f99c-4e16-830a-576376999fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =33\n",
    "\n",
    "img = datamodule.train_dataset.fetch_item(idx)[0]\n",
    "# aug_img = datamodule.train_dataset[idx][0].permute(1,2,0).numpy()\n",
    "image_stats(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc5e0d-ded3-4d9e-8002-2e3099d3c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datamodule.train_dataset.df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e0f27-fe4d-4846-84a0-c4661eecd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def calculate_img_channel_means(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    means = [np.mean(img[..., i]) / 255.0 for i in range(3)]\n",
    "    std =   [np.std(img[..., i]) / 255.0 for i in range(3)]\n",
    "    return means, std\n",
    "\n",
    "# images = glob.glob(os.path.join(PATH_DATASET, \"train_images\", \"*\", \"*\", \"*.jpg\"))\n",
    "image_filepaths = df.path.values.tolist()\n",
    "\n",
    "# images += glob.glob(os.path.join(PATH_DATASET, \"test_images\", \"*\", \"*.jpg\"))\n",
    "clr_mean_std = Parallel(n_jobs=os.cpu_count())(\n",
    "    delayed(calculate_img_channel_means)(fn) for fn in tqdm(image_filepaths)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67296029-0016-4bbd-9db7-c2263acec1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "\n",
    "\n",
    "img_color_mean = pd.DataFrame([c[0] for c in clr_mean_std]).describe()\n",
    "display(img_color_mean)\n",
    "img_color_std = pd.DataFrame([c[1] for c in clr_mean_std]).describe()\n",
    "display(img_color_std)\n",
    "\n",
    "img_color_mean = list(img_color_mean.T[\"mean\"])\n",
    "img_color_std = list(img_color_std.T[\"mean\"])\n",
    "print(\"Mean:\", img_color_mean,\"\\n\", \"Std:\", img_color_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8ab95-c92e-4b97-b37f-db00f9c25317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e972a04-472c-4bb7-902a-f5bbcd9fa97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50458aee-567e-4771-8c8f-e3dc39f6b537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd4e14-bf81-47b7-b195-50b89e086be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4d8c8-e44d-42d4-aae6-c5c81730d3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34256d3-d081-487a-a949-a1dfebdb0ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c467c0-727c-4edd-9d9d-b62b4d17e94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c97da6-12d7-42be-a865-0ea15602d940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f2936-4a10-425f-8713-e86b4ea9a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.zeros_like(img2, dtype=int)\n",
    "# mask = np.where(img2>=threshold, 1, 0)\n",
    "# img3 = img_as_ubyte(unnormalize(img2))[mask]\n",
    "\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb26d8-27e2-4c27-abb8-29861ca4f8d4",
   "metadata": {},
   "source": [
    "## Continued Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df12bd-cb0d-4c69-880a-184c8440a7b8",
   "metadata": {},
   "source": [
    "* Observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca875d5f-57fa-447e-b774-b6b0e943c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.utils.experiment_utils import (configure_callbacks,\n",
    "                                               configure_loggers,\n",
    "                                               configure_trainer,\n",
    "                                               configure_loss_func)\n",
    "import hydra\n",
    "if cfg.execution_list.model_fit:\n",
    "\n",
    "    hydra.utils.log.info(f\"Executing train stage: model_fit\")\n",
    "\n",
    "    hydra.utils.log.info(f\"Instantiating <{cfg.data.datamodule._target_}>\")\n",
    "    datamodule = hydra.utils.instantiate(\n",
    "        cfg.data.datamodule, _recursive_=False\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    loss_func = configure_loss_func(cfg, targets=datamodule.train_dataset.df.y)\n",
    "\n",
    "# logging.warning(\"1. Before model, before trainer\")\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.model_cfg._target_}>\")\n",
    "# model: pl.LightningModule = hydra.utils.instantiate(cfg.model, cfg=cfg, _recursive_=False)\n",
    "model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg, #model_cfg=cfg.model_cfg,\n",
    "                                                      loss_func=cfg.model_cfg.loss)\n",
    "\n",
    "# logging.warning(\"2. After model, before trainer\")\n",
    "# ic(torch.cuda.current_device())\t\n",
    "# ic(torch.cuda.get_device_name(0))\n",
    "wandb_logger = configure_loggers(cfg=cfg, model=model)\n",
    "callbacks: List[pl.Callback] = configure_callbacks(cfg=cfg.train)\t\n",
    "hydra.utils.log.info(f\"Instantiating the Trainer\")\n",
    "pp(OmegaConf.to_container(cfg.train.pl_trainer))\n",
    "trainer = configure_trainer(cfg,\n",
    "                            callbacks=callbacks,\n",
    "                            logger=wandb_logger)\n",
    "# logging.warning(\"3. After model, after trainer, before fit\")\n",
    "# ic(torch.cuda.current_device())\n",
    "num_samples = len(datamodule.train_dataset)\n",
    "num_classes = cfg.model_cfg.head.num_classes\n",
    "batch_size = datamodule.batch_size #[\"train\"]\n",
    "hydra.utils.log.info(\"Starting training with {} classes across {} images in batches of {} images each.\".format(\n",
    "    num_classes,\n",
    "    num_samples,\n",
    "    batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a03eed-333a-4b22-bbb2-e636715b4606",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp(OmegaConf.to_container(cfg, resolve=True))\n",
    "results = trainer.fit(model=model, datamodule=datamodule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbe2ac-017b-4084-93fb-1fc1270ab398",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09859a-d8b0-49c9-819b-840d2ad47437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e5140-8514-4a7b-84f6-5ebdfccaeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "from rich import print as pp\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from imutils.big.datamodule import Herbarium2022DataModule, Herbarium2022Dataset\n",
    "from imutils.ml.data.datamodule import Herbarium2022DataModule, Herbarium2022Dataset\n",
    "from imutils.ml.utils.etl_utils import ETL\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms as T\n",
    "import argparse\n",
    "import imutils\n",
    "from hydra.experimental import compose, initialize, initialize_config_dir\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from typing import *\n",
    "default_reader = None\n",
    "import torchmetrics\n",
    "\n",
    "from imutils.ml.models.pl import classifier\n",
    "\n",
    "from imutils.ml.utils.experiment_utils import configure_callbacks, configure_loggers, configure_trainer\n",
    "\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "from pathlib import Path\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"jrose/herbarium2022/37r673ke\")\n",
    "import imutils\n",
    "from imutils.ml.utils.etl_utils import ETL\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from rich import print as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b934c-c757-4ff7-aa63-160d47d68105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087a2be-e932-4541-af90-13835a211d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=10-val_loss=2.834-val_F1=0.384.ckpt\"\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=14-val_loss=2.521-val_F1=0.443.ckpt\"\n",
    "\n",
    "# ckpt_dir = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts\"\n",
    "# os.listdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d4b59-4e1d-4763-a340-17e5d9eca1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.utils.experiment_utils import (configure_callbacks,\n",
    "                                               configure_loggers,\n",
    "                                               configure_trainer,\n",
    "                                               configure_loss_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370120c-0893-4cf0-8562-485758c3d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/experiments/2022/herbarium2022/hydra_experiments/2022-03-29/05-31-45\"\n",
    "ckpt_dir = os.path.join(run_dir, \"ckpts\")\n",
    "ckpt_paths = sorted(os.listdir(ckpt_dir))[::-1][:3]   #[:-4:-1]\n",
    "\n",
    "ckpt_paths = [os.path.join(ckpt_dir, f, \"model_weights.ckpt\") for f in ckpt_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41459c5-7d4a-4285-b0f8-32d1496fa9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_main.py\n",
    "overrides = [\n",
    "    'core.name=\\\"Experiment #19 (2022-03-29)\\\"',\n",
    "    \"optim.optimizer.weight_decay=5e-6\",\n",
    "    \"hp.batch_size=24\",\n",
    "    \"aug@data.datamodule.transform_cfg=medium_image_aug_conf\",\n",
    "    \"hp.preprocess_size=512\",\n",
    "    \"hp.resolution=448\",\n",
    "    \"model_cfg.backbone.name=resnext50_32x4d\",\n",
    "    \"train.pl_trainer.devices=1\",\n",
    "    \"train.pl_trainer.accelerator=gpu\",\n",
    "    \"data.datamodule.num_workers=4\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2912e83-5e9d-4134-b165-794c09397e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.dirname(imutils.ml.BASE_ML_CONF_PATH)\n",
    "config_name = os.path.basename(imutils.ml.BASE_ML_CONF_PATH)\n",
    "\n",
    "print(config_path, config_name)\n",
    "\n",
    "cfg = ETL.init_structured_config(config_name = config_name,\n",
    "                                 config_path = config_path,\n",
    "                                 job_name = \"demo\",\n",
    "                                 dataclass_type= None,\n",
    "                                 overrides = [\"train.pl_trainer.strategy=null\",\n",
    "                                              *overrides],\n",
    "                                 cfg = None)\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "# Hydra run directory\n",
    "try:\n",
    "    hydra_dir = Path(HydraConfig.get().run.dir)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    hydra_dir = os.getcwd()\n",
    "\n",
    "\n",
    "hydra_dir = cfg.core.experiments_root_dir #\"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17\"\n",
    "\n",
    "\n",
    "if not cfg.get(\"hydra\"):\n",
    "    cfg.update({\"hydra\":{\"run\":{\"dir\":hydra_dir}},\n",
    "                \"run_output_dir\":hydra_dir})\n",
    "    print(cfg.hydra.run.dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93eee46-9cda-4486-8f41-b1e6e4b58e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edce6b-3900-40cf-83e7-8f474e36b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = ckpt_paths[1]\n",
    "# os.listdir(ckpt_path)\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c8be0-b85d-48e2-8b90-2fa432a06417",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(\n",
    "    cfg.data.datamodule, _recursive_=False\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf94eb-e5cb-4468-a4af-5336350cd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = configure_loss_func(cfg, targets=datamodule.train_dataset.df.y)\n",
    "\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.model_cfg._target_}>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849580-0f6e-4b0b-abd8-7171f3886fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg,\n",
    "                                                      loss_func=cfg.model_cfg.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d54cb-2b5e-4f17-a8e0-6d5e5db680ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(ckpt_path);\n",
    "model.eval();\n",
    "model.freeze();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b61ebd-87c2-4f33-ab7a-9f767565fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ffb83-0a54-4d39-997a-0141c03425dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device=\"cuda\"\n",
    "total=len(test_dataloader)\n",
    "\n",
    "results = []\n",
    "for batch_idx, batch in tqdm(enumerate(iter(test_dataloader)), total=total):\n",
    "    # x, y, metadata = batch\n",
    "    batch[0] = batch[0].to(device)\n",
    "    # image_ids = metadata['image_id']\n",
    "\n",
    "    output = model.predict_step(batch, batch_idx)\n",
    "    output[\"y_logit\"] = output[\"y_logit\"].cpu().detach()\n",
    "    results.append(output)\n",
    "\n",
    "\n",
    "    # results.append({\"image_id\": image_ids,\n",
    "    #                 \"y_logits\": y_logits})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d62362-7261-47ed-8bd2-d57e63bfec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b36bf-4ece-4f69-8857-5185d4c28748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56204fbd-f0c5-4458-8b58-b7ae688a36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logits = torch.cat([torch.argmax(r[\"y_logit\"], -1) for r in results])\n",
    "image_ids = torch.cat([r[\"image_id\"] for r in results])\n",
    "len(results[0][\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2ff43-3764-42fd-96cf-4441d04cfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6bff5-dbaf-4ed8-9df2-8743a89561c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in results:\n",
    "\n",
    "\n",
    "\n",
    "y_preds = np.concatenate([torch.argmax(r[\"y_logit\"], -1).numpy() for r in tqdm(results)])\n",
    "image_ids = np.concatenate([r[\"image_id\"] for r in results])\n",
    "len(results[0][\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4c69b-6da5-429f-a2b6-45f4cfad662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = datamodule.train_dataset.label_encoder.inv_transform(y_preds)\n",
    "y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80665b51-d3f5-47fa-a92c-593947732973",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({\"Id\":image_ids,\n",
    "                      \"Predicted\":y_preds})\n",
    "submit.to_csv(\"2022-04-04_JRose-Exp#19_baseline_herbarium2022_test_predictions_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b54118-fd38-42bd-9a5d-3e017e90c87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c5b8b7-050c-4eac-a3fc-0b7ea7a3c565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99edc5e2-0840-4193-aa36-aeebb5be2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845145d-7f9c-48f6-bce6-300a79a799c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(\"2022-04-04_JRose-Exp#19_baseline_herbarium2022_test_predictions_submission.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4df3d-ec38-4026-a527-fce6e68c67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766d9e3-13d9-46d7-b722-9ba3b6e50eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = datamodule.train_dataset.label_encoder\n",
    "\n",
    "# out = preds..assign(Predicted_scientificName = preds.apply(lambda x: label_encoder.inv_transform(x.Predicted), axis=1))\n",
    "out = preds.head(1000).apply(lambda x: label_encoder.inv_transform(x.Predicted)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9afb1-8c48-4d1c-b0ed-1698f21ec23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = datamodule.train_dataset.df\n",
    "\n",
    "test_df = datamodule.test_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a498977-5cdd-4d24-a39e-53ed419a0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = df.groupby(\"scientificName\").head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6f91e-f027-4be4-be0a-0b87f9a72c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Converting predictions back to standard category_ids\")\n",
    "\n",
    "# df.progress_apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31015ce3-3c19-4faf-97f4-0d14704ac212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_category_id(query):\n",
    "    return catalog[catalog.y==query].category_id.item()\n",
    "\n",
    "category_ids =  preds.assign(Predicted_cat_id = preds.progress_apply(lambda x: get_category_id(query=x.Predicted), axis=1))\n",
    "# category_ids =  preds.head(1000).apply(lambda x: get_category_id(query=x.Predicted), axis=1)\n",
    "category_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafacc3-e47d-4372-893d-bc86fd1f9d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_final = category_ids.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90b145-d670-4e3d-9e10-a5203480c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_final = preds_final.drop(columns=[\"Predicted\"]\n",
    "                              ).rename(columns={\"Predicted_cat_id\":\"Predicted\"})\n",
    "\n",
    "preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57349956-f337-43f4-8cc1-566878134fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_final.to_csv(\"2022-04-04_JRose-Exp#19_baseline_herbarium2022_test_predictions_submission--fixed-labels.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065e519-c0d5-4ad2-b756-b16edfc36964",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22ad7b-b4c0-4dec-8a3e-d85094f1dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "idx = 0\n",
    "\n",
    "img = Image.open(test_df.path[idx])\n",
    "pred_y = preds.Predicted[idx]\n",
    "pred_category_id = category_ids[idx]\n",
    "\n",
    "\n",
    "ax = plt.imshow(img)\n",
    "plt.title(f\"pred_y: {pred_y}, pred_category_id: {pred_category_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6068d0-769b-408f-8996-9afc8262ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "idx = 0\n",
    "samples = train_df[train_df.category_id==pred_category_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b41c3-a472-4be5-b72d-23397d459b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "fig, ax = plt.subplots(1,4, figsize=(30, 50))\n",
    "for i in range(4):\n",
    "    img = Image.open(samples.path.iloc[i])\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].set_title(f\"image_id: {samples.image_id.iloc[i]}\")\n",
    "\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344843b4-f57d-4dbd-ab26-b4aee7c69dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(train_df.path[idx])\n",
    "pred_y = preds.Predicted[idx]\n",
    "pred_category_id = category_ids[idx]\n",
    "\n",
    "\n",
    "ax = plt.imshow(img)\n",
    "plt.title(f\"pred_y: {pred_y}, pred_category_id: {pred_category_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad642046-58ed-4302-9f61-c5784199e235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e453ca8-fee9-42e7-9a06-9782584edfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ids = preds.head(1000).Id.values\n",
    "\n",
    "\n",
    "out = test_df[test_df.image_id.apply(lambda x: x in pred_ids)]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb32bc-c614-41f6-83da-abf98b78a07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d40086-7742-4b7a-a0dc-3e6c1352a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs in tqdm(test_dl):\n",
    "        inputs['pixel_values'] = inputs['pixel_values'].to('cuda')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds.extend([x.item() for x in logits.argmax(-1)])\n",
    "submit = pd.read_csv('../input/herbarium-2022-fgvc9/sample_submission.csv')\n",
    "submit['Predicted'] = preds\n",
    "submit.to_csv('beit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a5bb1-ad3b-4398-9cb0-1f03fe6038fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(OmegaConf.to_container(model.cfg, resolve=True))\n",
    "results = {}\n",
    "results['val'] = trainer.validate(model, datamodule=datamodule)\n",
    "pp(results['val'])\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=07-val_loss=3.338-val_F1=0.313.ckpt\"\n",
    "\n",
    "ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=10-val_loss=2.834-val_F1=0.384.ckpt\"\n",
    "\n",
    "# ckpt = torch.load(ckpt_path)\n",
    "# print(ckpt.keys())\n",
    "\n",
    "model = model.load_from_checkpoint(ckpt_path);\n",
    "model.eval();\n",
    "model.freeze();\n",
    "\n",
    "# batch[0] = batch[0].cuda()\n",
    "# batch[1] = batch[1].cuda()\n",
    "# x, y, metadata = batch\n",
    "# x = x.to('cuda')\n",
    "# y_logits = model(x)\n",
    "# y_logits_top5 = torch.topk(torch.Tensor(y_logits.cpu()), k=5, dim=1)\n",
    "# topk = 5\n",
    "# y_logits_top5_idx = y_logits_top5.indices.numpy()\n",
    "# labels_k = le.decode_topk(y_logits_top5_idx)\n",
    "# datamodule.train_dataset.label_encoder.classes_\n",
    "# y_pred = torch.zeros_like(y_logits_top5.indices)\n",
    "# topk_labels = np.empty((128,5), dtype=\"O\")\n",
    "# for k in range(5):\n",
    "#     labels_k = datamodule.train_dataset.label_encoder.inverse_transform(y_logits_top5.indices[:,k])\n",
    "#     topk_labels[:,k] = labels_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e029b16-b9f3-4b15-8170-746bb17ee79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f81ddc-3732-4925-a3d8-ebaf35b8c684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda43d86-875c-4d39-b1bd-96be3ada36a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e1e0ff9-67cf-44fe-a0cc-fa1fe5c96756",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98592e21-bf8d-4ec1-b78d-855563c1e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch = (next(iter(datamodule.train_dataloader())))\n",
    "\n",
    "x, y = batch[:2]\n",
    "\n",
    "# import cv2\n",
    "import torchvision\n",
    "# read_img = cv2.imread\n",
    "\n",
    "\n",
    "def plot_imgs(imgs,r=8,c=8,figsize=(20,20)):\n",
    "    _, axs = plt.subplots(r,c,figsize=figsize)\n",
    "    axs=axs.flatten()\n",
    "    for n, ax in enumerate(axs):\n",
    "        img=imgs[n]\n",
    "        \n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        ax.imshow(torchvision.transforms.functional.to_pil_image(img))\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "plot_imgs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d6a776-fbcd-47e5-8798-6e980cc42617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_stats(self, idx):\n",
    "    plt,axs = subplots(1, 3, figsize=(15,3))\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    for o,ax,title in zip(self.layer_stats(idx),axs,('mean','std','% near zero')):\n",
    "        ax.plot(o)\n",
    "        ax.set_title(f\"{-1*layer}th layer {title}\")\n",
    "# for layer in range(1,4):\n",
    "#     plot_layer_stats(learn.activation_stats,-1*layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79781d22-e80b-4f1b-a4b9-d620f4062928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.models.pl.classifier import LitClassifier\n",
    "\n",
    "model = LitClassifier(cfg=cfg,\n",
    "                      loss_func=loss_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54470734-fa18-4d5e-b6cf-f00a5ac14e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e8028-bf74-468b-96cd-2893ef3b04ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258502c0-b441-4d2c-851f-da280e59c897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ae34f-c1b8-48c9-9dda-71f63c1da30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e861201-f5f2-4abe-8f67-9917d5befeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46487494-89c9-41a3-924a-9e9b01e5c7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57bda7f-b807-41dc-b7fc-9fb96f50f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/experiments/2022/herbarium2022/hydra_experiments/2022-03-29/05-31-45\"\n",
    "ckpt_dir = os.path.join(run_dir, \"ckpts\")\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "ckpt_paths = [os.path.join(ckpt_dir, f) for f in sorted(os.listdir(ckpt_dir))[-top_k:]]\n",
    "paths = []\n",
    "for d in ckpt_paths:\n",
    "    if os.path.isdir(d):\n",
    "        for f in sorted(os.listdir(d)):\n",
    "            paths.append(os.path.join(d, f))\n",
    "    else:\n",
    "        paths.append(d)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6b9fa-cc13-42be-a62d-3e2eb9343475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"]=\"herbarium2022\"\n",
    "!set | grep WANDB\n",
    "\n",
    "\n",
    "artifact = wandb.Artifact(\"model-weights\", \"checkpoints\")\n",
    "# Add Files and Assets to the artifact using \n",
    "# `.add`, `.add_file`, `.add_dir`, and `.add_reference`\n",
    "artifact.add_dir(ckpt_dir)\n",
    "# artifact.add_file(ckpt_path)\n",
    "artifact.save()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"herbarium2022/37r673ke\")\n",
    "# run.upload_file(ckpt_path)\n",
    "# for path in ckpt_paths:\n",
    "#     print(f\"Uploading file to wandb: {path}\")\n",
    "#     run.upload_file(path)\n",
    "# run = wandb.init(project=PROJECT_NAME, resume=True)\n",
    "# run.finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c533788-e9a5-47af-9c78-0ecc81035e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext filprofiler\n",
    "\n",
    "import psutil\n",
    "from rich import print as pp\n",
    "print(f\"RAM memory % used: {psutil.virtual_memory()[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173156c9-1792-491e-ab0d-04d01f1069d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.data.datamodule import Herbarium2022DataModule, Herbarium2022Dataset\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb3cea-840c-4e88-9e35-3ef6ef16781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%filprofile\n",
    "\n",
    "root_dir = \"/media/data_cifs/projects/prj_fossils/data/raw_data/herbarium-2022-fgvc9_resize-512/catalogs\"\n",
    "\n",
    "ds = Herbarium2022Dataset(catalog_dir=root_dir, image_reader=\"PIL\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550fef0-9f1f-44f0-b7c9-5f59aeb63e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(dict(ds.df.iloc[0]))\n",
    "\n",
    "path = ds.df.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eda72a-a27a-48a6-a46b-be375cc4db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# %%filprofile\n",
    "# img_bytes = img.tobytes()\n",
    "\n",
    "%%filprofile\n",
    "\n",
    "def display_obj_size(obj):\n",
    "    img_mem = sys.getsizeof(obj)\n",
    "    # img_mem = sys.getsizeof(img_bytes)\n",
    "    print(\"img size in memory:\")\n",
    "    print(f\"- {img_mem:,} bytes\")\n",
    "    print(f\"- {img_mem/1000:,} kb\")\n",
    "    print(f\"- {img_mem/1000/1000:,} Mb\")\n",
    "    \n",
    "    \n",
    "display_obj_size(img.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f47188-f121-4836-8c9c-15907d16eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a414b67-f824-4da3-8b0a-e42b156da148",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%filprofile\n",
    "\n",
    "take_k = 50\n",
    "paths = ds.df.path[:take_k]\n",
    "\n",
    "imgs = []\n",
    "for i, path in enumerate(paths):\n",
    "    # img = Image.open(path)\n",
    "    # img = np.asarray(img)\n",
    "    with open(path,\"rb\") as f:\n",
    "        # imgs.append(f.read())\n",
    "        img_enc = f.read()\n",
    "        \n",
    "    img_buffer = np.frombuffer(img_enc, np.uint8)\n",
    "    dec_img = cv2.imdecode(img_buffer, cv2.IMREAD_ANYCOLOR)\n",
    "    img = dec_img[:,:,::-1]\n",
    "        \n",
    "    # img = cv2.imread(path)\n",
    "    # if i < 3:\n",
    "        # display_obj_size(img.tobytes())\n",
    "    imgs.append(img)\n",
    "    # break\n",
    "    \n",
    "imgs = np.stack(imgs)\n",
    "# print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2982cf-6a2b-4d4b-8048-69f68e8a3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape\n",
    "\n",
    "display_obj_size(imgs[0])\n",
    "\n",
    "# img_buffer = imgs[2]\n",
    "img_enc = imgs[2]\n",
    "\n",
    "\n",
    "# img_enc = base64.b64decode(img_b64_enc)\n",
    "img_buffer = np.frombuffer(img_enc, np.uint8)\n",
    "dec_img = cv2.imdecode(img_buffer, cv2.IMREAD_ANYCOLOR)\n",
    "img = img[:,:,::-1]\n",
    "\n",
    "dec_img.shape\n",
    "\n",
    "Image.fromarray(dec_img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12767afb-8cf5-4d0c-b182-27c16f30fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit img_mem = sys.getsizeof(img.tobytes())\n",
    "\n",
    "print(\"img size in memory:\")\n",
    "print(f\"- {img_mem:,} bytes\")\n",
    "print(f\"- {img_mem/1000:,} kb\")\n",
    "print(f\"- {img_mem/1000/1000:,} Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4442f7-4842-43a5-a593-17ff52b25a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "img_file = BytesIO()\n",
    "img.save(img_file, 'png')\n",
    "img_file_size_png = img_file.tell()\n",
    "img_file = BytesIO()\n",
    "img.save(img_file, 'jpeg')\n",
    "img_file_size_jpeg = img_file.tell()\n",
    "print(\"img_file_size png: \", img_file_size_png)\n",
    "print(\"img_file_size jpeg: \", img_file_size_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c15b1d-6938-4bc6-84b6-64a37f2f9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import StringIO\n",
    "output = StringIO.StringIO()\n",
    "image_output.save(output, 'PNG') #a format needs to be provided\n",
    "contents = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "image_filesize = len(contents)\n",
    "\n",
    "ram_info = psutil.virtual_memory()\n",
    "\n",
    "for name, quantity in ram_info._asdict().items():\n",
    "    if name == \"percent\":\n",
    "        print(f\"{name}: {quantity/100:.2%}\")\n",
    "    else:\n",
    "        print(f\"{name}: {quantity/1000/1000/1000:2,} GB\")\n",
    "        print(f\"{name}: {quantity/1000/1000:2,} MB\")\n",
    "        print(f\"{name}: {quantity/1000:.2e} kb\")\n",
    "    print(\"=\"*20)\n",
    "\n",
    "# pp(ram_info)\n",
    "\n",
    "# total, avail, perc = ram_info[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c3b15c-17f9-4de9-b323-823c68cd47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{0.000012079806881608064:e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7ae46-715f-4645-8dfa-86c8ddb8726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{0.0000027673238836757465:e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616b5fe-7eea-4969-bf4f-0e90d7080e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{0.000012079806881608064/0.0000027673238836757465:e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14839337-38f0-454b-8403-195c9e5109b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{0.0000027673238836757465/0.000012079806881608064}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9badc-431d-4313-b761-bc75e4163c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb sync --id \"37r673ke\" -p \"herbarium2022\" -e \"jrose\" --include-online \"/media/data_cifs/projects/prj_fossils/users/jacob/experiments/2022/herbarium2022/hydra_experiments/2022-03-29/05-31-45/ckpts/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd6ae7-3550-4720-bcd5-f2fbcb13740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(671817 + 167955)\n",
    "\n",
    "train = 671817 / 24 / 4\n",
    "val = 167955 / 24 / 4\n",
    "\n",
    "train\n",
    "val\n",
    "train+ val\n",
    "\n",
    "1/1.10\n",
    "1/1.3\n",
    "1/1.6\n",
    "\n",
    "24/1.10\n",
    "24/1.3\n",
    "24/1.6\n",
    "\n",
    "(24/1.10)**-1\n",
    "(24/1.3)**-1\n",
    "(24/1.6)**-1\n",
    "\n",
    "24/1.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0d6ab-43d4-4574-8090-c0c7b0bed117",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.dirname(imutils.ml.BASE_ML_CONF_PATH)\n",
    "config_name = os.path.basename(imutils.ml.BASE_ML_CONF_PATH)\n",
    "\n",
    "cfg = ETL.init_structured_config(config_name = config_name,\n",
    "                                 config_path = config_path,\n",
    "                                 job_name = \"demo\",\n",
    "                                 dataclass_type= None,\n",
    "                                 overrides = [\"data.datamodule.num_workers=4\",\n",
    "                                              \"data/datamodule@data=herbarium2022-res_512_datamodule\",\n",
    "                                              # \"train.pl_trainer.gpus=4\",\n",
    "                                              \"train.pl_trainer.accelerator=gpu\",\n",
    "                                              \"model_cfg.backbone.name=resnext50_32x4d\"],\n",
    "                                              # \"model_cfg.backbone.name=resnet_50\"],\n",
    "                                              # \"model_cfg.backbone.name=xcit_large_24_p16_224\"],\n",
    "                                              # \"model_cfg.backbone.name=resnetv2_101x1_bitm\"],\n",
    "                                             # \"model_cfg.backbone.name=resnetv2_50\"], \n",
    "                                 cfg = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2154b02-204b-4968-a007-48322116e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.set_struct(cfg, False)\n",
    "# Hydra run directory\n",
    "try:\n",
    "    hydra_dir = Path(HydraConfig.get().run.dir)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    hydra_dir = os.getcwd()\n",
    "\n",
    "\n",
    "hydra_dir = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17\"\n",
    "\n",
    "\n",
    "if not cfg.get(\"hydra\"):\n",
    "    cfg.update({\"hydra\":{\"run\":{\"dir\":hydra_dir}},\n",
    "                \"run_output_dir\":hydra_dir})\n",
    "    print(cfg.hydra.run.dir)\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg.hydra))#, resolve=True, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df917e0-0ac2-4518-a293-b3e42f9c54f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16022f92-652b-4271-b7c0-cdf6c9202143",
   "metadata": {},
   "source": [
    "## Instantiate experiment ingredients with config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5fb23-06a0-46f5-bab3-743e751e3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "# OmegaConf.register_new_resolver(\"int\", int)\n",
    "\n",
    "if cfg.train.deterministic:\n",
    "    pl.seed_everything(cfg.train.random_seed)\n",
    "\n",
    "if cfg.train.pl_trainer.fast_dev_run:\n",
    "    hydra.utils.log.info(\n",
    "        f\"Debug mode <{cfg.train.pl_trainer.fast_dev_run}>. \"\n",
    "        f\"Forcing debugger friendly configuration!\"\n",
    "    )\n",
    "    cfg.train.pl_trainer.gpus = 0\n",
    "    cfg.data.datamodule.num_workers = 0\n",
    "\n",
    "try:\n",
    "    hydra_dir = Path(HydraConfig.get().run.dir)\n",
    "except Exception as e:\n",
    "    hydra_dir = os.getcwd()\n",
    "\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.data.datamodule._target_}>\")\n",
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(\n",
    "    cfg.data.datamodule, _recursive_=False\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25db9d-cb0d-431c-a236-dc46da0cc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imutils.ml.utils.toolbox.nn.functional import sequence2np\n",
    "\n",
    "from imutils.ml.utils.toolbox.nn.loss import CBCrossEntropyLoss\n",
    "\n",
    "\n",
    "\n",
    "targets = datamodule.train_dataset.df.y\n",
    "\n",
    "loss_func = CBCrossEntropyLoss(targets=targets,\n",
    "                               beta=0.0,\n",
    "                               reduction=\"mean\")\n",
    "\n",
    "assert np.all(loss_func.weights.numpy()==1.0)\n",
    "\n",
    "targets = datamodule.train_dataset.df.y\n",
    "\n",
    "loss_func = CBCrossEntropyLoss(targets=targets,\n",
    "                               beta=0.99,\n",
    "                               reduction=\"mean\")\n",
    "\n",
    "# np.all(loss_func.weights.numpy()==1.0)\n",
    "\n",
    "w_max = loss_func.weights.numpy().max()\n",
    "w_min = loss_func.weights.numpy().min()\n",
    "\n",
    "w_sum = loss_func.weights.numpy().sum()\n",
    "w_count = len(loss_func.weights)\n",
    "\n",
    "print(f\"w_max: {w_max:.5f}\",\"\\n\",\n",
    "      f\"w_min: {w_min:.5f}\",\"\\n\",\n",
    "      f\"w_sum: {w_sum:.5f}\",\"\\n\",\n",
    "      f\"w_count: {w_count}\")\n",
    "\n",
    "w = loss_func.weights\n",
    "w_max = loss_func.weights.numpy().max()\n",
    "w_min = loss_func.weights.numpy().min()\n",
    "w_normalized = (w - w_min) / (w_max - w_min)\n",
    "\n",
    "\n",
    "\n",
    "for name, w in [(\"normalized weights\", w_normalized), (\"weights\", loss_func.weights)]:\n",
    "\n",
    "    w_max = w.numpy().max()\n",
    "    w_min = w.numpy().min()\n",
    "\n",
    "    w_sum = w.numpy().sum()\n",
    "    w_count = len(w)\n",
    "\n",
    "    print(f\"{name}:\", \"\\n\", \"=\"*10)\n",
    "    print(f\"w_max: {w_max:.5f}\",\"\\n\",\n",
    "          f\"w_min: {w_min:.5f}\",\"\\n\",\n",
    "          f\"w_sum: {w_sum:.5f}\",\"\\n\",\n",
    "          f\"w_count: {w_count}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e804cf-f576-4333-b978-90ac128b8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func.classes\n",
    "reindex = np.argsort(loss_func.class_counts)[::-1]\n",
    "reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab17679-ebed-4cd5-99d0-fe024b837556",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_class_counts = loss_func.class_counts[reindex]\n",
    "ordered_class_weights = loss_func.weights.numpy()[reindex]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddc5f7-08ee-4990-9fed-dd05ca619d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(10,5), sharex=True, sharey=False)\n",
    "ax[0].plot(ordered_class_counts/np.sum(ordered_class_counts))\n",
    "ax[1].plot(np.exp(ordered_class_weights))\n",
    "\n",
    "dir(loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8c66a-b6de-44e3-b656-bc0537b05ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([9.8, 68.0, 5.3, 3.5, 10.8, 1.1, 1.4], dtype=torch.float32)\n",
    "weights = weights / weights.sum()\n",
    "print(weights)\n",
    "weights = 1.0 / weights\n",
    "weights = weights / weights.sum()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d66ef-d696-4baf-973d-53591c9ca0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datamodule.train_dataset.df.y\n",
    "\n",
    "counts_df = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c60b0-9927-4244-9a2a-8e2e57e64777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = sequence2np(y)\n",
    "# classes, class_counts = np.unique(y, return_counts=True)\n",
    "# print(type(classes), type(class_counts))\n",
    "# for label in range(15000):\n",
    "#     assert class_counts[label] == counts_df[label]\n",
    "# y = y.values.to_numpy()\n",
    "# y.shape\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97179f9-a5db-461e-8a41-09e8bab90ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9002c-8137-445b-8d43-8e4934b174cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.warning(\"1. Before model, before trainer\")\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.model_cfg._target_}>\")\n",
    "# model: pl.LightningModule = hydra.utils.instantiate(cfg.model, cfg=cfg, _recursive_=False)\n",
    "# model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg, #model_cfg=cfg.model_cfg,\n",
    "#                                                       loss_func=cfg.model_cfg.loss)\n",
    "\n",
    "# logging.warning(\"2. After model, before trainer\")\n",
    "# ic(torch.cuda.current_device())\t\n",
    "# ic(torch.cuda.get_device_name(0))\n",
    "wandb_logger = configure_loggers(cfg=cfg, model=model)\n",
    "callbacks: List[pl.Callback] = configure_callbacks(cfg=cfg.train)\t\n",
    "hydra.utils.log.info(f\"Instantiating the Trainer\")\n",
    "pp(OmegaConf.to_container(cfg.train.pl_trainer))\n",
    "trainer = configure_trainer(cfg,\n",
    "                            callbacks=callbacks,\n",
    "                            logger=wandb_logger)\n",
    "# logging.warning(\"3. After model, after trainer, before fit\")\n",
    "# ic(torch.cuda.current_device())\n",
    "num_samples = len(datamodule.train_dataset)\n",
    "num_classes = cfg.model_cfg.head.num_classes\n",
    "batch_size = datamodule.batch_size #[\"train\"]\n",
    "hydra.utils.log.info(\"Starting training with {} classes across {} images in batches of {} images each.\".format(\n",
    "    num_classes,\n",
    "    num_samples,\n",
    "    batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68179651-461d-41d0-9474-92aec25a468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.test_dataset.test_transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981965a-3ed1-48ae-9ec6-c134289ae143",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2566ec-045a-4fbd-9818-75a328b0ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loader = datamodule.test_dataloader()\n",
    "for i, batch in tqdm(enumerate(iter(loader)), total = len(loader)):\n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbeabb-8aa3-47c7-8dd6-8b237bcf91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "128*2.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09398e1a-1017-4351-b4f5-0c772c35433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "64*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cba45-106f-4656-80a8-ec56c3ed9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(datamodule.test_dataset.df.path.iloc[0])\n",
    "img.size\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fffed-dfd6-40b5-b998-7012b4dfa138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meerkat as mk\n",
    "# from meerkat.contrib.imagenette import download_imagenette\n",
    "\n",
    "\n",
    "# dp_csv_path = datamodule.train_dataset.split_file_path\n",
    "dp_csv_path = datamodule.test_dataset.split_file_path\n",
    "\n",
    "# download_imagenette(\".\")\n",
    "dp = mk.DataPanel.from_csv(dp_csv_path)\n",
    "dp[\"img\"] = mk.ImageColumn.from_filepaths(dp[\"path\"],\n",
    "                                          transform=datamodule.test_transform)\n",
    "# dp[[\"scientificName\", \"image_id\", \"img\"]].lz[:3]\n",
    "dp[[\"image_id\", \"img\"]].lz[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8f284-21bb-4286-98cf-58673d3adb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[\"img\"][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc3487-6835-4177-a54f-790e95f46185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "blue_col = dp.map(\n",
    "    lambda x: np.array(x[\"img\"])[2, :, :].mean(), \n",
    "    # lambda x: np.array(x[\"img\"])[:, :, 2].mean(), \n",
    "    pbar=True, \n",
    "    num_workers=2\n",
    ")\n",
    "dp[\"avg_blue\"] = blue_col  # add the intensities as a new column in the `DataPanel` \n",
    "\n",
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb7194-7dd6-43a4-ad28-d778a3d03843",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dp[\"img\"][0])\n",
    "\n",
    "# dir(dp[\"img\"].data)\n",
    "dp[\"img\"].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2c881-969f-4f29-9c68-277efc03b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the forward hook\n",
    "class ActivationExtractor:\n",
    "    \"\"\"Extracting activations a targetted intermediate layer\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.activation = None\n",
    "\n",
    "    def forward_hook(self, module, input, output):\n",
    "        self.activation = output\n",
    "\n",
    "# model.setup()\n",
    "# 2. Register the forward hook\n",
    "extractor = ActivationExtractor()\n",
    "model.net.backbone.layer4.register_forward_hook(extractor.forward_hook);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8c694-fa06-4629-8d26-5ae5f449ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import meerkat.ml as mkml\n",
    "# 1. Move the model to GPU\n",
    "model.to(0).eval()\n",
    "\n",
    "# 2. Define a function that runs a forward pass over a batch \n",
    "@torch.no_grad()\n",
    "def predict(batch: mk.DataPanel):\n",
    "    input_col: mk.TensorColumn = batch[\"img\"] \n",
    "    x: torch.Tensor = input_col.data.to(0)  # We get the underlying torch tensor with `data` and move to GPU \n",
    "    out: torch.Tensor = model(x)  # Run forward pass\n",
    "\n",
    "    # Return a dictionary with one key for each of the new columns. Each value in the\n",
    "    # dictionary should have the same length as the batch. \n",
    "    return {\n",
    "        \"pred\": out.cpu().numpy().argmax(axis=-1),\n",
    "        \"probs\": torch.softmax(out, axis=-1).cpu(),\n",
    "        \"activation\": mkml.EmbeddingColumn(extractor.activation.mean(dim=[-1,-2]).cpu())\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "valid_dp = dp.lz[:100]\n",
    "# 3. Apply the update. Note that the `predict` function operates on batches, so we set \n",
    "# `is_batched_fn=True`. Also, the `predict` function only accesses the \"input\" column, by \n",
    "# specifying that here we instruct update to only load that one column and skip others \n",
    "valid_dp = valid_dp.update(\n",
    "    function=predict,\n",
    "    is_batched_fn=True,\n",
    "    batch_size=32,\n",
    "    input_columns=[\"img\"], \n",
    "    pbar=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa324b0-c5d5-4505-a6a8-f4dd4b686b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list\n",
    "\n",
    "# dp[\"img\"]\n",
    "updated_dp\n",
    "\n",
    "pp(OmegaConf.to_container(model.cfg, resolve=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884e96c-bf89-4b46-8b72-f6f7c3e79f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=10-val_loss=2.834-val_F1=0.384.ckpt\"\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=14-val_loss=2.521-val_F1=0.443.ckpt\"\n",
    "\n",
    "ckpt_dir = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts\"\n",
    "\n",
    "\n",
    "model = model.load_from_checkpoint(ckpt_path);\n",
    "model.eval();\n",
    "model.freeze();\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch in iter(test_dataloader):\n",
    "    x, y, metadata = batch\n",
    "    x.to(model.device)\n",
    "    image_ids = metadata['image_id']\n",
    "    \n",
    "    y_logits = model.predict_step(x)\n",
    "    \n",
    "    results.append({\"image_id\": image_ids,\n",
    "                    \"y_logits: y_logits\"})\n",
    "\n",
    "pp(OmegaConf.to_container(model.cfg, resolve=True))\n",
    "\n",
    "# dir()\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['val'] = trainer.validate(model, datamodule=datamodule)\n",
    "\n",
    "pp(results['val'])\n",
    "\n",
    "# datamodule.test_dataset.df\n",
    "# datamodule.train_dataset.df\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=07-val_loss=3.338-val_F1=0.313.ckpt\"\n",
    "\n",
    "ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=10-val_loss=2.834-val_F1=0.384.ckpt\"\n",
    "\n",
    "# ckpt = torch.load(ckpt_path)\n",
    "# print(ckpt.keys())\n",
    "\n",
    "model = model.load_from_checkpoint(ckpt_path);\n",
    "model.eval();\n",
    "model.freeze();\n",
    "# model.to(\"cpu\")\n",
    "\n",
    "# test_loader = datamodule.test_dataloader()\n",
    "# batch = next(iter(test_loader))\n",
    "\n",
    "# batch[1]#.cpu()\n",
    "\n",
    "# batch[:2] = (b.cuda() for b in batch[:2])\n",
    "# [b.cuda() for b in batch[:2]]\n",
    "\n",
    "# batch[0] = batch[0].cuda()\n",
    "# batch[1] = batch[1].cuda()\n",
    "# x, y, metadata = batch\n",
    "# x = x.to('cuda')\n",
    "# y_logits = model(x)\n",
    "# y_logits_top5 = torch.topk(torch.Tensor(y_logits.cpu()), k=5, dim=1)\n",
    "# topk = 5\n",
    "# y_logits_top5_idx = y_logits_top5.indices.numpy()\n",
    "# labels_k = le.decode_topk(y_logits_top5_idx)\n",
    "# datamodule.train_dataset.label_encoder.classes_\n",
    "# y_pred = torch.zeros_like(y_logits_top5.indices)\n",
    "# topk_labels = np.empty((128,5), dtype=\"O\")\n",
    "# for k in range(5):\n",
    "#     labels_k = datamodule.train_dataset.label_encoder.inverse_transform(y_logits_top5.indices[:,k])\n",
    "#     topk_labels[:,k] = labels_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccf91d-9be0-42c3-aed6-bc3123ad20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.warning(\"1. Before model, before trainer\")\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.model_cfg._target_}>\")\n",
    "# model: pl.LightningModule = hydra.utils.instantiate(cfg.model, cfg=cfg, _recursive_=False)\n",
    "# model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg, #model_cfg=cfg.model_cfg,\n",
    "#                                                       loss_func=cfg.model_cfg.loss)\n",
    "\n",
    "# logging.warning(\"2. After model, before trainer\")\n",
    "# ic(torch.cuda.current_device())\t\n",
    "# ic(torch.cuda.get_device_name(0))\n",
    "wandb_logger = configure_loggers(cfg=cfg, model=model)\n",
    "callbacks: List[pl.Callback] = configure_callbacks(cfg=cfg.train)\t\n",
    "hydra.utils.log.info(f\"Instantiating the Trainer\")\n",
    "pp(OmegaConf.to_container(cfg.train.pl_trainer))\n",
    "trainer = configure_trainer(cfg,\n",
    "                            callbacks=callbacks,\n",
    "                            logger=wandb_logger)\n",
    "# logging.warning(\"3. After model, after trainer, before fit\")\n",
    "# ic(torch.cuda.current_device())\n",
    "num_samples = len(datamodule.train_dataset)\n",
    "num_classes = cfg.model_cfg.head.num_classes\n",
    "batch_size = datamodule.batch_size #[\"train\"]\n",
    "hydra.utils.log.info(\"Starting training with {} classes across {} images in batches of {} images each.\".format(\n",
    "    num_classes,\n",
    "    num_samples,\n",
    "    batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b3215-cccd-4c38-93c2-f9cc6a60d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661bce5-94e0-4be9-9bbc-779d6a12cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.utils.model_utils import log_model_summary\n",
    "\n",
    "model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg, #model_cfg=cfg.model_cfg,\n",
    "                                              loss=cfg.model_cfg.loss)\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg.model_cfg, resolve=True, sort_keys=True))\n",
    "\n",
    "# print(OmegaConf.to_yaml(cfg, resolve=True, sort_keys=True))\n",
    "# print(OmegaConf.to_yaml(cfg, resolve=True, sort_keys=True))\n",
    "# print(cfg['data']['datamodule']['transform_cfg'])\n",
    "\n",
    "type(cfg.model_cfg.input_shape)\n",
    "type(OmegaConf.to_container(cfg.model_cfg.input_shape, resolve=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf354c3a-d436-4661-a2a0-80a5d9f02071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "# hydra.utils.log.info(f\"Instantiating <{cfg.model_cfg._target_}>\")\n",
    "# model: pl.LightningModule = hydra.utils.instantiate(model_cfg=cfg, _recursive_=False)\n",
    "\n",
    "\n",
    "from imutils.ml.utils.model_utils import log_model_summary\n",
    "\n",
    "model = imutils.ml.models.pl.classifier.LitClassifier(cfg=cfg, #model_cfg=cfg.model_cfg,\n",
    "                                              loss=cfg.model_cfg.loss)\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg.model_cfg, resolve=True, sort_keys=True))\n",
    "\n",
    "# input_size = (1, 3,224,224)\n",
    "# summary = log_model_summary(model=model,\n",
    "#                             input_size=input_size,\n",
    "#                             full_summary=True,\n",
    "#                             working_dir=\".\",\n",
    "#                             model_name=cfg.model_cfg.backbone.name,\n",
    "#                             verbose=1)\n",
    "\n",
    "from imutils.ml.utils.experiment_utils import configure_callbacks, configure_loggers, configure_trainer\n",
    "\n",
    "# Instantiate the callbacks\n",
    "callbacks: List[pl.Callback] = configure_callbacks(cfg=cfg.train) #OmegaConf.to_container(cfg.train, resolve=True))\n",
    "\n",
    "model.freeze_up_to(layer=-1,\n",
    "                  submodule=\"backbone\")\n",
    "\n",
    "# ([(n, p.requires_grad_(False)) for n, p in model.net.backbone.named_parameters()])\n",
    "pp([(n, p.requires_grad) for n, p in model.net.backbone.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d31c71-e1c9-4b14-a36e-ca3e077d2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule.test_dataset.df\n",
    "# datamodule.train_dataset.df\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=07-val_loss=3.338-val_F1=0.313.ckpt\"\n",
    "\n",
    "ckpt_path = \"/media/data/jacob/GitHub/image-utils/imutils/ml/hydra_experiments/2022-03-24/07-35-17/hydra_experiments/2022-03-24/07-35-17/ckpts/epoch=10-val_loss=2.834-val_F1=0.384.ckpt\"\n",
    "\n",
    "# ckpt = torch.load(ckpt_path)\n",
    "# print(ckpt.keys())\n",
    "\n",
    "model = model.load_from_checkpoint(ckpt_path);\n",
    "model.eval();\n",
    "model.freeze();\n",
    "# model.to(\"cpu\")\n",
    "\n",
    "# test_loader = datamodule.test_dataloader()\n",
    "# batch = next(iter(test_loader))\n",
    "\n",
    "# batch[1]#.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b61cc-e35f-457f-9cdb-12e543d3ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[:2] = (b.cuda() for b in batch[:2])\n",
    "# [b.cuda() for b in batch[:2]]\n",
    "\n",
    "# batch[0] = batch[0].cuda()\n",
    "# batch[1] = batch[1].cuda()\n",
    "# x, y, metadata = batch\n",
    "# x = x.to('cuda')\n",
    "# y_logits = model(x)\n",
    "# y_logits_top5 = torch.topk(torch.Tensor(y_logits.cpu()), k=5, dim=1)\n",
    "# topk = 5\n",
    "# y_logits_top5_idx = y_logits_top5.indices.numpy()\n",
    "# labels_k = le.decode_topk(y_logits_top5_idx)\n",
    "# datamodule.train_dataset.label_encoder.classes_\n",
    "# y_pred = torch.zeros_like(y_logits_top5.indices)\n",
    "# topk_labels = np.empty((128,5), dtype=\"O\")\n",
    "# for k in range(5):\n",
    "#     labels_k = datamodule.train_dataset.label_encoder.inverse_transform(y_logits_top5.indices[:,k])\n",
    "#     topk_labels[:,k] = labels_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3499dc-43e2-4ec9-9982-e99b31c5047f",
   "metadata": {},
   "source": [
    "#### Dev topk predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aed655-28d1-4093-84e8-26c62d12cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# topk_labels = [] #np.empty((128,5), dtype=\"string\")\n",
    "\n",
    "# topk = 5\n",
    "# y_logits_top5_idx = y_logits_top5.indices.numpy()\n",
    "\n",
    "# y = y_logits_top5_idx#.shape[1]\n",
    "\n",
    "# if isinstance(y, np.ndarray):\n",
    "#     if y.ndim == 2:\n",
    "#         topk = y.shape[1]\n",
    "#     else:\n",
    "#         topk = 1\n",
    "# if isinstance(y, list):\n",
    "#     if isinstance(y[0], np.ndarray):\n",
    "#         topk = y[0].shape[0]\n",
    "#     elif isinstance(y[0], list):\n",
    "#         topk = len(y[0])\n",
    "\n",
    "# for k in range(topk):\n",
    "#     # labels_k = datamodule.train_dataset.label_encoder.inverse_transform(y_logits_top5.indices[:,k])\n",
    "#     labels_k = le.decode(y[:,k])\n",
    "#     topk_labels.append(labels_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34c777-af7f-49a0-92ea-991f60c46dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topk_labels = np.vstack(topk_labels).T\n",
    "# topk_labels.shape\n",
    "\n",
    "# topk_labels[:2,:]\n",
    "# true_labels = le.decode(y.numpy())\n",
    "# topk_labels[0]\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# encoder = preprocessing.LabelEncoder()\n",
    "# encoder.fit([0,4,-2,6])\n",
    "# encoder.classes_\n",
    "\n",
    "# class_list = getattr(encoder, \"classes_\", [])\n",
    "# class2idx = {label: idx for idx, label in enumerate(class_list)}\n",
    "# print(class2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29695f9f-88e1-4c85-b5e2-3931d26ef226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.ml.utils.label_utils import LabelEncoder\n",
    "\n",
    "le = LabelEncoder.from_sklearn(datamodule.train_dataset.label_encoder)\n",
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b939d-a3b5-4044-85e4-cc3cae0c39b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a494-f105-4c7b-9503-00078c32ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from imutils.ml.utils.model_utils import log_model_summary\n",
    "\n",
    "log_model_summary(model, input_size=(2,3,224,224))\n",
    "\n",
    "ckpt['epoch']\n",
    "ckpt['global_step']\n",
    "ckpt['pytorch-lightning_version']\n",
    "ckpt['hparams_name']\n",
    "ckpt['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c5e62-3ef3-4126-b793-78bd0b15fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datamodule.test_dataset.y_col\n",
    "getattr(datamodule.test_dataset.df, \"y\", -1)\n",
    "# df = datamodule.train_dataset.df\n",
    "df = pd.concat([datamodule.train_dataset.df,\n",
    "                datamodule.val_dataset.df])\n",
    "class_counts = df.value_counts(\"y\")\n",
    "class_counts = class_counts.reset_index(drop=False).rename(columns={0:\"counts\"})\n",
    "num_classes = class_counts.shape[0]\n",
    "above_25 = class_counts[class_counts.counts>=25]\n",
    "above_10 = class_counts[class_counts.counts>=10]\n",
    "above_5 = class_counts[class_counts.counts>=5]\n",
    "\n",
    "below_5 = class_counts[class_counts.counts<5]\n",
    "below_10 = class_counts[class_counts.counts<10]\n",
    "below_25 = class_counts[class_counts.counts<25]\n",
    "\n",
    "print(\"Min: \", min(class_counts.counts),\"Max:\", max(class_counts.counts))\n",
    "pp(f\"above_25: {above_25.shape[0]}, {above_25.shape[0] / num_classes:.4%}\")\n",
    "pp(f\"above_10: {above_10.shape[0]}, {above_10.shape[0] / num_classes:.4%}\")\n",
    "pp(f\"above_5: {above_5.shape[0]}, {above_5.shape[0] / num_classes:.4%}\")\n",
    "\n",
    "# pp(above_10.shape[0], above_10.shape[0] / num_classes)\n",
    "# pp(above_5.shape[0], above_5.shape[0] / num_classes)\n",
    "\n",
    "pp(f\"below_5: {below_5.shape[0]}, {below_5.shape[0] / num_classes:.4%}\")\n",
    "pp(f\"below_10: {below_10.shape[0]}, {below_10.shape[0] / num_classes:.4%}\")\n",
    "pp(f\"below_25: {below_25.shape[0]}, {below_25.shape[0] / num_classes:.4%}\")\n",
    "# pp(below_10.shape[0], below_10.shape[0] / num_classes)\n",
    "# pp(below_25.shape[0], below_25.shape[0] / num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4383a-815f-4879-88c1-57b8758d4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_catalog(catalog: pd.DataFrame,\n",
    "                   column: str,\n",
    "                   include=None,\n",
    "                   exclude=None) -> pd.DataFrame:\n",
    "    num_rows = catalog.shape[0]\n",
    "    if isinstance(include, Sequence):\n",
    "        pp(f\"Including {len(include)}\")\n",
    "        catalog = catalog[catalog[column].apply(lambda x: x in include)]\n",
    "    if isinstance(exclude, Sequence):\n",
    "        pp(f\"Excluding {len(exclude)}\")\n",
    "        \n",
    "        catalog = catalog[catalog[column].apply(lambda x: x not in exclude)]\n",
    "\n",
    "    pp(f\"Input num_rows: {num_rows}\")\n",
    "    pp(f\"Filtered num_rows: {catalog.shape[0]}, {catalog.shape[0]/num_rows:.3%}\")\n",
    "        \n",
    "    return catalog\n",
    "\n",
    "df = pd.concat([datamodule.train_dataset.df,\n",
    "                datamodule.val_dataset.df])\n",
    "                # datamodule.test_dataset.df])\n",
    "class_counts = df.value_counts(\"y\")\n",
    "class_counts = class_counts.reset_index(drop=False).rename(columns={0:\"counts\"})\n",
    "num_classes = class_counts.shape[0]\n",
    "# above_20 = class_counts[class_counts.counts>=20].counts\n",
    "# above_20 = above_20.values.tolist()\n",
    "above_20 = None\n",
    "below_20 = class_counts[class_counts.counts<40].counts\n",
    "below_20 = below_20.values.tolist()\n",
    "above_20_catalog = filter_catalog(catalog=df,\n",
    "                                  column=\"y\",\n",
    "                                  include=above_20,\n",
    "                                  exclude=below_20)\n",
    "above_20_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10df005-39fe-4928-8b22-fc397e91c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts.describe()\n",
    "\n",
    "# above_20 = class_counts[class_counts.counts>=20].counts\n",
    "# above_20 = above_20.values.tolist()\n",
    "# above_20 = None\n",
    "below_20 = class_counts[class_counts.counts<40] # .counts\n",
    "\n",
    "below_20.describe()\n",
    "\n",
    "datamodule.val_dataset.df.value_counts(\"y\")\n",
    "\n",
    "dir(datamodule.train_dataset.df.groupby(\"y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f863a-76cb-4ede-a0e6-eee4d6fdefc2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "train --> (num_samples: 587,840), (num_batches: 9,185)\n",
    "train --> (num_samples: 587,840), (num_batches: 9,185)\n",
    "val --> (num_samples: 251,932), (num_batches: 3,937)\n",
    "val --> (num_samples: 251,932), (num_batches: 3,937)\n",
    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
    "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b7296-03cf-49ff-bf03-1134113ce324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader = datamodule.val_dataloader()\n",
    "\n",
    "# batch = next(iter(val_loader))\n",
    "\n",
    "# len(batch)\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# # Single-label categorical\n",
    "# x = torch.randn(10, 5)\n",
    "# y = torch.randint(5, (10,))\n",
    "# loss = nn.CrossEntropyLoss()(x, y)\n",
    "\n",
    "\n",
    "# print(x.shape, y.shape, loss.shape)\n",
    "# print(x.dtype, y.dtype, loss.dtype)\n",
    "\n",
    "# # model\n",
    "\n",
    "# num_samples = len(datamodule.train_dataset)\n",
    "# num_batches = len(datamodule.train_dataloader())\n",
    "\n",
    "# ic(num_samples, num_batches, num_samples/ num_batches)\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# print(f\"{2264842/2:,}\")\n",
    "\n",
    "# print(f\"{2264842/3:,}\")\n",
    "\n",
    "# ic(num_samples * np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fa0f5-9570-40a5-9063-4dfa4a14ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule.setup_transforms(datamodule.transform_cfg)\n",
    "# from imutils.ml.data.datamodule import get_default_transforms\n",
    "# a = get_default_transforms(mode=\"train\", config=datamodule.transform_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f3d25-71ae-435e-8d5c-71de0576f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "def configure_loggers(cfg):\n",
    "\n",
    "    wandb_logger = None\n",
    "    if \"wandb\" in cfg.logging:\n",
    "        hydra.utils.log.info(f\"Instantiating <WandbLogger>\")\n",
    "        wandb_config = cfg.logging.wandb\n",
    "        wandb_logger = pl.loggers.WandbLogger(\n",
    "            name=wandb_config\n",
    "            .get(\"name\", \n",
    "                           (cfg.data.datamodule.get(\"name\") + \"__\" + cfg.model_cfg.name)),\n",
    "            project=wandb_config.project,\n",
    "            entity=wandb_config.entity,\n",
    "            tags=cfg.core.tags,\n",
    "            log_model=True,\n",
    "        )\n",
    "        hydra.utils.log.info(f\"W&B is now watching <{wandb_config.watch.log}>!\")\n",
    "        wandb_logger.watch(\n",
    "            model, log=wandb_config.watch.log, log_freq=wandb_config.watch.log_freq\n",
    "        )\n",
    "\n",
    "\n",
    "        hydra.utils.log.info(f\"Instantiating the Trainer\")\n",
    "    return wandb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff464d9-1f34-40cf-bef7-9f1e08210409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb_logger = configure_loggers(cfg=cfg, model=model)\n",
    "# print(wandb_logger)\n",
    "\n",
    "# # The Lightning core, the Trainer\n",
    "# trainer = pl.Trainer(\n",
    "#     default_root_dir=cfg.hydra.run.dir,\n",
    "#     logger=wandb_logger,\n",
    "#     callbacks=callbacks,\n",
    "#     deterministic=cfg.train.deterministic,\n",
    "#     val_check_interval=cfg.logging.val_check_interval,\n",
    "#     log_every_n_steps=10,\n",
    "#     #auto_select_gpus=True,\n",
    "#     # benchmark=True,\n",
    "#     # accelerator=None,  # 'dp', \"ddp\" if args.gpus > 1 else None,\n",
    "#     #plugins=[DDPPlugin(find_unused_parameters=True)],\n",
    "#     **cfg.train.pl_trainer,\n",
    "# )\n",
    "# # num_samples = len(datamodule.train_dataset)\n",
    "# num_classes = cfg.model_cfg.head.num_classes\n",
    "# batch_size = datamodule.batch_size #[\"train\"]\n",
    "# hydra.utils.log.info(\"Starting training with {} classes and batches of {} images\".format(\n",
    "#     num_classes,\n",
    "#     batch_size))\n",
    "# # pp(OmegaConf.to_container(cfg.train.callbacks, resolve=True))\n",
    "# trainer.fit(model=model, datamodule=datamodule)\n",
    "# #%debug\n",
    "# hydra.utils.log.info(f\"Starting testing!\")\n",
    "# trainer.test(model=model, datamodule=datamodule)\n",
    "# shutil.copytree(\".hydra\", Path(wandb_logger.experiment.dir) / \"hydra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636a676-06cc-4cb7-ba0d-b2912a88191a",
   "metadata": {},
   "source": [
    "## Measure time and function wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8545cb-b243-4534-8847-ccadf4442c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        from time import time\n",
    "        start = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        total_time = time() - start\n",
    "        print(f'Elapsed time is {total_time} ms')\n",
    "        \n",
    "        if isinstance(result, int):\n",
    "            print(f\"{result}/{total_time} = {result/(total_time):.3f} samples/sec\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f044c2b-4201-40a2-8a9e-b52289866414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "@measure_time\n",
    "def loop_through_dataloader(dataloader, num_batches):\n",
    "    data_iter = iter(dataloader)\n",
    "    for i, batch in tqdm(enumerate(data_iter), total=num_batches):\n",
    "        if i > num_batches-1:\n",
    "            break\n",
    "    num_samples = i*len(batch[0])\n",
    "    return num_samples\n",
    "\n",
    "\n",
    "\n",
    "# train_iter = iter(datamodule.train_dataloader())\n",
    "# datamodule.setup()\n",
    "# dataloader = datamodule.train_dataloader()\n",
    "# num_batches = 40\n",
    "# loop_through_dataloader(dataloader, num_batches)\n",
    "# bb = next(iter(dataloader))\n",
    "# pp(datamodule.cfg)\n",
    "# pp(OmegaConf.to_container(datamodule.cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90405dc3-2953-40d6-ba62-970fe7dcefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(datamodule.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c4020-cd05-4bae-8c1c-8146ef69c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# default_cfg = DictConfig(dict(\n",
    "#     catalog_dir=None,\n",
    "#     label_col=\"scientificName\",\n",
    "#     train_size=0.7,\n",
    "#     shuffle=True,\n",
    "#     seed=14,\n",
    "#     batch_size = 128,\n",
    "#     num_workers = None,\n",
    "#     pin_memory=True,\n",
    "#     transform_cfg=None,\n",
    "#     remove_transforms=False,\n",
    "# ))\n",
    "\n",
    "# from rich import print as pp\n",
    "\n",
    "# pp(OmegaConf.to_yaml(default_cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62638da1-bbcd-48c2-8b20-ed2ec10fe60d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Mock config yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1334a44-e017-4ee2-a475-1071b0e95da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATALOG_DIR = \"/media/data_cifs/projects/prj_fossils/users/jacob/data/herbarium_2022/catalog\"\n",
    "\n",
    "# datamodule = Herbarium2022DataModule(catalog_dir=CATALOG_DIR,\n",
    "#                                      num_workers=4,\n",
    "#                                      # image_reader=read_file_binary,\n",
    "#                                      remove_transforms=True)\n",
    "# datamodule.setup()\n",
    "\n",
    "# subset = \"train\"\n",
    "# dataset = datamodule.get_dataset(subset=subset)\n",
    "\n",
    "# dataset.num_classes\n",
    "\n",
    "# trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958649f-4ec0-4567-bd28-61f6fafff7e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a2c0f-5826-42e2-867d-cf063fdfe66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchvision import transforms as T\n",
    "# import argparse\n",
    "# from rich import print as pp\n",
    "\n",
    "# args = argparse.Namespace(\n",
    "#     preprocess={\n",
    "#         \"train\":{\n",
    "#             \"resize\":512\n",
    "#         },\n",
    "#         \"val\":{\n",
    "#             \"resize\":256\n",
    "#         },\n",
    "#     },\n",
    "#     batch_transform={\n",
    "#         \"train\":{\n",
    "#             \"random_resize_crop\":224\n",
    "#         },\n",
    "#         \"val\":{\n",
    "#             \"center_crop\":224\n",
    "#         },\n",
    "#     normalize=(\n",
    "#        [0.485, 0.456, 0.406],\n",
    "#        [0.229, 0.224, 0.225]\n",
    "#     )\n",
    "#     }\n",
    "# )\n",
    "# pp(args)\n",
    "\n",
    "# kornia_transform = nn.Sequential(\n",
    "#     K.RandomHorizontalFlip(),\n",
    "#     K.RandomVerticalFlip(),\n",
    "#     K.RandomMotionBlur(3, 35., 0.5),\n",
    "#     K.RandomRotation(degrees=45.0),\n",
    "#     K.Normalize(mean=mean_std,std=mean_std)\n",
    "# )\n",
    "\n",
    "# import numpy as np\n",
    "# from torch import nn\n",
    "# import torch\n",
    "# from albumentations.augmentations import transforms as AT\n",
    "\n",
    "# to_tensor = T.ToTensor()\n",
    "\n",
    "# class Preprocess(nn.Module):\n",
    "\n",
    "#     def __init__(self, mode=\"train\", resize=None):\n",
    "#         super().__init__()\n",
    "#         self.mode = mode\n",
    "#         self.resize = resize        \n",
    "#         self.resize_func = T.Resize(self.resize)\n",
    "    \n",
    "#     @torch.no_grad()  # disable gradients for effiency\n",
    "#     def forward(self, x) -> torch.Tensor:\n",
    "#         # x_tmp: np.ndarray = np.array(x)  # HxWxC\n",
    "#         # x_out: Tensor = to_tensor(x_tmp, keepdim=True)  # CxHxW\n",
    "#         if self.resize:\n",
    "#             x = self.resize_func(x)\n",
    "\n",
    "#         return x #_out.float()# / 255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class BatchTransforms(nn.Module):\n",
    "#     \"\"\"Module to perform data augmentation using Kornia on torch tensors.\"\"\"\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  mode: str=\"train\",\n",
    "#                  random_resize_crop=None,\n",
    "#                  center_crop=None,\n",
    "#                  apply_color_jitter: bool = False,\n",
    "#                  normalize = (\n",
    "#                      [0,0,0],\n",
    "#                      [1,1,1]\n",
    "#                  )\n",
    "#                 ) -> None:\n",
    "#         super().__init__()\n",
    "#         self.mode = mode\n",
    "#         self.random_resize_crop = random_resize_crop\n",
    "#         self.center_crop = center_crop\n",
    "#         self._apply_color_jitter = apply_color_jitter\n",
    "#         self.normalize = normalize\n",
    "        \n",
    "#         self.build_transforms(mode=mode)\n",
    "\n",
    "        \n",
    "#     def add_train_transforms(self, transforms=None):\n",
    "        \n",
    "#         transforms = transforms or []\n",
    "#         # if mode == \"train\":\n",
    "#         transforms.append(T.RandomPerspective())\n",
    "#         if type(self.random_resize_crop) == int:\n",
    "#             transforms.append(T.RandomResizedCrop(self.random_resize_crop))\n",
    "#         transforms.extend([\n",
    "#             T.RandomHorizontalFlip(),\n",
    "#             T.RandomVerticalFlip()\n",
    "#         ])\n",
    "#         return transforms\n",
    "\n",
    "#     def add_test_transforms(self, transforms=None):\n",
    "        \n",
    "#         transforms = transforms or []\n",
    "#         if type(self.center_crop) == int:\n",
    "#             transforms.append(T.CenterCrop(self.center_crop))\n",
    "#         return transforms\n",
    "\n",
    "\n",
    "#     def build_transforms(self,\n",
    "#                          mode: str = \"train\"):\n",
    "#         transforms = []\n",
    "#         if mode == \"train\":\n",
    "#             transforms = self.add_train_transforms(transforms=transforms)\n",
    "#         elif mode in [\"val\", \"test\"]:\n",
    "#             transforms = self.add_test_transforms(transforms=transforms)\n",
    "\n",
    "#         transforms.extend([\n",
    "# \t\t\t# T.ToTensor(),\n",
    "# \t\t\tT.Normalize(*self.normalize)\n",
    "#         ])\n",
    "\n",
    "#         self.transforms = nn.Sequential(*transforms)\n",
    "#         self.jitter = AT.ColorJitter(brightness=0.2,\n",
    "#                                      contrast=0.2,\n",
    "#                                      saturation=0.2,\n",
    "#                                      hue=0.2,\n",
    "#                                      always_apply=False,\n",
    "#                                      p=0.5)\n",
    "\n",
    "#     @torch.no_grad()  # disable gradients for effiency\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         x_out = self.transforms(x)  # BxCxHxW\n",
    "#         if self._apply_color_jitter:\n",
    "#             x_out = self.jitter(x_out)\n",
    "#         return x_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for subset in [\"train\",\"val\", \"test\"]:\n",
    "#     data = Herbarium2022Dataset(subset=subset,\n",
    "#                                 label_col=\"scientificName\",\n",
    "#                                 train_size=0.7,\n",
    "#                                 shuffle=(subset != \"test\"),\n",
    "#                                 seed=14,\n",
    "#                                 transform=None)\n",
    "\n",
    "#########################################\n",
    "\n",
    "CATALOG_DIR = \"/media/data_cifs/projects/prj_fossils/users/jacob/data/herbarium_2022/catalog\"\n",
    "SHARD_DIR = \"/media/data_cifs/projects/prj_fossils/users/jacob/data/herbarium_2022/webdataset\"\n",
    "\n",
    "# datamodule = Herbarium2022DataModule(catalog_dir=CATALOG_DIR,\n",
    "#                                      batch_size=64,\n",
    "#                                      num_workers=4,\n",
    "#                                      image_reader=read_file_binary,\n",
    "#                                      remove_transforms=True)\n",
    "# datamodule.setup()\n",
    "\n",
    "\n",
    "# train_dataloader = datamodule.train_dataloader()\n",
    "# train_batch = next(iter(train_dataloader))\n",
    "# datamodule.train_dataset.encoder.inverse_transform(train_batch[1])\n",
    "\n",
    "# checkpoint_callback = [c for c in callbacks if isinstance(c, pl.callbacks.ModelCheckpoint)][0]\n",
    "# logging.info(f\"checkpoint_callback.best_model_path: {str(checkpoint_callback.best_model_path)}\")\n",
    "# config.system.tasks[f\"task_{task_id}\"].ckpt_path = checkpoint_callback.best_model_path\n",
    "# checkpoint_callback.best_model_score = checkpoint_callback.best_model_score or 0.0\n",
    "# logging.info(f\"checkpoint_callback.best_model_score: {checkpoint_callback.best_model_score:.3f}\")\n",
    "# logging.info(f\"[Initiating TESTING on task_{task_id}]\")\n",
    "\n",
    "\n",
    "# test_results = run_multitask_test(trainer=trainer,\n",
    "#                               model=model,\n",
    "#                               datamodule=datamodule,\n",
    "#                               config=config,\n",
    "#                               tasks=\"all\")#,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64696c69-944a-421c-b882-3b36adf86fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
