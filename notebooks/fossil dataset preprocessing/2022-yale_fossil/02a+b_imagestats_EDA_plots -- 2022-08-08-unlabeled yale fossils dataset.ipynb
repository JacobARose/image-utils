{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9119696f-234e-4e36-a174-ea857fd4bc1e",
   "metadata": {},
   "source": [
    "# 02a+b_imagestats_EDA_plots -- 2022-08-08-unlabeled yale fossils dataset.ipynb\n",
    "\n",
    "Perform Exploratory Data Analysis on image dataset statistics previously computed upstream\n",
    "\n",
    "Created on: Monday August 8th, 2022  \n",
    "Created by: Jacob A Rose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea3cf9-7770-4901-a788-804b6f6e1742",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "- using `torchshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69e750-f081-45e8-b2e9-93aa6e178b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torchshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec9100-cce7-4543-a6f3-158f0f07bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.float_format', \"{:,.2f}\".format)\n",
    "\n",
    "\n",
    "import meerkat as mk\n",
    "display_res = 1024\n",
    "# print(mk.config.DisplayOptions.max_image_width)\n",
    "mk.config.DisplayOptions.max_image_width = display_res\n",
    "mk.config.DisplayOptions.max_image_height = display_res\n",
    "\n",
    "mk.config.DisplayOptions.max_rows = 100\n",
    "print(f\"{mk.config.DisplayOptions.max_image_width=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec8a06-5883-427f-ba84-318e1ab69753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mk.config.DisplayOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380c624-bf1c-4713-b028-a3d53e4cb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# from omegaconf import DictConfig, OmegaConf\n",
    "import os\n",
    "from rich import print as pp\n",
    "\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import inspect\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "# import meerkat as mk\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from PIL.ImageStat import Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b701d77-1756-497a-b329-e6b7264cadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806ed09-303b-4b25-a97e-d4c79c6787f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mk.config.DisplayOptions)\n",
    "# display_res = 512\n",
    "# # print(mk.config.DisplayOptions.max_image_width)\n",
    "# mk.config.DisplayOptions.max_image_width = display_res\n",
    "# mk.config.DisplayOptions.max_image_height = display_res\n",
    "# print(f\"{mk.config.DisplayOptions.max_image_width=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c5b6b-5d7a-4906-b393-78c03a929921",
   "metadata": {},
   "source": [
    "### Define key file info & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b1b58-3e4c-4f7a-9831-9be08cfc56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yale_fossil_dir = \"/media/data_cifs/projects/prj_fossils/data/yale_full\"\n",
    "\n",
    "analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results/\"\n",
    "results_filename = \"01_image_stats_df\"\n",
    "\n",
    "parquet_dir = os.path.join(analysis_results_root_dir, \"parquet\")\n",
    "parquet_file_path = os.path.join(parquet_dir, f\"{results_filename}.parquet\")\n",
    "\n",
    "csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b552c5-e3da-4779-961f-b4c6c466570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "# csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")\n",
    "\n",
    "# df = pd.read_csv(csv_file_path, index_col=0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c53ea3-fa4d-49e1-93b7-c01f80cb266b",
   "metadata": {},
   "source": [
    "### Load previously computed image stats from parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a2f33-65ee-46f4-9477-0e56354d0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(parquet_file_path):\n",
    "    print(f\"Found pre-computed image statistics analysis, loading from file on disk at location: {parquet_file_path}\")\n",
    "    df = pd.read_parquet(parquet_file_path)\n",
    "    \n",
    "else:\n",
    "    raise IOError(f\"Couldn't find required parquet file at specified location: {parquet_file_path}\")\n",
    "\n",
    "df = df.assign(identifier = df.path.apply(lambda x: Path(x).stem))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac77d27-fb52-4aa0-a03a-caec7177e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "occurrence_catalog_path = \"/media/data_cifs/projects/prj_fossils/data/raw_data/2022-yale_fossil/metadata-clean/occurrence-clean.txt\"\n",
    "multimedia_catalog_path = \"/media/data_cifs/projects/prj_fossils/data/raw_data/2022-yale_fossil/metadata-clean/multimedia-clean.txt\"\n",
    "\n",
    "\n",
    "occurrence_catalog = pd.read_csv(occurrence_catalog_path,\n",
    "                                 sep=\"\\t\")\n",
    "occurrence_catalog.columns.values\n",
    "\n",
    "multimedia_catalog = pd.read_csv(multimedia_catalog_path,\n",
    "                                 sep=\"\\t\")\n",
    "multimedia_catalog.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673813f-f28c-4725-97d9-884607220b53",
   "metadata": {},
   "source": [
    "### Image IO function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0914348-25dd-4985-9407-ad1f4d06d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "import cv2\n",
    "\n",
    "def load_image_PIL(file_path: str,\n",
    "                   mode: str=\"RGB\"):\n",
    "    img = PIL.Image.open(file_path)\n",
    "    if mode == \"BGR\":\n",
    "        return np.array(img)[:,:,::-1]\n",
    "    if mode == \"RGB\":\n",
    "        return img\n",
    "    if mode == \"HSV\":\n",
    "        return img.convert(\"HSV\")\n",
    "    else:\n",
    "        raise Exception(f\"Invalid value for {mode=}\")\n",
    "    \n",
    "\n",
    "def load_image_cv2(file_path: str,\n",
    "                   mode: str=\"RGB\"):\n",
    "    img = cv2.imread(file_path)\n",
    "    if mode == \"BGR\":\n",
    "        return img\n",
    "    if mode == \"RGB\":\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if mode == \"HSV\":\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    else:\n",
    "        raise Exception(f\"Invalid value for {mode=}\")\n",
    "\n",
    "\n",
    "def load_image(file_path: str,\n",
    "               mode: str=\"RGB\",\n",
    "               backend: str=\"PIL\",\n",
    "               lazy_load: bool=False):\n",
    "    error = None\n",
    "\n",
    "    try:\n",
    "        if backend == \"PIL\":\n",
    "            img = load_image_PIL(file_path=file_path,\n",
    "                                 mode=mode)\n",
    "            if (not lazy_load) and isinstance(img, PIL.Image.Image):\n",
    "                img.load()\n",
    "\n",
    "        elif backend == \"cv2\":\n",
    "            img = load_image_cv2(file_path=file_path,\n",
    "                                  mode=mode)\n",
    "        else:\n",
    "            raise Exception(f\"Invalid value for {backend=}\")\n",
    "\n",
    "    except OSError as e:\n",
    "        error = str(e)\n",
    "        \n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "        img = load_image_PIL(file_path=file_path,\n",
    "                             mode=mode)\n",
    "        if isinstance(img, PIL.Image.Image):\n",
    "            img.load()\n",
    "        ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "\n",
    "    return img, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65786b3-81ef-4b1b-8e2a-a2e3d67814b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_file_size(path):\n",
    "    size = os.path.getsize(path)\n",
    "    size_MB = round(size/1024/1024,2)\n",
    "\n",
    "    print(\"Image File Size is \" + str(size_MB) + \"MB\" )\n",
    "\n",
    "\n",
    "def rescale_image(img: np.ndarray, max_size: int=512) -> np.ndarray:\n",
    "    h, w, c = img.shape\n",
    "    scale = min([max_size/h, max_size/w])\n",
    "    output_size = int(scale*w), int(scale*h)\n",
    "    \n",
    "    return cv2.resize(img, output_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "def create_image_thumbnail(image_path, output_dir, max_size: int, ext: str=\"jpg\"):\n",
    "    \n",
    "    # img = cv2.imread(image_path)\n",
    "    file_path = os.path.join(output_dir, Path(image_path).stem + f\".{ext}\")\n",
    "\n",
    "    if (not os.path.isfile(file_path)):\n",
    "    \n",
    "        img, error = load_image(file_path=image_path,\n",
    "                                mode=\"BGR\", backend=\"PIL\")\n",
    "        img = rescale_image(img=img, max_size=max_size)\n",
    "        cv2.imwrite(file_path, img, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "    \n",
    "    return {\"source_path\":image_path,\n",
    "            \"target_path\":file_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f345106-c72d-431f-acb9-7ebf544561ff",
   "metadata": {},
   "source": [
    "## Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2beb894-8492-4a40-a8f7-6e8cc235d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame({'percentage': abs(np.random.normal(loc=50, scale=30, size=100)),\n",
    "#                    'var1': np.random.rand(100),\n",
    "#                    'var2': np.random.rand(100),\n",
    "#                    'var3': np.random.rand(100)})\n",
    "\n",
    "# # Find out percentiles\n",
    "# lower = np.percentile(df['percentage'], 10)\n",
    "# upper = np.percentile(df['percentage'], 90)\n",
    "\n",
    "# # Select data between\n",
    "# trimmed = df[df.percentage.between(lower, upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be1aaa-0c35-46c4-96f6-8b722d2e249e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mamba install -q -y -c pyviz panel\n",
    "# import panel as pn\n",
    "# pn.extension()\n",
    "\n",
    "\n",
    "# # n_jobs = 16\n",
    "\n",
    "# if os.path.exists(parquet_file_path):\n",
    "#     print(f\"Found pre-computed image statistics analysis, skipping expensive parallel processing job & loading from disk\")\n",
    "#     analysis_df = pd.read_parquet(parquet_file_path)\n",
    "    \n",
    "# else:\n",
    "#     yale_file_list = extract_file_list_from_directory(parent_dir=yale_fossil_dir)\n",
    "#     yale_file_info_list = extract_file_ids_from_file_list(fpaths=yale_file_list)\n",
    "#     yale_info_df = make_file_info_dataframe(file_info=yale_file_info_list)\n",
    "#     df = yale_info_df\n",
    "\n",
    "#     total_rows = df.shape[0]\n",
    "#     file_paths = df[\"paths\"].values\n",
    "\n",
    "#     analysis_records = Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "#         delayed(analyze_image_from_file)(\n",
    "#             path) for path in tqdm(file_paths, total=total_rows)\n",
    "#     )\n",
    "\n",
    "#     analysis_df = pd.DataFrame.from_records(analysis_records)\n",
    "\n",
    "\n",
    "# analysis_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544d5ed-2410-4a6f-94b2-b20086b2b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = \"/dev/shm\"\n",
    "\n",
    "thumbnail_resolution = 512\n",
    "\n",
    "thumbnail_dir = os.path.join(tmp_dir, f\"jrose3/2022-yale_fossils/image_thumbnails/res={thumbnail_resolution}\")\n",
    "os.makedirs(thumbnail_dir, exist_ok=True)\n",
    "\n",
    "# sample_path = '/media/data_cifs/projects/prj_fossils/data/yale_full/urn:uuid:000012b6-2c07-4df6-941c-8f2d0915391c.png'\n",
    "# sample_thumbnail_path = os.path.join(thumbnail_dir, \"urn:uuid:000012b6-2c07-4df6-941c-8f2d0915391c.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e68db8-7686-4dfe-b7e4-5dab53c7f45e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pqdm.threads import pqdm\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "copy_img_func = partial(create_image_thumbnail,\n",
    "                        output_dir=thumbnail_dir,\n",
    "                        max_size=thumbnail_resolution,\n",
    "                        ext=\"jpg\")\n",
    "\n",
    "source_paths = df.path.values.tolist()\n",
    "n_jobs = 8\n",
    "inputs = source_paths\n",
    "\n",
    "thumbnail_file_paths = pqdm(inputs, copy_img_func, n_jobs=n_jobs)\n",
    "# errors = [p for p in thumbnail_file_paths if not isinstance(p, dict)]\n",
    "\n",
    "errors = [not isinstance(p, dict) for p in thumbnail_file_paths]\n",
    "errors_idx = np.where(errors)\n",
    "df.iloc[errors_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec3071-1f74-4ff5-87fc-efee7badd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail_df = pd.DataFrame.from_records(thumbnail_file_paths).rename(columns={\"source_path\":\"path\",\n",
    "                                                                               \"target_path\":\"thumb_path\"}\n",
    "                                                                     )\n",
    "df = df.merge(thumbnail_df, on=\"path\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc05b7b-62e4-438f-9c07-25f60bc2e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence_catalog.info()\n",
    "# multimedia_catalog.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f320ef93-9f97-4046-af80-d0331374f26f",
   "metadata": {},
   "source": [
    "## Remove low value columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4087b-6934-4563-9bd1-bdadc4207995",
   "metadata": {},
   "source": [
    "### Drop columns with all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe22c8-5497-4ed7-9771-eef99065895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(occurrence_catalog.columns)\n",
    "null_cols = occurrence_catalog.isnull().sum().sort_values(ascending=False)\n",
    "null_cols2drop_all = null_cols[null_cols == len(occurrence_catalog)].index\n",
    "null_cols2drop_all\n",
    "\n",
    "occurrence_catalog = occurrence_catalog.drop(columns=null_cols2drop_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b1c08-f264-4387-817b-6f73a8471648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dropping {len(null_cols2drop_all)} cols out of {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdf43b-63b2-4496-a8c4-a8d6d5577918",
   "metadata": {},
   "source": [
    "### Drop columns with more than `73,000` null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae2aaf-5c89-4897-bbfd-4ae3dc369752",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(occurrence_catalog.columns)\n",
    "null_cols = occurrence_catalog.isnull().sum().sort_values(ascending=False)\n",
    "null_cols2drop_threshold = null_cols[null_cols > 73000].index\n",
    "null_cols2drop_threshold\n",
    "occurrence_catalog = occurrence_catalog.drop(columns=null_cols2drop_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb244f4-65c6-4f1e-8c41-1b5036d71de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols = len(occurrence_catalog.columns)\n",
    "print(f\"Dropping {len(null_cols2drop_threshold)} cols out of {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91e02a-1a12-4410-9e11-7e4fd08a23b6",
   "metadata": {},
   "source": [
    "### Drop columns with fewer than 5 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707e5a2-cddf-4672-9cca-aa1b0eb6084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(occurrence_catalog.columns)\n",
    "col_cardinalities = occurrence_catalog.nunique().sort_values()\n",
    "low_cardinality_cols = col_cardinalities[col_cardinalities <= 5].index\n",
    "low_cardinality_cols\n",
    "\n",
    "occurrence_catalog = occurrence_catalog.drop(columns=low_cardinality_cols)\n",
    "\n",
    "\n",
    "print(f\"Dropping {len(low_cardinality_cols)} cols out of {num_cols}\")\n",
    "occurrence_catalog.info()\n",
    "occurrence_catalog.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291bf76-821f-4c7b-8942-0f1b88cc5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(occurrence_catalog.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a7599-61a1-48a5-a5be-fe1e3e6890b6",
   "metadata": {},
   "source": [
    "### Merge our 16,444 rows of image file info with our more comprehensive occurrence catalog with 40 remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe6a9b-cdc6-4fcd-b4a1-e8fb91928927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe(include='all')\n",
    "# multimedia_catalog.describe(include='all')\n",
    "multimedia_catalog.columns\n",
    "\n",
    "intermediate_df = df.merge(multimedia_catalog[['id', 'identifier']], on=\"identifier\") #.describe(include='all')\n",
    "\n",
    "intermediate_df = intermediate_df.merge(occurrence_catalog, on=\"id\") #.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e48d3-d585-4dcf-a435-16434f923e2b",
   "metadata": {},
   "source": [
    "### Manually drop 2 more columns based on low value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f62f18-1591-44a1-89c2-9d07d06d9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cols2drop = [\n",
    "    'eventDate',\n",
    "    'year'\n",
    "]\n",
    "num_cols = len(intermediate_df.columns)\n",
    "intermediate_df = intermediate_df.drop(columns=custom_cols2drop)\n",
    "print(f\"Dropping {len(custom_cols2drop)} cols out of {num_cols}\")\n",
    "\n",
    "\n",
    "intermediate_df.info()\n",
    "intermediate_df.describe(include='all')\n",
    "intermediate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17fd9e-05b4-42da-87b6-4c5beefa70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_cols = [\n",
    "    'thumb_path',\n",
    "    'path',\n",
    "    'r', 'g', 'b',\n",
    "    'h', 's', 'v',\n",
    "    'height', \n",
    "    'width', \n",
    "    'aspect_ratio',\n",
    "    'kingdom', 'phylum', 'class', 'order', 'family',\n",
    "    'genus', 'specificEpithet', 'taxonRank', 'vernacularName',\n",
    "    'continent', 'country', 'stateProvince', 'county', 'municipality', 'locality',\n",
    "    'higherGeography', 'formation', 'scientificName', 'higherClassification',\n",
    "    'earliestPeriodOrLowestSystem', 'earliestEpochOrLowestSeries', 'earliestAgeOrLowestStage',\n",
    "    'bibliographicCitation', \n",
    "    'references', \n",
    "    'decimalLatitude', 'decimalLongitude', 'coordinateUncertaintyInMeters',\n",
    "    'occurrenceID', \n",
    "    'catalogNumber', \n",
    "    'occurrenceRemarks', \n",
    "    'recordedBy',\n",
    "    'identifier', 'id',\n",
    "    'modified',\n",
    "    'previousIdentifications',\n",
    "    'georeferencedBy', 'georeferencedDate', 'georeferenceSources',\n",
    "    'dynamicProperties',\n",
    "    'error'\n",
    "    ]\n",
    "\n",
    "df = intermediate_df[final_clean_cols]\n",
    "df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a6451-f830-4d98-8b1f-ed6b0cd183e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed32b6-dbb4-422f-9175-0cd3f327c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results\"\n",
    "results_filename = \"02a_rich_metadata_full_catalog\"\n",
    "\n",
    "parquet_dir = os.path.join(analysis_results_root_dir, \"parquet\")\n",
    "parquet_file_path = os.path.join(parquet_dir, f\"{results_filename}.parquet\")\n",
    "\n",
    "csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(parquet_file_path):\n",
    "    print(f\"Skipping write to parquet after finding pre-existing parquet file at: {parquet_file_path}\" + \"\\n\" + \"Manually delete pre-existing parquet file in order to allow write operation.\")\n",
    "else:\n",
    "    os.makedirs(parquet_dir, exist_ok=True)\n",
    "    df.to_parquet(parquet_file_path)\n",
    "\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    print(f\"Skipping write to csv after finding pre-existing csv file at: {csv_file_path}\" + \"\\n\" + \"Manually delete pre-existing csv file in order to allow write operation.\")\n",
    "else:\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "    df.to_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d939cfd-b2b9-44ef-91d6-6c2f21403c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# intermediate_df[['decimalLatitude', 'decimalLongitude']].plot(kind=\"hist\", x='decimalLatitude', y='decimalLongitude')\n",
    "# sns.histplot(stat=\"density\",x='decimalLatitude', y='decimalLongitude', data=intermediate_df[['decimalLatitude', 'decimalLongitude']])\n",
    "# intermediate_df[['decimalLatitude', 'decimalLongitude', \"coordinateUncertaintyInMeters\"]].isna().sum()\n",
    "# intermediate_df.describe(include='all')\n",
    "# intermediate_df.columns\n",
    "\n",
    "\n",
    "# occurrence_catalog.georeferenceProtocol.value_counts()\n",
    "# occurrence_catalog.georeferenceSources.value_counts()\n",
    "# occurrence_catalog.geodeticDatum.value_counts()\n",
    "# occurrence_catalog.disposition.value_counts()\n",
    "# occurrence_catalog.continent.value_counts()\n",
    "\n",
    "# print(len(occurrence_catalog.columns))\n",
    "# occurrence_catalog.describe(include='all')\n",
    "\n",
    "# sns.heatmap(occurrence_catalog.isnull(), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c084ae-8774-4423-ade2-a161cdd560ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\n",
    "#     'thumb_path',\n",
    "#     'path',\n",
    "#     'r',\n",
    "#     'g',\n",
    "#     'b',\n",
    "#     'h',\n",
    "#     's',\n",
    "#     'v',\n",
    "#     'height',\n",
    "#     'width',\n",
    "#     'aspect_ratio',\n",
    "#     'error',\n",
    "#     'identifier'\n",
    "# ]\n",
    "\n",
    "# df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f5a13-15d7-45f4-9d1c-9ba4828197d5",
   "metadata": {},
   "source": [
    "## Embed Images in a mk.DataPanel & cache to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4c88f-3907-42b0-bd7e-b7a8412bc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meerkat as mk\n",
    "\n",
    "dp = mk.DataPanel.from_pandas(df)\n",
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c868ba6-72e6-4597-9397-9e3f183e48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dp[\"thumbnail\"] = mk.ImageColumn.from_filepaths(dp[\"thumb_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c277823a-092b-4241-bab1-2b5a237ed023",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cols = [\n",
    "    'thumbnail',\n",
    "    'thumb_path',\n",
    "    'path',\n",
    "    'r',\n",
    "    'g',\n",
    "    'b',\n",
    "    'h',\n",
    "    's',\n",
    "    'v',\n",
    "    'height',\n",
    "    'width',\n",
    "    'aspect_ratio',\n",
    "    'kingdom',\n",
    "    'phylum',\n",
    "    'class',\n",
    "    'order',\n",
    "    'family',\n",
    "    'genus',\n",
    "    'specificEpithet',\n",
    "    'taxonRank',\n",
    "    'vernacularName',\n",
    "    'continent',\n",
    "    'country',\n",
    "    'stateProvince',\n",
    "    'county',\n",
    "    'municipality',\n",
    "    'locality',\n",
    "    'higherGeography',\n",
    "    'formation',\n",
    "    'scientificName',\n",
    "    'higherClassification',\n",
    "    'earliestPeriodOrLowestSystem',\n",
    "    'earliestEpochOrLowestSeries',\n",
    "    'earliestAgeOrLowestStage',\n",
    "    'bibliographicCitation',\n",
    "    'references',\n",
    "    'decimalLatitude',\n",
    "    'decimalLongitude',\n",
    "    'coordinateUncertaintyInMeters',\n",
    "    'occurrenceID',\n",
    "    'catalogNumber',\n",
    "    'occurrenceRemarks',\n",
    "    'recordedBy',\n",
    "    'identifier',\n",
    "    'id',\n",
    "    'modified',\n",
    "    'previousIdentifications',\n",
    "    'georeferencedBy',\n",
    "    'georeferencedDate',\n",
    "    'georeferenceSources',\n",
    "    'dynamicProperties',\n",
    "    'error']\n",
    "\n",
    "dp = dp[analysis_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e21e43-6f05-47ce-bbf5-3fe1052648f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results/02b_rich_metadata_embedded_images_meerkat_datapanel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47685681-35ec-40dd-bb99-13b32ea18144",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results\"\n",
    "\n",
    "meerkat_dir = os.path.join(analysis_results_root_dir, \"meerkat\")\n",
    "embedded_images_meerkat_datapanel_filename = \"02b_rich_metadata_embedded_images_meerkat_datapanel\"\n",
    "\n",
    "mk_datapanel_path = os.path.join(meerkat_dir, embedded_images_meerkat_datapanel_filename)\n",
    "\n",
    "dp.write(mk_datapanel_path)\n",
    "########### Fully formatted datapanel can now be reloaded in another notebook by uncommenting the following:\n",
    "# reloaded_dp = mk.DataPanel.read(mk_datapanel_path)\n",
    "# reloaded_dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1052a-d8ff-4b2a-ac61-0e8e6ffc8427",
   "metadata": {},
   "source": [
    "## Sort by HSV value `v` and browse images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d80445-4f2a-4425-918f-ce176918a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dp.to_pandas()\n",
    "df = df.sort_values(\n",
    "    \"v\",\n",
    "    ascending=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "sorted_dp = mk.DataPanel.from_pandas(df)\n",
    "\n",
    "sorted_dp[\"thumbnail\"] = mk.ImageColumn.from_filepaths(sorted_dp[\"thumb_path\"])\n",
    "sorted_dp = sorted_dp[analysis_cols]\n",
    "sorted_dp.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f305341-f217-4b9c-9e03-4bf5e803a1f0",
   "metadata": {},
   "source": [
    "## Sort by HSV saturation `s` and browse images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690f661-e103-40ae-96c6-9f8ca910efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dp.to_pandas()\n",
    "df = df.sort_values(\n",
    "    \"s\",\n",
    "    ascending=False,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "sorted_dp = mk.DataPanel.from_pandas(df)\n",
    "\n",
    "sorted_dp[\"thumbnail\"] = mk.ImageColumn.from_filepaths(sorted_dp[\"thumb_path\"])\n",
    "sorted_dp = sorted_dp[analysis_cols]\n",
    "sorted_dp.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298d684-7829-4147-bb5e-2cf0d798ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dp.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3b755-cfac-45b7-a13b-fefa6ca1ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8085db4b-6d37-46d3-b006-6c6d0028fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "n_jobs = 16\n",
    "thumbnail_file_paths = Parallel(n_jobs=n_jobs)(delayed(copy_img_func)(path) for path in source_paths)\n",
    "\n",
    "%%time\n",
    "\n",
    "file_path = create_image_thumbnail(image_path=sample_path,\n",
    "                                   output_dir=thumbnail_dir,\n",
    "                                   max_size=thumbnail_resolution,\n",
    "                                   ext=\"jpg\")\n",
    "\n",
    "\n",
    "\n",
    "print(os.path.isfile(file_path))\n",
    "\n",
    "print_file_size(sample_path)\n",
    "print_file_size(file_path)\n",
    "\n",
    "# image_path = sample_path\n",
    "# max_size = thumbnail_resolution\n",
    "\n",
    "import time\n",
    "\n",
    "from random import randrange\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def func_call(position, total):\n",
    "    text = 'progressbar #{position}'.format(position=position)\n",
    "    with  tqdm(total=total, position=position, desc=text) as progress:\n",
    "        for _ in range(0, total, 5):\n",
    "            progress.update(5)\n",
    "            time.sleep(randrange(3))\n",
    "\n",
    "\n",
    "pool = ThreadPool(10)\n",
    "tasks = range(5)\n",
    "for i, url in enumerate(tasks, 1):\n",
    "    pool.apply_async(func_call, args=(i, 100))\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f64bed-7183-4ce4-866c-0a0bcaaec8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a8dda4-1802-4b15-8650-bc5df083cc7d",
   "metadata": {},
   "source": [
    "## Seaborn image attributes facet grid plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585130e-dd6b-4570-b927-87e990861683",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df[[\"r\",\"g\",\"b\", \"h\", \"s\", \"v\"]])#, hue=\"species\")\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4229c-bf72-48a2-9e56-7a71220484cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.despine(f)\n",
    "sns.kdeplot(df[\"h\"], shade=True)\n",
    "sns.kdeplot(df[\"s\"], shade=True)\n",
    "sns.kdeplot(df[\"v\"], shade=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45c3fd-d25b-47cf-8954-8b858fa6e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.merge(multimedia_catalog, on=\"identifier\")\n",
    "full_df = full_df.merge(occurrence_catalog, on=\"id\")\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f2d24-ddf7-4f91-8c30-7759fe9d7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "full_df.shape\n",
    "multimedia_catalog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c19c8-896d-4c28-abf9-1d6e8c572761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.apply(lambda x: x.identifier not in full_df.identifier.values, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33fc5d-4bb9-4ad7-8476-be752e5d8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_df = multimedia_catalog[multimedia_catalog.apply(lambda x: x.identifier not in full_df.identifier.values, axis=1)]\n",
    "\n",
    "# from PIL import Image\n",
    "# import requests\n",
    "# import IPython\n",
    "\n",
    "\n",
    "# def load_remote_image(url):\n",
    "#     # return Image.open(requests.get(url, stream=True).raw)\n",
    "#     try:\n",
    "#         return IPython.display.Image(url, width = 250)\n",
    "#     except:\n",
    "#         return \"Image not found\"\n",
    "\n",
    "\n",
    "\n",
    "# # url = 'https://newevolutiondesigns.com/images/freebies/colorful-background-14.jpg'\n",
    "# # IPython.display.Image(url, width = 250)\n",
    "\n",
    "# img_col = missing_df.assign(img = missing_df.accessURI.apply(load_remote_image))\n",
    "# img_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b871f0-33a0-46a1-b786-b4dc7a8628cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939cb70-10b6-4a56-a7de-4765499d1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\n",
    "    \"v\",\n",
    "    ascending=True, # False,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c15c5-276d-45ae-8caa-a4d7e663866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0.0, 0.25, 0.5, 0.75, 1.0] #[:-1]\n",
    "\n",
    "df[\"quantiles\"], o_bins = pd.qcut(\n",
    "    df[\"v\"],\n",
    "    len(bins),\n",
    "    labels=bins,\n",
    "    precision=2,\n",
    "    retbins=True\n",
    ")\n",
    "\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3d149-c805-45bd-b9d2-c50968cdfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_idx = df.groupby(\"quantiles\")[\"v\"].nlargest(10).reset_index(level=0).index\n",
    "smallest_idx = df.groupby(\"quantiles\")[\"v\"].nsmallest(10).reset_index(level=0).index\n",
    "\n",
    "\n",
    "largest_idx\n",
    "smallest_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f690d98-8514-4ca2-8182-4f56c9ce3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bd075-567b-4f97-9bab-afb8e8b8e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest = df.loc[smallest_idx,:]\n",
    "largest = df.loc[largest_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b4ea4-912a-4917-997a-3a85d73967cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i, paths, quantiles, v_list = [\n",
    "    list(c) for c in unzip(\n",
    "        smallest[[\"path\", \"quantiles\", \"v\"]].to_records()\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# i, paths, quantiles, v_list = [\n",
    "#     list(c) for c in unzip(\n",
    "#         largest[[\"path\", \"quantiles\", \"v\"]].to_records()\n",
    "#     )\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ca72f-9c91-4270-a858-f2e849909878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f0d38-6ab6-401d-a955-6adcbd32927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ce2d0-8642-49bc-9784-37c36167f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs_order=sorted(set(quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90881c7-e920-474c-9644-70fb0bdd1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs_order\n",
    "\n",
    "\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846f33c-3e24-49b9-b0a7-1ffc7b01b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot.plot_class_tabs(paths,\n",
    "                        labels=[f\"{q:.2%}\" for q in quantiles],\n",
    "                        custom_texts=[f\"{v=}\" for v in v_list],\n",
    "                        tabs_order=np.sort(list(set(quantiles)))\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe65e5e-1495-43e8-a5c7-45e2691a0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df.to_records()\n",
    "records\n",
    "\n",
    "records[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e39418-82f2-47b9-aeed-e6f638352471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ec8c2-7a10-47f4-85bf-3cb3b1c3856b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa381803-78cd-4545-b248-79172aad4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot.plot_class_tabs\n",
    "\n",
    "ipyplot.plot_class_tabs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5d1b6-8908-4071-9d49-3b1785de68ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d0794-4953-4269-b945-2c721f916147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ec031-2df9-437b-b392-9b4a6b86db46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af79ef-308d-4c46-9dde-6538cfea93f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd6a85-d7bd-4244-a680-8c3ed5be506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b482-52c7-4fe3-8fd4-13908b8a4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def generate_file_path_dataframe_fixture() -> pd.DataFrame:\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [2768571, 130655, 1155027, 34713051, 331002277],\n",
    "            [1448753, 60632, 790040, 3070447, 212558178],\n",
    "            [654405, 9536, 422931, 19852167, 145934619],\n",
    "            [605216, 17848, 359891, 8826585, 1379974505],\n",
    "            [288477, 9860, 178245, 1699369, 32969875]\n",
    "        ],\n",
    "        columns = ['Total Cases', 'Total Deaths', 'Total Recovered', 'Total Tests', 'Population']\n",
    "    )\n",
    "\n",
    "    df['Country'] = [\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-United-States-of-America.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Brazil.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Russia.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-India.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Peru.png'\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def path_to_image_html(path: str,\n",
    "                       width: int=128):\n",
    "    return f'<img src=\"{path}\" width=\"{width}\" >'\n",
    "\n",
    "\n",
    "def display_image_df(df: pd.DataFrame,\n",
    "                     formatters: Dict[str,Callable]\n",
    "                    ):\n",
    "    return HTML(\n",
    "        df.to_html(\n",
    "            escape=False,\n",
    "            formatters=formatters\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993b9f8-07d3-46bf-9377-8f81105d5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42da24d-f602-4efa-8a71-d151bc67ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatters = {\n",
    "    \"img\": \n",
    "    partial(\n",
    "        path_to_image_html#, width-50\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_html = display_image_df(\n",
    "    df=df.assign(img=df.path.values),\n",
    "    formatters=formatters\n",
    ")\n",
    "df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e515ca7-ed14-49b2-9d0e-ae62764fa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering the dataframe as HTML table\n",
    "# df.to_html(escape=False, formatters=dict(Country=path_to_image_html))\n",
    "\n",
    "\n",
    "# Rendering the images in the dataframe using the HTML method.\n",
    "# HTML(df.to_html(escape=False,formatters=dict(Country=path_to_image_html)))\n",
    "\n",
    "\n",
    "\n",
    "# Saving the dataframe as a webpage\n",
    "# df.to_html('webpage.html',escape=False, formatters=dict(Country=path_to_image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738d45c-eaa6-4475-8512-49ec2388436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97e4b5-e02e-4869-8593-91a68a5a5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2665c61-75be-4fa4-8c28-a3db1dd28f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb8d9d-5d07-48a8-b41b-e04a32772db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720d4b8-b66b-4753-bb5c-3a26d9495a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964db28-ddc8-475f-86f2-77e8a0c118c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut?\n",
    "\n",
    "dir(df.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae028fa3-126c-4bcf-955c-fe4ddee38011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install ipyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222029b-1092-4d69-8dd9-36c18b579888",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ipyplot)\n",
    "\n",
    "ipyplot.plot_images?\n",
    "\n",
    "ipyplot.plot_class_representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd3630-d72c-45cf-9a44-eb462b1cf7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brightness = df.sort_values(by=\"v\",\n",
    "                               ascending=False,\n",
    "                               ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2547485-5316-4f6e-8620-2f529f4c67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_brightness = df_brightness.assign(imgs = df_brightness.path.apply(PIL.Image.open))\n",
    "\n",
    "df_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799941e-a978-4cc7-b161-44eacbc86a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0634a86-8252-4d5a-840b-fc3dbca375d9",
   "metadata": {},
   "source": [
    "### pd.DataFrame function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6fe76-ffd4-45f9-a321-0840a1a8f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from typing import *\n",
    "# fpaths = {}\n",
    "# dps = {}\n",
    "\n",
    "def extract_file_list_from_directory(parent_dir) -> List[str]:\n",
    "    \n",
    "    blacklist = [\".ipynb_checkpoints\"]\n",
    "    return sorted([os.path.join(parent_dir, p) for p in os.listdir(parent_dir) if p not in blacklist])\n",
    "\n",
    "\n",
    "def extract_file_ids_from_file_list(fpaths: List[str]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"paths\" : fpaths,\n",
    "        \"file_ids\" : [Path(p).stem for p in fpaths]\n",
    "    }\n",
    "\n",
    "\n",
    "def make_file_info_dataframe(file_info: Dict[str, Any], **kwargs) -> pd.DataFrame:\n",
    "    return pd.DataFrame(file_info, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739e4ba-df0a-41ae-94c0-ef26dd346981",
   "metadata": {},
   "source": [
    "### Image stats analysis function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650bc2d-d562-4c7e-9078-a86da85c4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_img_shape(img: PIL.Image.Image) -> Tuple:\n",
    "    # img = PIL.Image.open(path)\n",
    "    h, w = img.height, img.width\n",
    "    ratio = h/w\n",
    "    return {\n",
    "        \"height\": h, \n",
    "        \"width\": w,\n",
    "        \"aspect_ratio\": ratio\n",
    "    }\n",
    "\n",
    "\n",
    "def calc_rgb_stats(img: PIL.Image.Image) -> Tuple:\n",
    "    r, g, b = Stat(img).mean\n",
    "    return {\n",
    "        \"r\": r,\n",
    "        \"g\": g,\n",
    "        \"b\": b\n",
    "    }\n",
    "\n",
    "\n",
    "def calc_hsv_stats(img: PIL.Image.Image) -> Tuple:\n",
    "    img = img.convert(\"HSV\")\n",
    "    h, s, v = Stat(img).mean\n",
    "    return {\n",
    "        \"h\": h,\n",
    "        \"s\": s,\n",
    "        \"v\": v\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_image_from_file(path: str):\n",
    "\n",
    "    img, error = load_image(path, \n",
    "                            mode=\"RGB\",\n",
    "                            backend=\"PIL\",\n",
    "                            lazy_load=False)\n",
    "    \n",
    "    return {\n",
    "        \"path\": path,\n",
    "        **calc_img_shape(img),\n",
    "        **calc_rgb_stats(img),\n",
    "        **calc_hsv_stats(img),\n",
    "        \"error\": error\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea6f1f-0ce1-4d92-a323-8a1de424b453",
   "metadata": {},
   "source": [
    "## Main: Process images or load previous results from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a58c1-fa0d-4f18-9afe-bc53fb51c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yale_fossil_dir = \"/media/data_cifs/projects/prj_fossils/data/yale_full\"\n",
    "\n",
    "# analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results/\"\n",
    "# results_filename = \"image_stats_df\"\n",
    "\n",
    "# parquet_dir = os.path.join(analysis_results_root_dir, \"parquet\")\n",
    "# parquet_file_path = os.path.join(parquet_dir, f\"{results_filename}.parquet\")\n",
    "\n",
    "# csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "# csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")\n",
    "\n",
    "# # n_jobs = 16\n",
    "\n",
    "# if os.path.exists(parquet_file_path):\n",
    "#     print(f\"Found pre-computed image statistics analysis, skipping expensive parallel processing job & loading from disk\")\n",
    "#     analysis_df = pd.read_parquet(parquet_file_path)\n",
    "    \n",
    "# else:\n",
    "#     yale_file_list = extract_file_list_from_directory(parent_dir=yale_fossil_dir)\n",
    "#     yale_file_info_list = extract_file_ids_from_file_list(fpaths=yale_file_list)\n",
    "#     yale_info_df = make_file_info_dataframe(file_info=yale_file_info_list)\n",
    "#     df = yale_info_df\n",
    "\n",
    "#     total_rows = df.shape[0]\n",
    "#     file_paths = df[\"paths\"].values\n",
    "\n",
    "#     analysis_records = Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "#         delayed(analyze_image_from_file)(\n",
    "#             path) for path in tqdm(file_paths, total=total_rows)\n",
    "#     )\n",
    "\n",
    "#     analysis_df = pd.DataFrame.from_records(analysis_records)\n",
    "\n",
    "\n",
    "# analysis_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66a63c-e238-49dd-9b73-3c154359a208",
   "metadata": {},
   "source": [
    "### Output any new analysis to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93537b5a-d434-43d8-a10b-fc9f9b19a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results/\"\n",
    "# results_filename = \"image_stats_df\"\n",
    "\n",
    "# parquet_dir = os.path.join(analysis_results_root_dir, \"parquet\")\n",
    "# parquet_file_path = os.path.join(parquet_dir, f\"{results_filename}.parquet\")\n",
    "\n",
    "# csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "# csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf13932-d485-4210-9e81-8e0e622c4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# parquet_dir = os.path.join(analysis_results_root_dir, \"parquet\")\n",
    "# parquet_file_path = os.path.join(parquet_dir, f\"{results_filename}.parquet\")\n",
    "\n",
    "# csv_dir = os.path.join(analysis_results_root_dir, \"csv\")\n",
    "# csv_file_path = os.path.join(csv_dir, f\"{results_filename}.csv\")\n",
    "\n",
    "\n",
    "if os.path.exists(parquet_file_path):\n",
    "    print(f\"Skipping write to parquet after finding pre-existing parquet file at: {parquet_file_path}\" + \"\\n\" + \"Manually delete pre-existing parquet file in order to allow write operation.\")\n",
    "else:\n",
    "    os.makedirs(parquet_dir, exist_ok=True)\n",
    "    analysis_df.to_parquet(parquet_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    print(f\"Skipping write to csv after finding pre-existing csv file at: {csv_file_path}\" + \"\\n\" + \"Manually delete pre-existing csv file in order to allow write operation.\")\n",
    "else:\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "    analysis_df.to_csv(csv_file_path)\n",
    "\n",
    "print(f\"Finished analysis results can be found at either:\")\n",
    "print(parquet_file_path)\n",
    "print(\"or\")\n",
    "print(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba084aa-b72e-40e7-a71a-0e3804201337",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fc256-eacf-46d2-b9bc-ffc9142d59a6",
   "metadata": {},
   "source": [
    "### Misc analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfb2a5-1a26-4202-920e-51bd6c50a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "new_df = pd.read_parquet(parquet_file_path)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06d6cb-decd-4be7-9678-1e2cfe8402d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "new_df = pd.read_csv(\"data/csv/image_stats_df.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1aee6-0b1e-4f57-97ca-881294d65197",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4c448-045c-4192-a8dd-8d0a2ef8f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_types = analysis_df.value_counts(\"error\").to_dict().keys()\n",
    "\n",
    "for k in error_types:\n",
    "    print(k)\n",
    "    error_df = analysis_df[analysis_df.error==k]\n",
    "    error_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d562b-b251-4f6f-a3fc-856a47d2903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = \"image file is truncated (0 bytes not processed)\"\n",
    "analysis_df[analysis_df.error==k]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
