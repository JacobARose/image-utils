{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9119696f-234e-4e36-a174-ea857fd4bc1e",
   "metadata": {},
   "source": [
    "# 04_image deduplication through clustering -- 2022-09-21-unlabeled yale fossils dataset.ipynb\n",
    "\n",
    "Inputs: version 1 of the cleaned 2022 unlabeled yale fossils dataset, having identified & removed **irrelevant outlier images**\n",
    "\n",
    "Outputs: version 2 of the cleaned 2022 unlabeled yale fossils dataset, having identified & removed **duplicate images** as well\n",
    "\n",
    "Created by: Jacob A Rose  \n",
    "Created on: Tuesday September 20th, 2022  \n",
    "<!-- Updated on:  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc419e13-a5fb-438c-adda-78d76dcd4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install torchshow\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.float_format', \"{:,.2f}\".format)\n",
    "\n",
    "from rich import print as pp\n",
    "import meerkat as mk\n",
    "display_res = 1024\n",
    "# print(mk.config.DisplayOptions.max_image_width)\n",
    "mk.config.display.max_rows = 100\n",
    "mk.config.display.max_image_width = display_res\n",
    "mk.config.display.max_image_height = display_res\n",
    "\n",
    "# mk.config.DisplayOptions.max_rows = 100\n",
    "# mk.config.DisplayOptions.max_image_width = display_res\n",
    "# mk.config.DisplayOptions.max_image_height = display_res\n",
    "\n",
    "# print(f\"{mk.config.DisplayOptions.max_image_width=}\")\n",
    "print(\"mk.config.display=\")\n",
    "pp(dict(vars(mk.config.display)))\n",
    "\n",
    "mk.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8ef6a-8bdb-4ad2-8840-ecbd8993f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import inspect\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from PIL.ImageStat import Stat\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0514f0-a05e-4a82-b7c4-9090e9a1648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676214c-248f-4b10-9323-04d0b3994123",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486da293-95d6-48a5-9692-c40eb8aaeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def rescale_image(img: np.ndarray, max_size: int=512) -> np.ndarray:\n",
    "    h, w, c = img.shape\n",
    "    scale = min([max_size/h, max_size/w])\n",
    "    output_size = int(scale*w), int(scale*h)\n",
    "    \n",
    "    return cv2.resize(img, output_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def rescale_image_PIL(img: PIL.Image.Image, max_size: int=512) -> PIL.Image:\n",
    "    # print(img)\n",
    "    # img.load()\n",
    "    w, h = img.width, img.height\n",
    "    scale = max([max_size/w, max_size/h])\n",
    "    output_size = int(scale*w), int(scale*h)\n",
    "    \n",
    "    return img.resize(output_size, resample=PIL.Image.Resampling.BICUBIC)\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def hconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC):\n",
    "    h_min = min(im.shape[0] for im in im_list)\n",
    "    im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation)\n",
    "                      for im in im_list]\n",
    "    return cv2.hconcat(im_list_resize)\n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "def image_grid(image_paths, \n",
    "               col: int=5,\n",
    "               max_imgs: int=-1,\n",
    "               include_filenames_as_titles=False):\n",
    "    \n",
    "    if max_imgs > 0:\n",
    "        image_paths = image_paths[:max_imgs]\n",
    "    \n",
    "    image_count = len(image_paths)\n",
    "    row = math.ceil(image_count/col)\n",
    "    fig = plt.figure(figsize=(col*4,row*4))\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img_path = str(img_path)\n",
    "\n",
    "        img = plt.imread(img_path)\n",
    "\n",
    "        ax = plt.subplot(row, col, i + 1)\n",
    "        plt.imshow(img)\n",
    "        if include_filenames_as_titles:\n",
    "            plt.title(Path(img_path).name)\n",
    "\n",
    "        # ax.set_xticklabels([])\n",
    "        # ax.set_yticklabels([])\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, top=0.97)\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac315c90-041b-4a0b-bbb9-e4bd6dfcbe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty(path):\n",
    "    \"\"\"\n",
    "    Returns True if the input path is an empty directory, False if anything's in it. Throws an error if target isn't a directory.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return len(os.listdir(path)) == 0\n",
    "\n",
    "def get_version_from_path(path: str) -> int:\n",
    "    path = Path(path).stem\n",
    "    return int(path.split(\"_\")[1])\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_version(root_dir: str,\n",
    "                       skip_version_if_exists: bool=False) -> Path:\n",
    "    \"\"\"\n",
    "    \n",
    "    Input a root dir, and this function will either create & return a new subdir labeled \"version_0\", or it will find the latest created version that doesn't have any files in it.\n",
    "    \n",
    "    Should run once in an experiment & save in a variable if need to reference version elsewhere in script.\n",
    "    \n",
    "    root_dir: str\n",
    "        Location in which multiple version subdirs will be located (e.g. \"./version_{0,1,2,3...}\"\n",
    "    skip_version_if_exists: bool, default=False\n",
    "        If False, attempt to load previous annotations if found on disk. If True, always go to the next version number if version subdir is not empty.\n",
    "        By default, attempts to load previous annotations if they exist.\n",
    "    \n",
    "    \"\"\"\n",
    "    v = 0\n",
    "    if not is_empty(root_dir):\n",
    "        for d in sorted(os.listdir(root_dir)):\n",
    "            v = max([v, get_version_from_path(d)])\n",
    "            if (\n",
    "                skip_version_if_exists\n",
    "                and (not is_empty(Path(root_dir, d)))\n",
    "            ):\n",
    "                v = get_version_from_path(d) + 1\n",
    "\n",
    "    save_dir = Path(root_dir, f\"version_{v}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54639c-d9e1-4ed9-8b83-1f3aaa6134f4",
   "metadata": {},
   "source": [
    "### Functions for caching annotations\n",
    "\n",
    "* Functions to load (`load_cached_annotations` and save (`cache_annotations`) versioned catalogs of annotated/labeled datasets to iteratively work through a large set in many small increments.\n",
    "\n",
    "* Saves an `annotated_df` and a `non_annotated_df` containing the same columns, with the latter having NaN for all values of the `label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd9689-3c8b-4ce8-bab0-dd2df3dea751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "\n",
    "def cache_annotations(save_dir: str,\n",
    "                      annotated_df: pd.DataFrame,\n",
    "                      non_annotated_df: pd.DataFrame\n",
    "                     ) -> None:\n",
    "    \"\"\"\n",
    "    Save 2 different dataframes into a cache directory as parquet & csv files.\n",
    "    \n",
    "    The 1st contains only rows that have been manually annotated at least once.\n",
    "    The 2nd contains only rows that have never been annotated (indicated by a value of label==\"\")\n",
    "    \"\"\"\n",
    "    annotations_cache_dir = Path(save_dir, \"annotations_cache\")\n",
    "    os.makedirs(annotations_cache_dir, exist_ok=True)\n",
    "\n",
    "    annotated_df.to_parquet(annotations_cache_dir / f\"annotated.parquet\")\n",
    "    annotated_df.to_csv(annotations_cache_dir / f\"annotated.csv\")\n",
    "    annotated_df.describe(include='all').to_csv(annotations_cache_dir / \"annotated_summary.csv\")\n",
    "\n",
    "    non_annotated_df.to_parquet(annotations_cache_dir / f\"non_annotated.parquet\")\n",
    "    non_annotated_df.to_csv(annotations_cache_dir / f\"non_annotated.csv\")\n",
    "    non_annotated_df.describe(include='all').to_csv(annotations_cache_dir / \"non_annotated_summary.csv\")\n",
    "    \n",
    "    \n",
    "def load_cached_annotations(\n",
    "    save_dir: str\n",
    ") -> Tuple[Any]:\n",
    "    \"\"\"\n",
    "    Load 2 different dataframes from a cache directory from either parquet or csv files.\n",
    "    \n",
    "    The 1st contains only rows that have been manually annotated at least once.\n",
    "    The 2nd contains only rows that have never been annotated (indicated by a value of label==\"\")\n",
    "    \"\"\"\n",
    "    annotations_cache_dir = Path(save_dir, \"annotations_cache\")\n",
    "    if not os.path.isdir(annotations_cache_dir):\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(annotations_cache_dir / f\"annotated.parquet\"):\n",
    "        annotated_df = pd.read_parquet(annotations_cache_dir / f\"annotated.parquet\")\n",
    "    else:\n",
    "        annotated_df = pd.read_csv(annotations_cache_dir / f\"annotated.csv\", index_col=0)\n",
    "\n",
    "    if os.path.isfile(annotations_cache_dir / f\"non_annotated.parquet\"):\n",
    "        non_annotated_df = pd.read_parquet(annotations_cache_dir / f\"non_annotated.parquet\")\n",
    "    else:\n",
    "        non_annotated_df = pd.read_csv(annotations_cache_dir / f\"non_annotated.csv\", index_col=0)\n",
    "\n",
    "\n",
    "    return annotated_df, non_annotated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc2779-3506-4d4f-8b9b-bb97436a342f",
   "metadata": {},
   "source": [
    "## Specify & Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c5b6b-5d7a-4906-b393-78c03a929921",
   "metadata": {},
   "source": [
    "### Define key file info & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b1b58-3e4c-4f7a-9831-9be08cfc56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yale_fossil_dir = \"/media/data_cifs/projects/prj_fossils/data/yale_full\"\n",
    "\n",
    "analysis_results_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/analysis_results/\"\n",
    "results_filename = \"01_image_stats_df\"\n",
    "\n",
    "meerkat_dir = os.path.join(analysis_results_root_dir, \"meerkat\")\n",
    "meerkat_path = os.path.join(meerkat_dir, \"02b_rich_metadata_embedded_images_meerkat_datapanel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e0b4f-d0a6-4a1c-83e9-db10cc72ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/manual_annotations\"\n",
    "save_dir = get_latest_version(root_dir=annotations_dir)\n",
    "print(f\"Checking for cached annotations in {save_dir}\")\n",
    "pp(f'Loading from: {Path(save_dir).stem.replace(\"_\", \" \")}')\n",
    "# cache_annotations(save_dir=save_dir,\n",
    "#                   annotated_df=annotated_df,\n",
    "#                   non_annotated_df=non_annotated_df)\n",
    "\n",
    "\n",
    "annotated_df, non_annotated_df = load_cached_annotations(save_dir=save_dir)\n",
    "if (\n",
    "    isinstance(annotated_df, pd.DataFrame) \n",
    "    and isinstance(non_annotated_df, pd.DataFrame)\n",
    "):\n",
    "    df = pd.concat([\n",
    "        non_annotated_df, annotated_df\n",
    "    ])\n",
    "    dp = mk.DataPanel.from_pandas(df)\n",
    "    print(f\"Successfully loaded from cache\")\n",
    "else:\n",
    "    dp = mk.DataPanel.read(meerkat_path)\n",
    "    print(f\"No cache exists, loading raw data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569a96-2ba6-4e8b-b05c-16847e5284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.describe(include='all')\n",
    "non_annotated_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffde97-8d6f-4386-bb8d-5b6e322844e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dp.columns\n",
    "dp = dp.sort(by=\"v\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892580a9-85c2-48d4-8971-f453e584b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_record_cols = [\n",
    "    'thumbnail',\n",
    "    'thumb_path',\n",
    "    'path'\n",
    "]\n",
    "\n",
    "\n",
    "stats_cols = [    \n",
    "    # 'thumbnail',\n",
    "    'thumb_path',\n",
    "    'path',\n",
    "    'r',\n",
    "    'g',\n",
    "    'b',\n",
    "    'h',\n",
    "    's',\n",
    "    'v',\n",
    "    'height',\n",
    "    'width',\n",
    "    'aspect_ratio'\n",
    "]\n",
    "\n",
    "geo_cols = [\n",
    "    # 'thumbnail',\n",
    "    'thumb_path',\n",
    "    'path',\n",
    "    'kingdom',\n",
    "    'phylum',\n",
    "    'class',\n",
    "    'order',\n",
    "    'family',\n",
    "    'genus',\n",
    "    'specificEpithet',\n",
    "    'taxonRank',\n",
    "    'vernacularName',\n",
    "    'continent',\n",
    "    'country',\n",
    "    'stateProvince',\n",
    "    'county',\n",
    "    'municipality',\n",
    "    'locality'\n",
    "]\n",
    "\n",
    "column_groups = [\n",
    "    \"image_record_cols\",\n",
    "    \"stats_cols\",\n",
    "    \"geo_cols\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "options=[\n",
    "    'Fossil Leaf', \n",
    "    'Cleared Leaf',\n",
    "    'other', \n",
    "    'unknown',\n",
    "    ''\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54add9a3-d7b0-43d4-9a4d-432711a420a8",
   "metadata": {},
   "source": [
    "## Main Interface: Annotation Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3359b4-2926-4977-a34a-3c7a291730a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = non_annotated_df.sort_values(\"v\", ascending=False)\n",
    "\n",
    "pp(f\"Skipping a total of {len(annotated_df)} previously annotated samples distributed as follows:\")\n",
    "annotated_df.value_counts(\"label\")\n",
    "\n",
    "pp(f\"Beginning the continued annotation process on the remaining {len(non_annotated_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79819f40-b9ec-472c-9cab-95f48204d5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bf0ea-0eaf-43c5-a584-47be2cd00d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = \"/media/data_cifs/projects/prj_fossils/data/yale_full\"\n",
    "root_path = \"/dev/shm/jrose3/2022-yale_fossils/image_thumbnails/res=512\"\n",
    "\n",
    "paths = [Path(root_path, p) for p in os.listdir(root_path)]\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a2d703-51a2-4fd4-a35e-d94d8264d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from difPy import dif\n",
    "# search = dif(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b94fe7-3027-4547-bdf8-ec7dfd4d8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff276b71-014d-47e0-bdb8-08918fff9c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156c30b-d1ef-4c59-832f-876d9cd5f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fn(filename: str, **kwargs):\n",
    "    f = open(filename, \"rb\").read()\n",
    "    return Image(value=f, format=Path(filename).suffix.strip(\".\"), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7447f-4697-4a50-ba53-6b4888cf8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.value_counts(\"label\")\n",
    "# import pandas as pd\n",
    "# import pigeonXT as pixt\n",
    "\n",
    "from IPython.display import display#, Image\n",
    "from ipywidgets import Image\n",
    "\n",
    "# df = dp.to_pandas()\n",
    "# df.index.name = \"idx\"\n",
    "# df = df.reset_index()\n",
    "\n",
    "# ddf = annotated_df\n",
    "# ddf.columns\n",
    "# ddf.value_counts('label')\n",
    "# ddf.value_counts('aspect_ratio')\n",
    "# non_annotated_df.value_counts('aspect_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c32bf-41cc-4c3a-95ec-b107b54f60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.histplot(non_annotated_df, x='aspect_ratio')\n",
    "# sns.histplot(annotated_df, x='aspect_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b99d12-b9e4-437a-890c-a46a5f8abbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([annotated_df, non_annotated_df])\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d48d79-489e-4972-8be1-c5cf4746f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df, x='stateProvince', kde=True)\n",
    "\n",
    "# rb_df = df.sort_values(\"recordedBy\")\n",
    "# rb_df.value_counts(\"recordedBy\")\n",
    "\n",
    "# import ipyplot\n",
    "# ipyplot.plot_class_representations(images, labels, img_width=150)\n",
    "# rb_df.columns\n",
    "\n",
    "# images = rb_df.thumb_path.values.tolist()\n",
    "# labels = rb_df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577f533-d4bf-4349-a778-f1d9f4d3a260",
   "metadata": {},
   "source": [
    "# I. EDA & metadata-guided analysis based on `recordedBy` and `country` columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9987e7-058e-40b3-9497-a74b35cc0d25",
   "metadata": {},
   "source": [
    "## Inspect `recordedBy` column\n",
    "\n",
    "    * Sort df by value of `recordedBy` column\n",
    "\n",
    "### A. Create na-contribution, single-contribution & multi-contribution partitions of the dataset\n",
    "- by dividing samples between  \n",
    "    i. those with NaN values for `recordedBy`  \n",
    "    ii. those from contributors with only 1 included specimen  \n",
    "    iii. and those from contributors with 2 or more,  \n",
    "respectively.\n",
    "\n",
    "* **Goal**: Looking for unique patterns that often result from a single source\n",
    "* **Note**: all rows with NaN values in `recordedBy` column are included in the single_contrib collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93d2ca-5953-4bb9-b25a-36badaee6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20990017-a10c-4fbf-bc5b-edfcbc0ba8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = df.sort_values(\"recordedBy\")#.head(10)\n",
    "v_counts = rb_df.value_counts(\"recordedBy\")\n",
    "\n",
    "v_counts = v_counts[v_counts>1]\n",
    "\n",
    "# `values` are the recordedBy names that satisfy the test condition: having more than 1 specimen.\n",
    "values = v_counts.index.values\n",
    "\n",
    "multi_contrib = rb_df[rb_df.recordedBy.apply(lambda x: x in values) & ~rb_df.recordedBy.isna()]\n",
    "single_contrib = rb_df[rb_df.recordedBy.apply(lambda x: x not in values) & ~rb_df.recordedBy.isna()]\n",
    "\n",
    "na_contrib = rb_df[rb_df.recordedBy.isna()]\n",
    "\n",
    "print(f\"{multi_contrib.shape=}, {single_contrib.shape=}, {na_contrib.shape=}\")\n",
    "\n",
    "assert single_contrib.recordedBy.isna().sum() == 0\n",
    "assert multi_contrib.recordedBy.isna().sum() == 0\n",
    "assert na_contrib.recordedBy.isna().sum() == na_contrib.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f454516-e321-40b3-8c0d-7aedd0d9e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "12263 + 47 + 4134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b224e-382d-4dc7-92f3-80b6675af1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_contrib[single_contrib.recordedBy.isna()].describe(include='all')\n",
    "# multi_contrib[multi_contrib.recordedBy.isna()]\n",
    "\n",
    "# labels[labels==\"None\"]\n",
    "\n",
    "# labels.isna().sum()#.info()\n",
    "\n",
    "# labels.iloc[labels.isna()] = \"NA\"\n",
    "\n",
    "# labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffa0d6-be01-45ae-8917-a09599a9a371",
   "metadata": {},
   "source": [
    "# II. Visual Inspection of image groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f2015-adba-4569-b141-6aed514c68ef",
   "metadata": {},
   "source": [
    "## A. Plotting single contributor images in a grid\n",
    "\n",
    "<!-- * Replace NaN values with a string placeholder of \"NA\" -->\n",
    "\n",
    "### (A.0) - display plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b0f29-5811-4377-8060-0dbccb505e75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs, labels = single_contrib.thumb_path, single_contrib.recordedBy\n",
    "# labels.iloc[labels.isna()] = \"NA\"\n",
    "labels.value_counts().T\n",
    "\n",
    "ipyplot.plot_class_representations(imgs.values, labels.values, img_width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9de91-1197-4e1c-ae0a-d989f6d4b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92ec50-352b-42af-af9c-9e09d0f9b9db",
   "metadata": {},
   "source": [
    "### (A.1) - Conclusion: \n",
    "\n",
    "`0` undesired images out of `47`, all Fossils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba453a9a-a24d-4a2a-be93-179ee4c99678",
   "metadata": {},
   "outputs": [],
   "source": [
    "## B. Plotting na-contributor images in tabs, grouped by `country`\n",
    "\n",
    "# na_contrib.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea002118-b188-41b2-8fee-d0a3e6d621c6",
   "metadata": {},
   "source": [
    "# Plotting images by class between tabs\n",
    "\n",
    "## Looking closely at all rows with NaN values for `recordedBy`, group them by `country`\n",
    "\n",
    "1. `4,134` out of `16,444` specimens have `NaN` values for `recordedBy`  \n",
    "2. `92%` of these have either `NaN` (50%) or `USA` (42%) for `country`\n",
    "3. After manually inspecting all images grouped by country below, all of the countries except `NA`, `USA`, and `Brazil` contain valid entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e02c3-5892-40c2-a3c3-d53c8c89b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate a list to keep track of our annotations\n",
    "\n",
    "marked_for_removal = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2807725-ba13-48b2-8c40-bde23a6de5f4",
   "metadata": {},
   "source": [
    "### (B.0) - Inspect low-contribution groups\n",
    "    * Manually inspect rows with both  \n",
    "        a. NaN in `recordedBy` column, and  \n",
    "        b. column `country` value with fewer than 120 rows in total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d7e0d-3960-4558-a8f3-0ede129c5e99",
   "metadata": {},
   "source": [
    "* Sort values by HSV `v` channel value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59a11d-2810-4ece-ba42-4a06fd321cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_contrib = na_contrib.sort_values(\"v\", ascending=False)\n",
    "na_contrib = na_contrib.sort_values(\"h\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c5d7d-4c81-43f3-b810-543801d1a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Select all rows with `recordedBy` == NaN\n",
    "# na_recordedBy = rb_df[rb_df.recordedBy.isna()]\n",
    "# print(f\"{rb_df.shape=}, {na_recordedBy.shape=}\")\n",
    "\n",
    "print(f\"{rb_df.shape=}, {na_contrib.shape=}\")\n",
    "\n",
    "na_contrib.columns\n",
    "# na_contrib.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cc582-034d-4f6a-b053-6e94d65126fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key = 'country'\n",
    "\n",
    "# imgs, labels = na_contrib.thumb_path, na_contrib.loc[:,label_key]\n",
    "imgs, labels = na_contrib.thumb_path, na_contrib[label_key]\n",
    "ids = na_contrib[\"identifier\"]\n",
    "h, s, v = na_contrib[\"h\"], na_contrib[\"s\"], na_contrib[\"v\"]\n",
    "#Replace NaN values with string placeholder \"NA\"\n",
    "# labels.iloc[labels.isna()] = \"NA\"\n",
    "labels = labels.fillna(\"NA\")\n",
    "\n",
    "# labels.value_counts()\n",
    "\n",
    "assert ids.value_counts().shape[0] == labels.shape[0]\n",
    "assert labels.value_counts().sum() == labels.shape[0]\n",
    "\n",
    "vc_norm = labels.value_counts(True)\n",
    "vc = labels.value_counts()\n",
    "pd.concat([vc, vc_norm], axis=1)\n",
    "\n",
    "tabs_order = labels.value_counts().index.values[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e585aa-3fc0-4164-838b-fb5af669ae67",
   "metadata": {},
   "source": [
    "#### Plot max=120 images per country's tab to quickly weed out the smaller countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583d3cb-4c3c-4f68-b9cd-475f8590cceb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_class_tabs(imgs.values, labels.values, custom_texts=ids.values, max_imgs_per_tab=120, img_width=150, tabs_order=tabs_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5c74d-11d0-452e-88a7-b7d6f5742cf9",
   "metadata": {},
   "source": [
    "### (B.0) - Conclusion:\n",
    "* Saving `USA` and `NA` for the next step, the only low-contribution group with undesirable specimens is `1` row with `recordedBy=NaN` & `country=\"Brazil\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa614d8c-5521-4068-a375-bca23729efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_drop = labels[labels==\"Brazil\"].index\n",
    "thumb_paths_to_drop = imgs[idx_to_drop].values.tolist()\n",
    "\n",
    "thumb_paths_to_drop\n",
    "assert len(thumb_paths_to_drop) == 1\n",
    "\n",
    "marked_for_removal.append({\n",
    "    \"thumb_path\": thumb_paths_to_drop[0],\n",
    "    \"reason\": \"Image does not contain a Fossil\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3d5fa-e9df-4335-a029-e374547f2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_for_removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb180e96-b1a5-4c4b-8fc2-9325067b31b9",
   "metadata": {},
   "source": [
    "### (B.1) - Inspect high-contribution groups\n",
    "    * Narrow down to only the 3 countries of interest\n",
    "\n",
    "1. `NA` - `2,051` specimens need to be reviewed\n",
    "2. `USA` - `1,720` specimens need to be reviewed\n",
    "3. `Brazil` - `1` specimen -- patently undesired image based upon manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc251bb-7c10-4652-b03b-a83597b90508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786deca6-5959-4491-b1dd-cb28b627dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select only specimens from countries with at least `thresh` entries\n",
    "# thresh = 25\n",
    "# in_thresh = labels.value_counts() >= thresh\n",
    "# keep_idx = labels.apply(lambda x: in_thresh[x])\n",
    "# imgs = imgs[keep_idx.index]\n",
    "# labels = labels[keep_idx]\n",
    "\n",
    "#######################\n",
    "# # Select only specimens from countries in our manually constructed search query\n",
    "search_query = [\"NA\", \"USA\", \"Brazil\"]\n",
    "in_query = labels.apply(lambda x: x in search_query)\n",
    "keep_idx = labels[in_query]\n",
    "\n",
    "imgs = imgs[keep_idx.index]\n",
    "labels = labels[keep_idx.index]\n",
    "ids = ids[keep_idx.index]\n",
    "\n",
    "h = h[keep_idx.index]\n",
    "s = s[keep_idx.index]\n",
    "v = v[keep_idx.index]\n",
    "###############\n",
    "###############\n",
    "\n",
    "imgs.shape\n",
    "labels.shape\n",
    "labels.value_counts()#label_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fb4a1-71cb-47e6-8dc4-0592041699ca",
   "metadata": {},
   "source": [
    "### sort by `v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4426963-cc00-4f9f-ba87-cedd9d0ee435",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = v.sort_values(ascending=False).index.values\n",
    "\n",
    "imgs = imgs[sorted_idx]\n",
    "labels = labels[sorted_idx]\n",
    "ids = ids[sorted_idx]\n",
    "h = h[sorted_idx]\n",
    "s = s[sorted_idx]\n",
    "v = v[sorted_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b7bf1-ee29-4018-aca6-88f8b4ffe13b",
   "metadata": {},
   "source": [
    "#### Display the 3 countries of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4edf7-ced9-4c54-879b-5bcf1010feca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=2500, img_width=200)\n",
    "# ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=1025, img_width=200)\n",
    "\n",
    "# start_idx = 400\n",
    "# end_idx = 1025\n",
    "\n",
    "start_idx = 0\n",
    "end_idx = -1\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    \"images\": imgs.values[start_idx:end_idx],\n",
    "    \"labels\": labels.values[start_idx:end_idx],\n",
    "    \"custom_texts\": ids[start_idx:end_idx]\n",
    "}\n",
    "ipyplot.plot_class_tabs(**kwargs,\n",
    "                        max_imgs_per_tab=2500, # 1025,\n",
    "                        img_width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154331f-1b9d-46c9-a71f-2d3651b804a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bd776-aa1d-4d00-84c8-91f497fdaf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img = cv2.imread(file_paths_to_drop[0])\n",
    "# plt.imshow(img[:,:,::-1])\n",
    "\n",
    "# rows2drop = rb_df[rb_df.thumb_path.apply(lambda x: x in file_paths_to_drop)]\n",
    "# identifier2drop = rows2drop.identifier\n",
    "# identifier2drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd6ec4-7c62-4829-aa9f-3a2581714fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_idx = 0\n",
    "# end_idx = -1\n",
    "\n",
    "idx = labels[labels==\"NA\"].index.values\n",
    "\n",
    "kwargs = {\n",
    "    \"images\": imgs[idx].values,\n",
    "    \"labels\": labels[idx].values,\n",
    "    \"custom_texts\": ids[idx].values\n",
    "}\n",
    "\n",
    "kwargs[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b359876-6a50-4bd6-a48b-d3768d17a5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_idx = [\n",
    "2,\n",
    "3,\n",
    "7,\n",
    "8,\n",
    "13,\n",
    "15,\n",
    "19,\n",
    "22,\n",
    "24,\n",
    "25,\n",
    "27,\n",
    "33,\n",
    "34,\n",
    "38,\n",
    "42,\n",
    "52,\n",
    "53,\n",
    "55,\n",
    "56,\n",
    "57,\n",
    "58,\n",
    "62,\n",
    "67,\n",
    "68,\n",
    "87,\n",
    "91,\n",
    "93,\n",
    "99,\n",
    "106,\n",
    "108,\n",
    "111,\n",
    "115,\n",
    "119,\n",
    "121,\n",
    "122,\n",
    "124,\n",
    "126,\n",
    "127,\n",
    "129,\n",
    "130,\n",
    "131,\n",
    "132,\n",
    "139,\n",
    "140,\n",
    "143,\n",
    "144,\n",
    "145,\n",
    "146,\n",
    "147,\n",
    "148,\n",
    "153,\n",
    "154,\n",
    "156,\n",
    "157,\n",
    "158,\n",
    "161,\n",
    "162,\n",
    "163,\n",
    "164,\n",
    "165,\n",
    "166,\n",
    "170,\n",
    "171,\n",
    "172,\n",
    "174,\n",
    "175,\n",
    "176,\n",
    "177,\n",
    "178,\n",
    "181,\n",
    "183,\n",
    "188,\n",
    "189,\n",
    "190,\n",
    "191,\n",
    "192,\n",
    "193,\n",
    "194,\n",
    "195,\n",
    "196,\n",
    "197,\n",
    "198,\n",
    "199,\n",
    "204,\n",
    "208,\n",
    "209,\n",
    "210,\n",
    "213,\n",
    "225,\n",
    "231,\n",
    "235,\n",
    "260,\n",
    "263,\n",
    "289,\n",
    "318,\n",
    "550,\n",
    "664,\n",
    "1561\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c6aef-9119-4e6e-a571-fd373f0ca972",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {k: v[selected_idx] for k, v in kwargs.items()}\n",
    "kwargs['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e96e8-d1d9-4db5-9384-8f5c842d04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_for_removal.extend(\n",
    "    [\n",
    "        {\n",
    "            \"thumb_path\": path,\n",
    "            \"reason\": \"Specimen image appears not to be a Fossil, found by manual inspection after filtering for rows with NaN values in `recordedBy`, then rows with NaN values in `country`, then sorting by `v`\"\n",
    "        }\n",
    "        for path in kwargs[\"images\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41397b27-ace8-4bbd-b3eb-913a4521b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(marked_for_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0d15e-cbc0-4aca-82c2-52b1ec6f9baf",
   "metadata": {},
   "source": [
    "### (B.1) - Conclusion:\n",
    "* Manually reviewed the top 2 `country` values (after filtering for recordedBy=NaN) for rows to remove\n",
    "Found:  \n",
    "1. `USA` has `0` rows to remove\n",
    "2. `NA` has `98` rows to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05507047-5f6d-4a5a-8788-82510237ef52",
   "metadata": {},
   "source": [
    "## Outcome of our 1st exploration procedure (I.(B.0) and I.(B.1)):\n",
    "    1. Filtered to include only those with NaN values in the `recordedBy` column ( `4,134` out of `16,444` specimens)\n",
    "    2. Grouped by each row's value in the `country` column (max: NaN with 2,051 | min: 4-way tie with 1)\n",
    "    \n",
    "    \n",
    "Found a total of:  \n",
    "    1. `1` rows that need to be removed with `column=\"Brazil\"`.  \n",
    "    2. `0` rows that need to be removed with `column=\"USA\"`.  \n",
    "    3. `98` rows that need to be removed with `column=NaN`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98fb5ee-f911-4bfa-b6f3-fe2900b41660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal_df = rb_df[rb_df.identifier.apply(lambda x: x in kwargs[\"custom_texts\"])]\n",
    "# removal_df\n",
    "\n",
    "\n",
    "# dp = mk.DataPanel.from_pandas(removal_df.sort_values([\"recordedBy\", \"country\"], ascending=False))\n",
    "\n",
    "# _cols = dp.columns\n",
    "# _cols.remove(\"recordedBy\")\n",
    "# dp[\"thumbnail\"] = mk.ImageColumn.from_filepaths(dp[\"thumb_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288337d-6d7c-475e-96f2-5580b3bc7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "16444-4082-99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c5523-2c09-43a9-9b26-4ef3a0f5a23d",
   "metadata": {},
   "source": [
    "## Summary of Section I.\n",
    "\n",
    "We've so far found:\n",
    "\n",
    "* `99` rows out of `16,444` to remove\n",
    "* `4082` (`47` + `4035`) rows out of `16,444` to keep\n",
    "\n",
    "What remains to be reviewed:\n",
    "\n",
    "* `12,263` rows out of `16,444` remain to be seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712aa320-61c8-493d-8807-f17ec193aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "16444 - 4134"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e5940-fdb4-422d-a953-16c6d56c86b5",
   "metadata": {},
   "source": [
    "# II. Double check entries with valid `recordedBy` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8145c-669c-4bf0-823c-a05f38097be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = multi_contrib.thumb_path, multi_contrib.recordedBy\n",
    "# # labels.iloc[labels.isna()] = \"NA\"\n",
    "# labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aadeee-62ab-4cf5-bd1b-b6bdc4008962",
   "metadata": {},
   "source": [
    "## II.a) -- 1st check those with contributors with < 50 contributions\n",
    "\n",
    "1. `1,196` out of `12,263`/`16,444` (remaining/total) specimens have values for `recordedBy` corresponding to contributors with more than 1 but less than 50 contributions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61c74b-74da-49ee-a369-b369d00ee17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Select all rows with `recordedBy` values from contributors with more than 1 but less than thresh # of contributions\n",
    "\n",
    "label_key = \"recordedBy\"\n",
    "thresh = 50\n",
    "\n",
    "labels = rb_df.recordedBy\n",
    "vc = labels.value_counts()\n",
    "included_labels = vc[(vc < thresh) & (vc > 1)].index.values\n",
    "\n",
    "\n",
    "valid_recordedBy = rb_df[rb_df.recordedBy.apply(lambda x: x in included_labels)]\n",
    "print(f\"{rb_df.shape=}, {valid_recordedBy.shape=}\")\n",
    "print(f\"{rb_df.shape[0] - valid_recordedBy.shape[0]=}\")\n",
    "\n",
    "\n",
    "# label_key = 'country'\n",
    "label_key = 'recordedBy'\n",
    "imgs, labels = valid_recordedBy.thumb_path, valid_recordedBy.loc[:,label_key]\n",
    "assert labels.isna().sum() == 0\n",
    "\n",
    "vc_norm = labels.value_counts(True)\n",
    "vc = labels.value_counts()\n",
    "pd.concat([vc, vc_norm], axis=1)\n",
    "\n",
    "tabs_order = labels.value_counts().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6215f-43e0-4256-8b37-07911ef644bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.shape\n",
    "vc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d5018-2199-4d89-9cdc-1f5311d16133",
   "metadata": {},
   "outputs": [],
   "source": [
    "12310 - 1196\n",
    "\n",
    "16444 - 12310\n",
    "\n",
    "4134 + 1196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d962c5c-478a-4cc7-b815-41a3dabcde3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=55, img_width=200, tabs_order=tabs_order)#, force_b64=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855fe0c-724a-46aa-9d9d-5932f994ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "16444 - (4082 + 1196 + 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c94206-8cf1-4cf8-b49e-9caabe470e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df.value_counts(\"recordedBy\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d628cff-c9d1-450b-934e-a83d924ccc97",
   "metadata": {},
   "source": [
    "### II.a) - Conclusion:\n",
    "* Manually reviewed the rows with valid `recordedBy` values from contributors with # of contributions between 1 and 50\n",
    "Found:  \n",
    "1. `0` out of `1,196` rows to remove from any of the `117` of `195` total unique contributors\n",
    "\n",
    "So far, I've reviewed `5,377` of `16,444` total, leaving `11,067` left to review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7db13-b534-4055-8d0c-b1bfbcf00e67",
   "metadata": {},
   "source": [
    "## 2nd, check those with contributors with >= 50 contributions\n",
    "\n",
    "1. `11,067` out of `16,444` specimens have `recordedBy` values from contributors >= 50 contributions from `31` out of `195` known contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafdb6a-d13d-40e7-9b71-1717d0592219",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df.value_counts('recordedBy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f288d-3efc-4a60-82b0-75f99e355c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc[(vc >= thresh)].sum() +vc[(vc < thresh)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81a01-c5ac-4690-ac89-b68661e33726",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Select all rows with `recordedBy` values from contributors with more than or equal to thresh # of contributions\n",
    "\n",
    "thresh = 50\n",
    "\n",
    "labels = rb_df.recordedBy\n",
    "vc = labels.value_counts()\n",
    "included_labels = vc[(vc >= thresh)].index.values\n",
    "\n",
    "\n",
    "valid_recordedBy = rb_df[rb_df.recordedBy.apply(lambda x: x in included_labels)]\n",
    "print(f\"{rb_df.shape=}, {valid_recordedBy.shape=}\")\n",
    "print(f\"{rb_df.shape[0] - valid_recordedBy.shape[0]=}\")\n",
    "\n",
    "\n",
    "# label_key = 'country'\n",
    "label_key = 'recordedBy'\n",
    "imgs, labels = valid_recordedBy.thumb_path, valid_recordedBy.loc[:,label_key]\n",
    "assert labels.isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2e072-8484-432f-9cde-e278ed4a4490",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc_norm = labels.value_counts(True)\n",
    "vc = labels.value_counts()\n",
    "pd.concat([vc, vc_norm], axis=1)\n",
    "\n",
    "tabs_order = labels.value_counts().index.values\n",
    "\n",
    "vc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40b116-00be-4757-a562-9349f201c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.iloc[1:].sum() + 4774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d7dc0-a84a-4695-86f3-c380cbc33ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_dict = {\n",
    "    \"contains many valid Fossils with misleadingly bright color/saturation values\":\n",
    "        [\"H. F. Wells\",\n",
    "         \"George R. Wieland\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205c48c-73b0-455c-844c-6cc50e7c9d0a",
   "metadata": {},
   "source": [
    "### Since it's such an outlier in terms of specimens-per-contributor, let's display the top 1 contributor separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4474d-c4bb-4ed1-9ab3-7d844d8cba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba912467-3b67-4f85-9913-ead7b9b3f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=1000, img_width=150, tabs_order=tabs_order[1:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce9823-5804-433a-9e89-93eee6db155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Found `0` rows to remove out of `4,774` total contributed by `\"Samuel S. Strong\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1444735-ddad-47ee-b3f9-4ff356baa310",
   "metadata": {},
   "outputs": [],
   "source": [
    "675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b083941-67d0-4011-9268-af7ab8692dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=1000, img_width=150, tabs_order=tabs_order[:1])\n",
    "\n",
    "# labels_select = [l for l in labels if l in tabs_order[:1]]\n",
    "labels_select = labels[labels.apply(lambda x: x in tabs_order[:1])]\n",
    "idx_select = labels_select.index.values\n",
    "\n",
    "imgs_select = imgs.loc[idx_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93413895-95f2-418a-86cb-d19818bb3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_select.shape\n",
    "imgs_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9e72c-dd2e-4016-95aa-6232874a7f28",
   "metadata": {},
   "source": [
    "### Found `0` rows to remove out of `4,774` total contributed by `\"Samuel S. Strong\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1f759-87d2-4a49-afbe-cb080c4cd667",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imgs_sel, \n",
    "\n",
    "ipyplot.plot_class_tabs(imgs_select.values, labels_select.values,\n",
    "                    max_imgs_per_tab=5000, img_width=150)#, tabs_order=tabs_order[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be2c08-af78-42f5-81c5-8ae0736c9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark_for_inspection = {\"recordedBy\":\n",
    "#                            [\"Leo J. Hickey\"]\n",
    "#                       }\n",
    "# Found 1 possible mistake in \"Leo J. Hickey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718293b2-434f-463c-9388-daa56f93f422",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "_imgs = mk.ImageColumn.from_filepaths(rb_df[rb_df.recordedBy==\"Leo J. Hickey\"].thumb_path.values)\n",
    "_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43bb25a-8deb-45e0-bb42-3a4db4613cdb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 1. Select all rows with `recordedBy` values from contributors with more than thresh # of contributions\n",
    "\n",
    "# thresh = 1\n",
    "# labels = rb_df.recordedBy\n",
    "\n",
    "# vc = labels.value_counts()\n",
    "# included_labels = vc[vc > thresh].index.values\n",
    "\n",
    "# valid_recordedBy = rb_df[rb_df.recordedBy.apply(lambda x: x in included_labels)]\n",
    "# print(f\"{rb_df.shape=}, {valid_recordedBy.shape=}\")\n",
    "# print(f\"{rb_df.shape[0] - valid_recordedBy.shape[0]=}\")\n",
    "\n",
    "# thresh = 25\n",
    "# in_thresh = labels.value_counts() >= thresh\n",
    "# keep_idx = labels.apply(lambda x: in_thresh[x])\n",
    "# imgs = imgs[keep_idx.index]\n",
    "# labels = labels[keep_idx]\n",
    "\n",
    "\n",
    "# label_key = 'country'\n",
    "# label_key = 'recordedBy'\n",
    "# imgs, labels = valid_recordedBy.thumb_path, valid_recordedBy.loc[:,label_key]\n",
    "\n",
    "# assert labels.isna().sum() == 0\n",
    "#Replace NaN values with string placeholder \"NA\"\n",
    "# labels.iloc[labels.isna()] = \"NA\"\n",
    "\n",
    "# vc_norm = labels.value_counts(True)\n",
    "# vc = labels.value_counts()\n",
    "# pd.concat([vc, vc_norm], axis=1)\n",
    "\n",
    "# tabs_order = labels.value_counts().index.values\n",
    "\n",
    "# ipyplot.plot_class_tabs(imgs.values, labels.values, max_imgs_per_tab=50, img_width=200, tabs_order=tabs_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb3838-87f9-495c-9aee-adc166f5be67",
   "metadata": {},
   "source": [
    "* (1:35 AM Monday September 19th, 2022) -- Inspected all `recordedBy` values for contributors with < 50 included specimens, found no issues except for possible herbarium twigs & stems included in 1 contributor's entries (`Jeffrey B. Doran`)\n",
    "\n",
    "\n",
    "* (4:29 AM Monday September 19th, 2022) -- Inspected all `recordedBy` values for contributors with >= 50 included specimens (except for `Samuel S. Strong` who contributed the most out of anyone, with a total of `4,774` records), found only 1 problem specimen contributed by `Leo J. Hickey`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586983e-da71-4912-927a-cba1e3f9293a",
   "metadata": {},
   "source": [
    "### Below, we visualize the specimens selected for possible removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1bbc4b-f3db-4c86-9ad8-33915bd79c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marked_for_removal = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739849c7-591c-4a55-8823-64e7297f932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = mk.DataPanel.from_pandas(rb_df.sort_values(\"recordedBy\", ascending=False))\n",
    "\n",
    "_cols = dp.columns\n",
    "_cols.remove(\"recordedBy\")\n",
    "dp[\"thumbnail\"] = mk.ImageColumn.from_filepaths(dp[\"thumb_path\"])\n",
    "dp = dp[[\"thumbnail\", \"recordedBy\", *_cols]]\n",
    "# dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10965d4-b41a-4c9d-a414-ffececfca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = dp[dp[\"recordedBy\"] == \"Leo J. Hickey\"].lz[22:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90a473-ccb3-4673-b2e9-41ce1741f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected\n",
    "len(marked_for_removal)\n",
    "\n",
    "marked_for_removal.append({\n",
    "    \"thumb_path\": selected[\"thumb_path\"][0],\n",
    "    \"reason\": \"Image does not contain a Fossil\"\n",
    "})\n",
    "\n",
    "len(marked_for_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd7580-83de-4f76-b68f-c677af847a82",
   "metadata": {},
   "source": [
    "Some samples contributed by Jeffrey B. Doran were marked as being possibly non-Fossils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a764233-3021-4da4-b580-eb38a7c8b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = dp[dp[\"recordedBy\"] == \"Jeffrey B. Doran\"]# .lz[22:23]\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70154715-5097-43dc-aa10-a0bf202b3710",
   "metadata": {},
   "source": [
    "Based on visual inspection of this small subset (19 rows), it becomes clear that simply sorting the subset in order of increasing value for `v` column (`value` in HSV image color formats) allows us to cleanly divide into 2 categories, valid vs. invalid specimens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9abba6-7ae2-4b41-a5c1-6359be2c2e27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected = selected.sort(by=\"v\") \n",
    "#[selected.columns[:5]]\n",
    "\n",
    "to_remove_dp = selected[12:]\n",
    "to_keep_dp = selected[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005829b-d59c-41d2-96cf-e433417ae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_for_removal.extend(\n",
    "    [\n",
    "        {\n",
    "            \"thumb_path\": path,\n",
    "            \"reason\": \"Image does not contain a Fossil, but what appears to be a collection of stems or roots on bright white backgrounds.\"\n",
    "        }\n",
    "        for path in to_remove_dp[\"thumb_path\"].to_pandas().values.tolist()\n",
    "    ]\n",
    ")\n",
    "# marked_for_removal\n",
    "\n",
    "len(rb_df)\n",
    "len(marked_for_removal)\n",
    "len(rb_df) - len(marked_for_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1b92e-c7ff-4ea6-868b-9a3081a6c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657461ee-edb3-42ce-a342-3ede8cc866a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marked_for_removal[0][\"thumb_path\"] = marked_for_removal[0][\"thumb_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bb0ea-3326-4c49-b135-65f0bd678811",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_for_removal_dict = {}\n",
    "for k in marked_for_removal[0].keys():\n",
    "    marked_for_removal_dict[k] = [i[k] for i in marked_for_removal]\n",
    "    \n",
    "len(marked_for_removal_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381bcedf-dfc8-4a26-abb0-02a251c4f1e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "removal_df = pd.DataFrame.from_records(marked_for_removal)\n",
    "\n",
    "removal_df = (\n",
    "    removal_df\n",
    "    .merge(rb_df, on=\"thumb_path\")\n",
    "    .rename(columns={\"reason\":\"reason_removed\"})\n",
    "    .drop(columns=[\"label\"])\n",
    ")\n",
    "# removal_df\n",
    "assert removal_df.shape == (107,52)\n",
    "\n",
    "ids2remove = removal_df.identifier.values.tolist()\n",
    "\n",
    "# rb_df[rb_df.identifier.apply(lambda x: x in ids2remove)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd7c68-5a23-48c4-9b70-368e5b6fae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf0284-3efe-476a-9165-055135ab2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2keep = rb_df[rb_df.identifier.apply(lambda x: x not in ids2remove)]\n",
    "\n",
    "final_df2keep = (\n",
    "    final_df2keep.drop(columns=[\"label\"])\n",
    ")\n",
    "assert final_df2keep.shape == (16337,51)\n",
    "\n",
    "final_df2keep.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f30f2-1445-49d1-92b5-da5d0e5b0bf3",
   "metadata": {},
   "source": [
    "# III. Save Versions 0 (inputs to this notebook) and 1 (outputs of this notebook) as csv catalogs for sharing with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5bea05-dce2-41fe-be0f-1a56ee7c1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = Path('/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/official_releases/version_0')\n",
    "save_dir = Path(\"/media/data_cifs/projects/prj_fossils/data/raw_data/2022-yale_fossil/official_releases/version_0\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "rb_df.to_csv(Path(save_dir, \"original_catalog.csv\"))\n",
    "\n",
    "with open(Path(save_dir, \"README.md\"), \"w\") as f:\n",
    "    f.write(\n",
    "        \"\"\"\n",
    "# 2022 yale fossil dataset\n",
    "## version 0\n",
    "\n",
    "Created on: Monday Sept 19th, 2022  \n",
    "Created by: Jacob A Rose, working on data provided by Peter Wilf  \n",
    "\n",
    "Contains a total of `16,444` specimens without removing any of the many duplicates and non-Fossil images.  \n",
    "See versions 1+ for cleaner versions of thhe catalog.\n",
    "        \"\"\"\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe466f-6816-436a-a3c2-84c6ce6a20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = Path('/media/data_cifs/projects/prj_fossils/users/jacob/github/image-utils/notebooks/fossil dataset preprocessing/2022-yale_fossil/official_releases/version_1')\n",
    "save_dir = Path(\"/media/data_cifs/projects/prj_fossils/data/raw_data/2022-yale_fossil/official_releases/version_1\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc264fb-0166-4ae5-a038-49233caf1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal_df.to_pandas().drop(columns=[\"thumbnail\"]).to_csv(Path(save_dir, \"catalog_marked_for_removal.csv\"))\n",
    "\n",
    "removal_df.to_csv(Path(save_dir, \"catalog_marked_for_removal.csv\"))\n",
    "final_df2keep.to_csv(Path(save_dir, \"catalog_marked_to_keep.csv\"))\n",
    "\n",
    "removal_df.to_parquet(Path(save_dir, \"catalog_marked_for_removal.parquet\"))\n",
    "final_df2keep.to_parquet(Path(save_dir, \"catalog_marked_to_keep.parquet\"))\n",
    "\n",
    "with open(Path(save_dir, \"README.md\"), \"w\") as f:\n",
    "    f.write(\n",
    "        f\"\"\"\n",
    "# 2022 yale fossil dataset\n",
    "## version 1\n",
    "\n",
    "Created on: Monday Sept 19th, 2022  \n",
    "Created by: Jacob A Rose, working on data provided by Peter Wilf  \n",
    "\n",
    "Contains 2 separate catalogs containing respectively:  \n",
    "1. `catalog_marked_for_removal`: `{removal_df.shape[0]}` specimens for removal, and  \n",
    "2. `catalog_marked_to_keep`: `{final_df2keep.shape[0]}` specimens for keeping  \n",
    "\n",
    "from an original total of `16,444` specimens.  \n",
    "\n",
    "------------  \n",
    "* The `catalog_marked_for_removal` contains an extra column describing the reason for removal  \n",
    "* Version 2 will deal with removing the still included sequence of duplicate images\n",
    "        \"\"\"\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59d443-5b1c-4e15-a182-86decc86c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark_for_inspection = {\"recordedBy\":\n",
    "#                            [\"Jeffrey B. Doran\"]\n",
    "#                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815956ce-03af-47ca-8ff8-cc4d29033353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "669ca670-59cf-4f34-a42e-5cbd4a04039d",
   "metadata": {},
   "source": [
    "## Misc extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61fd3a-677e-44c6-81fb-a379f0f661ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\n",
    "    \"v\",\n",
    "    ascending=True, # False,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df\n",
    "\n",
    "bins = [0.0, 0.25, 0.5, 0.75, 1.0] #[:-1]\n",
    "\n",
    "df[\"quantiles\"], o_bins = pd.qcut(\n",
    "    df[\"v\"],\n",
    "    len(bins),\n",
    "    labels=bins,\n",
    "    precision=2,\n",
    "    retbins=True\n",
    ")\n",
    "\n",
    "df.describe(include=\"all\")\n",
    "\n",
    "largest_idx = df.groupby(\"quantiles\")[\"v\"].nlargest(10).reset_index(level=0).index\n",
    "smallest_idx = df.groupby(\"quantiles\")[\"v\"].nsmallest(10).reset_index(level=0).index\n",
    "\n",
    "\n",
    "largest_idx\n",
    "smallest_idx\n",
    "\n",
    "from more_itertools import unzip\n",
    "\n",
    "smallest = df.loc[smallest_idx,:]\n",
    "largest = df.loc[largest_idx,:]\n",
    "\n",
    "\n",
    "i, paths, quantiles, v_list = [\n",
    "    list(c) for c in unzip(\n",
    "        smallest[[\"path\", \"quantiles\", \"v\"]].to_records()\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# i, paths, quantiles, v_list = [\n",
    "#     list(c) for c in unzip(\n",
    "#         largest[[\"path\", \"quantiles\", \"v\"]].to_records()\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "\n",
    "import ipyplot\n",
    "\n",
    "tabs_order=sorted(set(quantiles))\n",
    "\n",
    "ipyplot.plot_class_tabs(paths,\n",
    "                        labels=[f\"{q:.2%}\" for q in quantiles],\n",
    "                        custom_texts=[f\"{v=}\" for v in v_list],\n",
    "                        tabs_order=np.sort(list(set(quantiles)))\n",
    "                    )\n",
    "\n",
    "records = df.to_records()\n",
    "records\n",
    "\n",
    "records[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e39418-82f2-47b9-aeed-e6f638352471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af79ef-308d-4c46-9dde-6538cfea93f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ac04a-db8c-41fe-96d5-766307c731f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "\n",
    "def generate_file_path_dataframe_fixture() -> pd.DataFrame:\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [2768571, 130655, 1155027, 34713051, 331002277],\n",
    "            [1448753, 60632, 790040, 3070447, 212558178],\n",
    "            [654405, 9536, 422931, 19852167, 145934619],\n",
    "            [605216, 17848, 359891, 8826585, 1379974505],\n",
    "            [288477, 9860, 178245, 1699369, 32969875]\n",
    "        ],\n",
    "        columns = ['Total Cases', 'Total Deaths', 'Total Recovered', 'Total Tests', 'Population']\n",
    "    )\n",
    "\n",
    "    df['Country'] = [\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-United-States-of-America.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Brazil.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Russia.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-India.png',\n",
    "        'https://www.countries-ofthe-world.com/flags-normal/flag-of-Peru.png'\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def path_to_image_html(path: str,\n",
    "                       width: int=128):\n",
    "    return f'<img src=\"{path}\" width=\"{width}\" >'\n",
    "\n",
    "\n",
    "def display_image_df(df: pd.DataFrame,\n",
    "                     formatters: Dict[str,Callable]\n",
    "                    ):\n",
    "    return HTML(\n",
    "        df.to_html(\n",
    "            escape=False,\n",
    "            formatters=formatters\n",
    "        )\n",
    "    )\n",
    "\n",
    "formatters = {\n",
    "    \"img\": \n",
    "    partial(\n",
    "        path_to_image_html#, width-50\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_html = display_image_df(\n",
    "    df=df.assign(img=df.path.values),\n",
    "    formatters=formatters\n",
    ")\n",
    "df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d959bc-8d58-4ca1-aa47-804b863906a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
