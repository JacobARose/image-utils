{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Property Outliers {#plot_vision_image_property_outliers}\n",
    "=======================\n",
    "\n",
    "This notebooks provides an overview for using and understanding the\n",
    "image property outliers check, used to detect outliers in simple image\n",
    "properties in a dataset.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "-   [Why Check for Outliers?](#why-check-for-outliers)\n",
    "-   [How Does the Check Work?](#how-does-the-check-work)\n",
    "-   [Which Image Properties Are Used?](#which-image-properties-are-used)\n",
    "-   [Run the Check](#run-the-check)\n",
    "\n",
    "Why Check for Outliers?\n",
    "-----------------------\n",
    "\n",
    "Examining outliers may help you gain insights that you couldn\\'t have\n",
    "reached from taking an aggregate look or by inspecting random samples.\n",
    "For example, it may help you understand you have some corrupt samples\n",
    "(e.g. an image that is completely black), or samples you didn\\'t expect\n",
    "to have (e.g. extreme aspect ratio). In some cases, these outliers may\n",
    "help debug some performance discrepancies (the model can be excused for\n",
    "failing on a totally dark image). In more extreme cases, the outlier\n",
    "samples may indicate the presence of samples interfering with the\n",
    "model\\'s training by teaching the model to fit \\\"irrelevant\\\" samples.\n",
    "\n",
    "How Does the Check Work?\n",
    "------------------------\n",
    "\n",
    "Ideally we would like to directly find images which are outliers, but\n",
    "this is computationally expensive and does not have a clear and\n",
    "explainable results. Therefore, we use image properties in order to find\n",
    "outliers (such as brightness, aspect ratio etc.) which are much more\n",
    "efficient to compute, and each outlier is easily explained.\n",
    "\n",
    "We use [Interquartile\n",
    "Range](https://en.wikipedia.org/wiki/Interquartile_range#Outliers) to\n",
    "define our upper and lower limit for the properties\\' values.\n",
    "\n",
    "### Which Image Properties Are Used?\n",
    "\n",
    "By default the checks use the built-in image properties, and it\\'s also\n",
    "possible to replace the default properties with custom ones. For the\n",
    "list of the built-in image properties and explanation about custom\n",
    "properties refer to\n",
    "`vision properties </user-guide/vision/vision_properties>`{.interpreted-text\n",
    "role=\"doc\"}.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Check\n",
    "=============\n",
    "\n",
    "For the example we will load COCO object detection data, and will run\n",
    "the check with the default properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install deepchecks --quiet --upgrade # --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffb17f7ebfd4e77a5f586438c80b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6984509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - Checks will run on the cpu by default. To make use of cuda devices, use the device parameter in the run function.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98eebcae9e43b79af3ed281cc9c97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4><b>Image Property Outliers</b></h4>'), HTML(value='<p>Find outliers images withâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.vision.checks import ImagePropertyOutliers\n",
    "from deepchecks.vision.datasets.detection.coco import load_dataset\n",
    "\n",
    "train_data = load_dataset(train=True, object_type='VisionData')\n",
    "check = ImagePropertyOutliers()\n",
    "result = check.run(train_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the results in an IDE like PyCharm, you can use the following\n",
    "code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#  result.show_in_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be displayed in a new window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe Graphic Result\n",
    "======================\n",
    "\n",
    "The check shows a section for each property. In each section we show the\n",
    "number of outliers and the non-outlier property range, and also the\n",
    "images with the lowest and highest values for the property.\n",
    "\n",
    "For example in property \\\"RMS Contrast\\\" we can see that only 3 outliers\n",
    "were found, 1 below the normal property range and 2 above. Now we can\n",
    "inspect these images and decide if we wish to ignore these kinds of\n",
    "samples or if we would like the model to be able to support them, in\n",
    "which case we may take a close look into the model\\'s predictions on\n",
    "these samples.\n",
    "\n",
    "Observe Result Value\n",
    "====================\n",
    "\n",
    "The check returns CheckResult object with a property \\'value\\' on it\n",
    "which contain the information that was calculated in the check\\'s run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aspect Ratio': {'indices': [6, 4, 27, 40, 63, 31, 8, 46, 10, 32, 22],\n",
       "  'lower_limit': 0.340625,\n",
       "  'upper_limit': 1.3029296874999998},\n",
       " 'Area': {'indices': [60, 61, 44, 25, 62, 13, 6, 58, 50, 11, 26, 14, 45],\n",
       "  'lower_limit': 220800.0,\n",
       "  'upper_limit': 359040.0},\n",
       " 'Brightness': {'indices': [54, 55, 47, 38, 62, 28],\n",
       "  'lower_limit': 0.23778584214186751,\n",
       "  'upper_limit': 0.6858694940161068},\n",
       " 'RMS Contrast': {'indices': [54, 56, 61],\n",
       "  'lower_limit': 0.09993963741568856,\n",
       "  'upper_limit': 0.36929402509717535},\n",
       " 'Mean Red Relative Intensity': {'indices': [50, 37, 36, 60, 61, 55],\n",
       "  'lower_limit': 0.24169391794555903,\n",
       "  'upper_limit': 0.4769510114694686},\n",
       " 'Mean Green Relative Intensity': {'indices': [61, 3, 60, 63, 48, 54, 50],\n",
       "  'lower_limit': 0.28084770328411535,\n",
       "  'upper_limit': 0.4030514973864122},\n",
       " 'Mean Blue Relative Intensity': {'indices': [60, 55, 50],\n",
       "  'lower_limit': 0.15795800862207085,\n",
       "  'upper_limit': 0.41322135317957304}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_classes_indices',\n",
       " '_current_index',\n",
       " '_data_loader',\n",
       " '_get_classes_error',\n",
       " '_get_data_loader_copy',\n",
       " '_get_data_loader_props',\n",
       " '_get_data_loader_sequential',\n",
       " '_image_formatter_error',\n",
       " '_label_formatter_error',\n",
       " '_label_map',\n",
       " '_num_classes',\n",
       " '_sampler',\n",
       " '_transform_field',\n",
       " 'assert_images_valid',\n",
       " 'assert_labels_valid',\n",
       " 'batch_of_index',\n",
       " 'batch_to_images',\n",
       " 'batch_to_labels',\n",
       " 'classes_indices',\n",
       " 'copy',\n",
       " 'data_dimension',\n",
       " 'data_loader',\n",
       " 'from_dataset',\n",
       " 'get_augmented_dataset',\n",
       " 'get_classes',\n",
       " 'get_transform_type',\n",
       " 'has_images',\n",
       " 'has_labels',\n",
       " 'infer_on_batch',\n",
       " 'init_cache',\n",
       " 'is_sampled',\n",
       " 'label_id_to_name',\n",
       " 'n_of_samples_per_class',\n",
       " 'num_classes',\n",
       " 'num_samples',\n",
       " 'original_num_samples',\n",
       " 'task_type',\n",
       " 'to_batch',\n",
       " 'to_dataset_index',\n",
       " 'transform_field',\n",
       " 'update_cache',\n",
       " 'validate_format',\n",
       " 'validate_get_classes',\n",
       " 'validate_image_data',\n",
       " 'validate_infered_batch_predictions',\n",
       " 'validate_label',\n",
       " 'validate_prediction',\n",
       " 'validate_shared_label']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 24, 48]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to_dataset_index(0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
